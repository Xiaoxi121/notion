# 计算机系统

**大体上的重要内容**

**进程（Process） 是指计算机中正在运行的一个程序实例。**举例：你打开的微信就是一个进程。
**线程（Thread） 也被称为轻量级进程，**更加轻量。**一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。**

## 二、硬件结构

### 2.1 CPU是如何工作的

#### 图灵机的工作方式

纸带、读写头、存储单元控制单元以及运算单元

#### 冯诺依曼模型

运算器、控制器、存储器、输入设备、输出设备

#### 线路位宽与CPU位宽

硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽

#### 指令

- R指令 用于算术和逻辑操作
- l指令 用于数据传输、条件分支
- J指令 用于跳转

#### 指令的执行速度

程序cpu执行时间=指令数*每条指令的平均时钟周期数（CPI）\*时钟周期时间

### 2.2  磁盘比内存慢几万倍？

#### 存储器的层次结构

- 寄存器

  32位CPu中存储4字节，64位中存储8字节数据

- Cpu Cache（CPU高速缓存，分为L1、L2、L3，其中L1又分为指令缓存和数据缓存）

  使用SRAM 静态随机存储器：断电则数据消失

  每个Cpu核心都有一块属于自己的L1高速缓存

- 内存

  使用DRAM动态随机存取存储器：需要定时刷新电容，才能存储数据

- 硬盘
  前三者断电后都会消失，硬盘不会

### 2.3 如何写出让CPU跑的更快的代码？

#### CPU Cache有多快？

L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。

程序执行时，会先将内存中的数据**加载到共享的 L3** Cache 中，再加载到每**个核心独有的 L2** Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取

#### CPU Cache的数据结构和读取过程是什么样的？

CacheLine是Cpu从内存读取数据的基本单位，而CacheLine是由各种标志(tag)+数据块(Data block)组成

内存和Cache的映射关系：

- 直接映射-取模运算（内存直接取模运算映射到Cpu Cache）
- 全相连Cache
- 组相连Cache

一个内存地址包括  组标记、CPU Cache Line索引、偏移量三个信息
Cpu Cache中的数据结构包括 索引、有效位、组标记、数据块

根据内存地址中索引计算CpuCache索引-》看有效位、组标记是否正确-》根据偏移量信息读取对应字

#### 如何写出让Cpu跑的更快的代码？

=如何写出Cpu缓存命中率高的代码？=降低指令缓存和数据缓存的缓存命中率

- 数据缓存：遍历数组时，按照内存布局顺序访问
- 指令缓存：动态分支预测
- 提升多核Cpu的缓存命中率：由于时间片影响，各个线程交替使用cpu。所以使用sched-setaffinity方法将线程绑定到某一个Cpu核心，保证各个核心的缓存命中率不受影响

### 2.4 CPU缓存一致性

#### 将Cache中的数据写回内存

写直达：把数据同时写入内存和Cache中

写回：将数据写入Cache中，块被替换时看原本是否是脏，是则写入内存。

#### 缓存一致性问题

未写入内存是被其他进程读取数据，缓存不一致

- 写传播：更新Cache数据时，必须传播到其他核心的Cache
- 事务的串行化：某个Cpu核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的。
  - 锁+写传播

#### 总线嗅探

保证写传播实现，总线广播cpu核心对变量修改的事件。不能保证事务串行化的实现。

#### MESI协议

- Modified，已修改
- Exclusive，独占
- Shared，共享
- Invalidated，已失效

### 2.5 CPU是如何执行任务的？

#### Cpu是如何读写数据的？

Cache 并没有起到缓存的效果，变量 A 和 B 之间没有关系，但因为同属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响。

避免 Cache 伪共享实际上是用**空间换时间**的思想，浪费一部分 Cache 空间，从而换来性能的提升。

#### CPU是如何选择线程的？

1. 进程和线程都是用task_struct结构体表示的，线程承载资源更少，是轻量级线程。
2. Linux内核中的调度器调度对象就是task_struct，因此将这个数据结构称为任务。
3. 根据任务的优先级及相应要求，分为两种。数值越小，优先级越高。
   1. 实时任务
   2. 普通任务

##### 调度类

Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：

- SCHED_DEADLINE：是按照 **deadline** 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；
- SCHED_FIFO：对于相同优先级的任务，按**先来先服务**的原则，**但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；**
- SCHED_RR：对于相同优先级的任务，轮流着运行，**每个任务都有一定的时间片，**当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是**高优先级的任务依然可以抢占低优先级的任务；**

而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：

- SCHED_NORMAL：普通任务使用的调度策略；
- SCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。

##### 完全公平调度(CFS 完全公平调度)

尽量保证公平，实际运行时间相同的情况下，高权重任务优先

##### CPU运行队列

Deadline》Realtime》Fair ，因此实时任务总是会比普通任务优先执行。

##### 调整优先级

nice值是优先级的修正数值，调整的是普通任务的优先级

### 2.6 什么是软中断？

#### 中断是什么

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

#### 什么是软中断

中断过程分成

- 上半部分 处理硬件请求 硬中断
- 下半部分 由内核触发 软中断（此外，一些内核自定义事件也属于软中断）

### 2.7 为什么0.1+0.2 ！= 0.3？

#### 为什么负数要用补码表示？

如果不用补码，在做基本加减法运算的时候，需要多一步来判断是否位负，如果为负数，需要把加法减法反转。补码对于负数的加减法操作，和正数是一样的，可以优化性能。

#### 十进制小数与二进制的转换

符号位+指数位+尾数位

由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会造成精度缺失的情况。

#### 计算机怎么存储小数的？

指数位=移动的位数+偏移量

指数可能是正数也可能是负数，转向无符号整数以避免这个问题，所以要加上一个偏移量

#### 0.1+0.2！=0.3？ 

0.300000004....7个0

## 三、操作系统结构

### 3.1 Linux内核 vs Windows内核

#### 内核

应用连接硬件设备的桥梁。

- 进程调度、内存管理、硬件通信、提供系统调用

#### Linux的设计

Linux 内核设计的理念主要有这几个点：

- MultiTask，多任务

  ​	单核并发 多核并行

- SMP，对称多处理

  ​	SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。

- ELF，可执行文件链接格式

  ​	ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式

- Monolithic Kernel，宏内核

#### 用户态和内核态

- 用户态(User Mode) : **用户态运行的进程可以直接读取用户程序的数据，**拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。
- 内核态(Kernel Mode)：**内核态运行的进程几乎可以访问计算机的任何资源**包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。

- **计算机中的特权指令只能在内核态下执行，以保证系统安全。用户态程序需通过系统调用来请求执行这些指令。**这种机制有助于防止资源冲突并提升系统稳定性。

用户态切换到内核态的三种方式：

1. 系统调用
   1. 系统调用是应用程序与操作系统之间进行交互的一种方式，通过系统调用，应用程序可以访问操作系统底层资源例如文件、设备、网络等。
   2. 步骤
      1. **用户态的程序发起系统调用，**因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此**会中断执行，也就是 Trap（Trap 是一种中断）。**
      2. 发生中断后，**当前 CPU 执行的程序会中断，跳转到中断处理程序**。**内核程序开始执行**，也就是开始处理系统调用。
      3. **内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作**
2. 中断
3. 异常

## 四、内存管理

### 4.1 为什么要有虚拟内存？

#### 虚拟内存

1. 程序访问虚拟地址的时候，由操作系统转换成不同的物理地址（通过Cpu芯片中的内存管理单元mmu的映射关系来转换成物理地址）
2. 操作系统通过 **内存分段**和**内存分页** 来管理虚拟地址和物理地址之间的关系

#### 内存分段

段根据实际需求分配内存，不会出现内部内存碎片

虚拟地址=

- 段选择因子+
  - =段号（段表内的索引）
    - 段表=段基地址+段界限+特权级DPL
  - +特权等标志位
- 段内偏移量

产生问题

- 内存碎片
  - 出现外部内存碎片（用内存交换解决此问题）
- 内存交换效率低（内存交换的空间太大）
  - 需要重新swap内存区域，产生性能瓶颈

#### 内存碎片

- 内部内存碎片(Internal Memory Fragmentation，简称为内存**碎片)：已经分配给进程使用但未被使用的内存**。导致内部内存碎片的主要原因是，当采用固定比例比如 2 的幂次方进行内存分配时，进程所分配的内存可能会比其实际所需要的大。举个例子，一个进程只需要 65 字节的内存，但为其分配了 128（2^7） 大小的内存，那 63 字节的内存就成为了内部内存碎片。
- 外部内存碎片(External Memory Fragmentation，简称为外部碎片)：**由于未分配的连续内存区域太小，以至于不能满足任意进程所需要的内存分配请求，这些小片段且不连续的内存空间被称为外部碎片。**也就是说，外部内存碎片指的是那些并未分配给进程但又不能使用的内存。我们后面介绍的分段机制就会导致外部内存碎片。

![image-20241004205214859](D:\2024\Notes\Typora\八股\计算机系统.assets\image-20241004205214859.png)

#### 常见的内存管理方式

1. 连续内存管理

   1. 连续内存管理为程序分配连续的内存空间，但易产生内存碎片，导致利用率不高。Linux 中采用的伙伴系统算法虽减少了外部碎片，但对于非2的幂次方的内存需求仍会造成内部碎片浪费。

2. 非连续内存管理

   1. 段式管理

      以段(—段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。

   2. 页式管理

      把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被划分为连续等长的虚拟页，是现代操作系统广泛使用的一种内存管理方式。

   3. 段页式管理

      结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。

#### 内存分页

- 将整个虚拟和物理内存空间切割成一段段固定尺寸的大小，称作页。
- 页表存储在内存单元中，内存管理单元（MMU）将虚拟内存单元转换成物理单元地址
- 进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
- 内存空间不够，将其他最近没使用的内存页面换出到硬盘，因此一次修改的只有少数几个页，内存交换效率高

虚拟地址=

- 页号

  页表的索引，页表包括虚拟页号+物理页每页所在物理内存的基地址。

- 页内偏移

##### 多级页表

- 一级页表覆盖到全部虚拟地址空间，二级页表在需要的时候创建。
- 64位分成4级目录
  - 全局页目录项
  - 上层页目录项
  - 中间页目录项
  - 页表项

##### TLB

Translation Lookaside Buffer

在CPU芯片中，加入一个专门访问程序最常访问的页表项Cache，通常称为页表缓存、转址旁路缓存、块表等。

#### 段页式内存管理

- 内存分段+内存分页组合使用
- 先分段，将每个段分为多个页。地址结构=段号+段内页号+页内位移

端页地址-》物理地址三次访问

- 段表-》页表起始地址
- 页表-》物理页号
- 将物理页号+页内位移结合，得到物理地址。

#### Linux内存布局

Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。

虚拟内存作用：

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

（javaguide版）

1. **隔离进程：**物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。
2. **提升物理内存利用率：**有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。
3. **简化内存管理：**进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。
4. **多个进程共享物理内存**：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。
5. **提高内存使用安全性：**控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。
6. **提供更大的可使用内存空间：**可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动

##### 没有虚拟内存的问题

1. **用户程序可以访问任意物理内存，可能会不小心操作到系统运行必需的内存**，进而造成操作系统崩溃，严重影响系统的安全。
2. **同时运行多个程序容易崩溃。**比如你想同时运行一个微信和一个 QQ 音乐，微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就可能会造成微信这个程序会崩溃。
3. **程序运行过程中使用的所有数据或指令都要载入物理内存，根据局部性原理，其中很大一部分可能都不会用到，白白占用了宝贵的物理内存资源。**
   ……

### 4.2 malloc是如何分配内存的？

#### Linux进程的内存分布长什么样？

- 虚拟地址空间内部分为内核空间和用户空间，32和64位地址空间范围不同
- 代码段、数据段、bss段、堆段、文件映射段、栈段

#### malloc是如何分配内存的？

- brk 堆顶指针向高地址移动        分配小于128kb则使用brk
- mmap 私有匿名映射 在文件映射区分配一块内存    大于128kb使用mmap

#### malloc分配的是物理内存吗

malloc分配的是虚拟内存

只有在访问虚拟内存，查找页表，发现不在物理内存中才会触发缺页中断，建立虚拟和物理之间的关系

#### malloc(1)会分配多大的虚拟内存？

glibc2.17分配的是132k字节内存

#### free释放内存，会归还给操作系统吗?

- malloc通过brk申请的内存free后堆内存还存在，即没有还给操作系统，先放进malloc的内存池里，在申请时可以直接复用。但是进程退出后，操作系统会回收进程资源
- 如果malloc通过mmap方式申请，free后会归还。

#### 为什么不全部使用mmap来分配内存？

频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。

#### 为什么不全部使用brk来分配内存？

容易产生内存碎片

#### free函数只传入一个内存地址，为什么能知道要释放多大的内存？

malloc返回给用户态的内存起始地址比进程堆空间起始地址多的字节用来保存内存块的表述信息，当执行free时，向左偏移，分析内存块的大小

### 4.3 内存满了会发生什么？

#### 虚拟内存的作用

- **虚拟内存可以使得进程的运行内存超过物理内存大小**，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些**没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。**
- 由**于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的**。**进程也没有办法访问其他进程的页表，所以这些页表是私有的**，这就**解决了多进程之间地址冲突的问题。**
- 页表里的**页表项中除了物理地址之外，还有一些标记属性的比**特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统**提供了更好的安全性**

#### 内存分配的过程是什么样的

虚拟内存没有物理内存-》缺页中断-》切换到内核态-》有空闲的物理内存直接分配并建立映射关系-》没有的话回收内存-》后台内存回收（异步）-》直接内存回收（同步）-》触发OOM机制

#### 哪些内存可以被回收

- 文件页（内核缓存的磁盘数据和文件数据）
  - 回收干净页-》直接释放内存
  - 回收脏页-》先写入磁盘再释放内存
- 匿名页
  - 通过Linux的swap机制进行回收，swap把不常访问的内存先写入磁盘中，然后释放这些内存。



两个回收都基于LRU（优先回收不常访问算法），维护活跃内存页链表和不活跃内存页链表

#### 回收内存带来的性能影响

磁盘io和同步（直接内存回收）都会影响系统性能

##### 调整文件和匿名页的回收倾向

swappiness调整回收倾向比例

##### 尽早触发kswapd内核线程异步回收内存

如果关注延迟那就适当地增大 min_free_kbytes，如果关注内存的使用量那就适当地调小 min_free_kbytes

##### NUMA架构下的内存回收策略

SMP-》每个CPU地位平等-》一致性存储访问结构（UMA）:总线带宽压力增大，每个CPu可以使用带宽减少'

非一致性存储访问结构(NUMA)，一组CPU有自己独立的资源：在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。

#### 如何保护一个进程不被OOM杀掉

用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。

### 4.4 在4GB物理内存的机器上，申请8g内存会怎么样？

#### 操作系统虚拟内存大小

- 32位操作系统

  进程最多只能申请3gb的虚拟内存空间，所以申请虚拟内存阶段失败

- 64位操作系统

  64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。

  但是申请虚拟内存的过程中，还是使用到了物理内存（比如内核保存虚拟内存的数据结构，也是占用物理内存的），如果你的主机是只有 2GB 的物理内存的话，大概率会触发 OOM。

  如果没有开启 Swap 机制，程序就会直接 OOM；
  如果有开启 Swap 机制，程序可以正常运行。

#### Swap机制的作用

在内存不足和内存闲置的情况下触发

### 4.5 如何避免预读失效和缓存污染的问题

Redis 的缓存淘汰算法则是通过实现 LFU 算法来避免「缓存污染」而导致缓存命中率下降的问题（Redis 没有预读机制）。
MySQL 和 Linux 操作系统是通过改进 LRU 算法来避免「预读失效和缓存污染」而导致缓存命中率下降的问题。

#### Linux和MySQL的缓存

Linux对读取的文件数据进行缓存，缓存在文件系统中的Page Cache中

MySQL数据存在磁盘中，在内存空间中设计缓冲池。

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则磁盘中读取。
- 修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其设置为脏页，由后台线程将脏页写入到磁盘。

#### 传统LRU是如何管理内存数据的

当访问的页在内存里，就直接把该页对应的 LRU 链表节点移动到链表的头部。
当访问的页不在内存里，除了要把该页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的页。

无法解决预读失效和缓存污染的问题

#### 预读失效怎么办？

##### 什么是预读机制？

预读机制带来的好处就是减少了 磁盘 I/O 次数，提高系统磁盘 I/O 吞吐量。

##### 预读失效会带来什么问题？

不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率

##### 如何避免预读失效带来的问题？

- 最好就是让预读页停留在内存里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长。
- Linux中和MySQL都是**将数据分为了冷数据和热数据，然后分别进行 LRU 算法**
  - linux 
    - active list  _inactive list
    - activelist降级到inactivelist inactivelist末位淘汰
  - MySql
    - young-old

#### 缓存污染怎么办？

##### 什么是缓存污染？

只访问过一次的从非活跃移到活跃，如果此后不活跃，污染活跃队列

##### 缓存污染会带来什么问题？

当某一个 SQL 语句扫描了大量的数据时，在 Buffer Pool 空间比较有限的情况下，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，MySQL 性能就会急剧下降。

##### 如何避免缓存污染带来的影响？

提高进入活跃的门槛

- Linux：第二次页被访问
- MySQlInnob：第二次页被访问+距离上一次访问超过1s

### 4.6 深入了解Linux虚拟内存管理

#### 1. 什么是虚拟内存地址

- 以 Intel Core i7 处理器为例，64 位虚拟地址的格式为：全局页目录项（9位）+ 上层页目录项（9位）+ 中间页目录项（9位）+ 页表项（9位）+ 页内偏移（12位）。共 48 位组成的虚拟内存地址。
- 32 位虚拟地址的格式为：页目录项（10位）+ 页表项（10位） + 页内偏移（12位）。共 32 位组成。
- 操作系统一般通过 CPU 芯片中的一个重要组件 MMU(Memory Management Unit，内存管理单元) 将虚拟地址转换为物理地址，这个过程被称为 地址翻译/地址转换（Address Translation） 。

#### 2. 为什么要使用虚拟地址访问内存

在直接操作物理内存的情况下，需要知道每一个变量的位置都被安排在了哪里，而且还要注意和多个进程同时运行的时候，不能共用同一个地址，否则就会造成地址冲突。

根据程序空间局部性原理，进程倾向于访问最近的内存，因此一个进程分配很少的物理内存就可以实现。虚拟内存可以提供物理地址的隔离，扩展了可用空间。

#### 3. 进程虚拟内存空间

- 代码段
  - 存放需要被加载到内存中的二进制机器码
- 数据段
  - 指定了初始值的全局变量和静态变量在虚拟内存空间中的存储区域
- bss段
  - 没有指定初始值的全局变量和静态变量在虚拟内存空间中的存储区域
- 堆（OS堆而不是jvm中的堆）
  - 存放动态申请的内存区域
- 文件映射与匿名映射区
  - 动态链接库中的代码段，数据段，BSS 段，以及通过 mmap 系统调用映射的共享内存区。
- 栈
  - 调用函数过程中使用到的局部变量和函数参数

#### 4. Linux进程虚拟内存空间

##### 32位

- 用户态虚拟空间3g，内核态虚拟空间1g
- 堆从低到高 栈、文件映射与匿名映射区从高到低

##### 64位

- 使用48位描述虚拟内存空间，内核态和用户态都是128t，中间形成空洞canonical address
- 在代码段跟数据段的中间还有一段不可以读写的保护段，它的作用是防止程序在读写数据段的时候越界访问到代码段，这个保护段可以让越界访问行为直接崩溃，防止它继续往下运行。

#### 5. 进程虚拟内存空间的管理

- task_struct 进程的核心数据结构
- mm_struct 进程的内存空间描述符
- vm_area_struct 虚拟内存区域描述符

##### 内核如何划分用户和内核虚拟内存空间+内核如何布局进程虚拟内存空间

我们知道内核是通过一个 mm_struct 结构的内存描述符来表示进程的虚拟内存空间的，并通过 task_size 域来划分用户态虚拟内存空间和内核态虚拟内存空间。

##### 内核如何管理虚拟内存区域

 vm_area_struct，正是这个结构体描述了这些虚拟内存区域 VMA（virtual memory area）

##### 定义虚拟内存区域的访问权限和行为规范

vm_page_prot 和 vm_flags 都是用来标记 vm_area_struct 结构表示的这块虚拟内存区域的访问权限和行为规范

- vm_page_prot 偏向于定义底层内存管理架构中页这一级别的访问控制权限，它可以直接应用在底层页表中，它是一个具体的概念。
- vm_flags 则偏向于定于整个虚拟内存区域的访问权限以及行为规范。描述的是虚拟内存区域中的整体信息，而不是虚拟内存区域中具体的某个独立页面

##### 关联内存映射中的映射关系

anon_vma，vm_file，vm_pgoff 分别和虚拟内存映射相关

- 当我们调用 malloc 申请内存时，如果申请的是小块内存（低于 128K）则会使用 do_brk() 系统调用通过调整堆中的 brk 指针大小来增加或者回收堆内存。
- 如果申请的是比较大块的内存（超过 128K）时，则会调用 mmap 在上图虚拟内存空间中的文件映射与匿名映射区创建出一块 VMA 内存区域（这里是匿名映射）。这块**匿名映射区域就用 struct anon_vma 结构表示。**
- 当调用 mmap 进行文件映射时，**vm_file 属性就用来关联被映射的文件**。这样一来虚拟内存区域就与映射文件关联了起来。**vm_pgoff 则表示映射进虚拟内存中的文件内容**，在文件中的偏移。

##### 针对虚拟内存区域的相关操作

- struct vm_area_struct 结构中还有一个 vm_ops 用来指向针对虚拟内存区域 VMA 的相关操作的函数指针。
- struct vm_operations_struct 结构中定义的都是对虚拟内存区域 VMA 的相关操作函数指针。

##### 虚拟内存区域在内核中是如何被组织的

我们可以通过 cat /proc/pid/maps 或者 pmap pid 查看进程的虚拟内存空间布局以及其中包含的所有内存区域。这两个命令背后的实现原理就是通过遍历内核中的这个 vm_area_struct 双向链表获取的。

尤其在进程虚拟内存空间中包含的内存区域 VMA 比较多的情况下，使用**红黑树**查找特定虚拟内存区域的时间复杂度是 O( logN ) ，可以显著减少查找所需的时间。

#### 6. 程序编译后的二进制文件如何被映射到虚拟内存空间中

那么这些 ELF 格式的二进制文件中的 Section 是如何加载并映射进虚拟内存空间的呢？
内核中完成这个映射过程的函数是 load_elf_binary ，这个函数的作用很大，加载内核的是它，启动第一个用户态进程 init 的是它，fork 完了以后，调用 exec 运行一个二进制程序的也是它。当 exec 运行一个二进制程序的时候，除了解析 ELF 的格式之外，另外一个重要的事情就是建立上述提到的内存映射。

#### 7. 内核虚拟内存空间

内核态虚拟内存空间是所有进程共享的，不同进程进入内核态之后看到的虚拟内存空间全部是一样的。

##### 32位体系内核虚拟内存空间布局

##### 直接映射区

- 3G -- 3G + 896m 这块 896M 大小的虚拟内存会直接映射到 0 - 896M 这块 896M 大小的物理内存上，这块区域中的虚拟内存地址直接减去 0xC000 0000 (3G) 就得到了物理内存地址。所以我们称这块区域为直接映射区
- 前 1M 已经在系统启动的时候被系统占用，1M 之后的物理内存存放的是内核代码段，数据段，BSS 段（这些信息起初存放在 ELF格式的二进制文件中，在系统启动的时候被加载进内存）。
- 当进程被创建完毕之后，在内核运行的过程中，会涉及内核栈的分配，内核会为每个进程分配一个固定大小的内核栈（一般是两个页大小，依赖具体的体系结构），每个进程的整个调用链必须放在自己的内核栈中，内核栈也是分配在直接映射区。
- 内核栈容量小而且是固定的，用户空间中的栈容量大而且可以动态扩展。内核栈的溢出危害非常巨大，它会直接悄无声息的覆盖相邻内存区域中的数据，破坏数据。
- 直接映射区的前 16M 专门让内核用来为 DMA 分配内存，这块 16M 大小的内存区域我们称之为 ZONE_DMA。

##### ZONE_HIGHMEM高端内存

这样一来物理内存中的 ZONE_HIGHMEM 区域就只能采用动态映射的方式映射到 128M 大小的内核虚拟内存空间中，也就是说只能动态的一部分一部分的分批映射，先映射正在使用的这部分，使用完毕解除映射，接着映射其他部分。

##### vmalloc动态映射内存

和用户态进程使用 malloc 申请内存一样，在这块动态映射区内核是使用 vmalloc 进行内存分配。由于之前介绍的动态映射的原因，vmalloc 分配的内存在虚拟内存上是连续的，但是物理内存是不连续的。通过页表来建立物理内存与虚拟内存之间的映射关系，从而可以将不连续的物理内存映射到连续的虚拟内存上。

##### 永久映射区

而在 PKMAP_BASE 到 FIXADDR_START 之间的这段空间称为永久映射区。在内核的这段虚拟地址空间中允许建立与物理高端内存的长期映射关系

##### 固定映射区

采用固定虚拟地址的好处是它相当于一个指针常量（常量的值在编译时确定），指向物理地址，如果虚拟地址不固定，则相当于一个指针变量。

在内核的启动过程中，有些模块需要使用虚拟内存并映射到指定的物理地址上，而且这些模块也没有办法等待完整的内存管理模块初始化之后再进行地址映射。因此，内核固定分配了一些虚拟地址，这些地址有固定的用途，使用该地址的模块在初始化的时候，将这些固定分配的虚拟地址映射到指定的物理地址上去

##### 临时映射区

##### 32位体系结构下Linux虚拟内存空间整体布局

##### 64位体系内核虚拟内存空间布局

由于虚拟内存空间足够的大，即便是内核要访问全部的物理内存，直接映射就可以了，

##### 64位体系结构下Linux虚拟内存空间整体布局

#### 8. 到底什么是物理地址

##### 8.1 DRAM芯片的访问

##### 8.2 CPU如何读主存

CPU 与内存之间的数据交互是通过总线（bus）完成的，而数据在总线上的传送是通过一系列的步骤完成的，这些步骤称为总线事务（bus transaction）。

##### 8.3 CPU从内存读取数据过程

##### 8.4 如何根据物理内存地址从主存中读取数据

##### 8.5 CPU向内存中写入数据过程

## 五、进程管理

### 5.1 进程、线程基础知识

#### 进程

我们**编写的代码**只是一个存储在硬盘的静态文件，通过编译后就会**生成二进制可执行文件**，当我们**运行**这个可执行文件后，它会被**装载到内存中**，接着 **CPU 会执行程序中的每一条指令**，那么这**个运行中的程序，就被称为「进程」**（Process）。

<img src="D:\2024\Notes\Typora\八股\计算机系统.assets\image-20240910153216600.png" alt="image-20240910153216600" style="zoom:50%;" />

##### 进程的状态

**运行、阻塞（等待事件）、就绪（等待cpu调度）**

**创建、结束**

阻塞挂起、就绪挂起

- 进程所使用的内存空间不在物理内存
- sleep
- 用户挂起

##### 进程的控制结构

pcb（process control block）进程存在唯一标识

- 进程描述信息

  - 进程标识符
  - 用户标识符

- 进程控制和管理信息

  - 进程当前状态
  - 进程优先级

- 资源分配清单

  有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

- CPU相关信息

  CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

pcb的组织方式

- 通过链表的方式组织具有相同状态的进程，组成各种队列
- 通过索引方式将统一状态的进程组织在一个索引表中，索引表项指向相应的PCB，不同状态对应不同的索引表

##### 进程的控制

创建、终止、阻塞、挂起

创建

- 申请空白pcb
- 分配资源
- 插入到就绪队列

终止

- 查找需要终止的pcb
- 如果正在执行，终止执行，将cpu资源分配给其他的
- 如果有子进程，分配给1号进程处理
- 归还该进程的资源
- 从队列中删除

阻塞

- 找到对应的pcb
- 如果正在运行，保护现场，转为阻塞，停止运行
- 插入到阻塞队列

唤醒

- 找到对应的pcb
- 从阻塞队列中移除，置为就绪
- 将pcb插入到就绪队列中，等待调度

##### 进程的上下文切换

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。

CPU上下文

- CPu寄存器
- 数据寄存器

CPu上下文切换

​	CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。
​	系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

CPU上下文切换

- 进程上下文切换
  - 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。
  - 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等**用户空间的资源**，还包括了内核堆栈、寄存器**等内核空间的资源。**
  - 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：
  - 发生场景：
    - 时间片耗尽、系统资源不足、sleep、保证高优先级进程运行、发生硬件中断
- 线程上下文切换
- 中断上下文切换

#### 线程

更小的能独立运行的基本单位

##### 为什么使用线程

线程之间可以并发运行且共享相同的地址空间。

##### 什么是线程

优点：

- 一个进程可以同时存在多个线程
- 线程之间可以并发运行
- 线程之间可以共享地址空间和文件等资源

缺点：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃

##### 线程与进程的比较

在前面我们知道了，线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。

##### 有了进程为什么话需要线程

1. 线程更轻量，一个进程可以创建多个线程。
2. 进程切换是一个开销很大的操作，线程切换的成本较低。
3. 同一进程内的线程共享内存和文件，因此它们之间相互通信无须调用内核
4. 多个线程可以并发处理不同的任务，更有效地利用了多处理器和多核计算机。而进程只能在一个时间干一件事，如果在执行过程中遇到阻塞问题比如 IO 阻塞就会挂起直到结果返回。

##### 线程的上下文切换

- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；
- 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

##### 线程的实现

- 用户线程
  - 基于用户态的线程管理库来实现的，tcb也是在库里面的，所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。
  - 优点
    - 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），**TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；**
    - **用户线程的切换也是由线程库函数来完成的，**无需用户态与内核态的切换，所以速度特别快；
  - 缺点
    - 由于操作系统不参与线程的调度**，如果一个线程发起了系统调用而阻塞**，那进程所包含的用户线程都不能执行了。
    - 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行**，因为用户态的线程没法打断当前运行中的线程**，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。
    - 由于时间片分配给进程，故与其他进程比，在多线程执行时，**每个线程得到的时间片较少，**执行会比较慢；
- 内核线程
  - 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。
  - 优点
    - 在一个进程当中，**如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运**行；
    - **分配给线程，多线程的进程获得更多的 CPU 运行时间；**
  - 缺点
    - 在支持内核线程的操作系统中，**由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；**
    - 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，**系统开销比较大；**
- 轻量级线程
  - 轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。
  - 在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。

##### 线程间的同步方式有哪些？

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。

1. 互斥锁(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. 读写锁（Read-Write Lock）：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。
3. 信号量(Semaphore)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
4. 屏障（Barrier）：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。比如 Java 中的 CyclicBarrier 是这种机制。
5. 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

#### 调度

选择一个进程运行

 	在抢占式调度中，操作系统可以在任何时候中断正在运行的进程，并将 CPU分配给另一个处于就绪状态的进程。这意味着，一个高优先级的进程可以随时抢占正在运行的低优先级进程的 CPU时间片。这种方式可以保证高优先级进程得到更快的响应时间，但可能会导致低优先级进程的运行时间不确定。
 	    相反，在非抢占式调度中，一个进程只有在自愿放弃CPU或者因为等待某个事件而被阻塞时，操作系统才会将 CPU分配给另一个进程。这种方式可以保证低优先级进程得到更稳定的运行时间，但可能会导致高优先级进程得不到及时响应。总的来说，抢占式调度适用于实时系统或需要快速响应的场景，而非抢占式调度适用于一些需要稳定运行的应用，如批处理系统。

- 抢占式调度
  - 运行-》就绪
  - 等待-》就绪
- 非抢占式调度
  - 运行-》等待
  - 运行-》终止

调度原则：

cpu利用率、系统吞吐量、周转时间、等待时间、响应时间

### 5.2 进程间有哪些通信方式？

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

每个进程都有自己的用户空间，而**内核空间是每个进程共享**的。因此**进程之间想要进行通信，就需要通过内核**来实现。

- 管道

  - 最简单效率最差
  - 管道不是文件，本质上就是内核中的**一个缓存**，当进程创建一个管道后，Linux会返回**两个文件描述符，**一个是写入端的描述符，一个是输出端的描述符，可以通过这两个描述符往管道写入或者读取数据。
  - 如果想要实现两个进程通过管道来通信，则需要让创建管道的**进程fork子进程**，这样子进程们就拥有了**父进程的文件描述符，**这样子进程之间也就有了**对同一管道的操作**。
  - 缺点：
    - 半双工通信，一条管道只能**一个进程写，一个进程读。**
    - **一个进程写完后，另一个进程才能读**，反之同理。
- 消息队列

  - 优点：
    - 管道的通信方式效率是低下的，不适合进程间频繁的交换数据。A进程往消息队列写入数据后就可以正常返回，B进程**需要时再去读取**就可以了，效率比较高。
    - 数据会被分为一个一个的数据单元，称为**消息体**，消息发送方和接收方约定好消息体的数据类型，不像管道是无格式的字节流类型，这样的好处是可以边发送边接收，而**不需要等待完整的**数据。
  - 缺点
    - 每个**消息体有一个最大长度**的限制，并且**队列所包含消息体的总长度也是有上限**的，这是其中一个不足之处。
    - 消息队列通信过程中存在**用户态和内核态**之间的**数据拷贝问题**。进程往消息队列写入数据时，会发送用户态拷贝数据到内核态的过程，同理读取数据时会发生从内核态到用户态拷贝数据的过程。
- 共享内存

  - 优点：
    - 解决了消息队列存在的内核态和用户态之间数据拷贝的问题。
    - 现代操作系统对于内存管理采用的是**虚拟内存**技术，也就是说每个进程都有自己的虚拟内存空间，虚拟内存映射到真实的物理内存。**共享内存**的机制就是，不同的进程**拿出一块虚拟内存空间，映射到相同的物理内存空间**。这样一个进程写入的东西，另一个进程马上就能够看到，不需要进行拷贝。
- 信号量

  - 使用共享内存的通信方式，如果有**多个进程**同时往共享内存写入数据，有可能先写的进程的内容**被其他进程覆盖了**。因此需要一种保护机制，信号量本质上是一个整型的计数器，用于实现进程间的**互斥**和**同步**。

  - 操作信号量的两种方式

    - P操作：这个操作会将**信号量减一**，相减后信号量如果小于0，则表示资源已经被占用了，进程需要阻塞等待；如果大于等于0，则说明还有资源可用，进程可以正常执行。
    - V操作：这个操作会将**信号量加一**，相加后信号量如果小于等于0，则表明当前有进程阻塞，于是会将该进程唤醒；如果大于0，则表示当前没有阻塞的进程。

  - 信号量实现互斥

    - 信号量初始化为1
    - 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
    - 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
    - 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1

  - 信号量实现同步

    - 信号量初始化为0
    - 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
    - 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
    - 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

- 信号
  - 前面说的进程间通信，都是常规状态下的工作模式。对于**异常情况**下的工作模式，就需要用「信号」的方式来通知进程。
  - 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。
  - **信号是进程间通信机制中唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。
    - 执行默认操作
    - 捕捉信号
    - 忽略信号
- Socket

  - 前面提到的管道，消息队列，共享内存，信号量和信号都是在**同一台主机上**进行进程间通信，如果想要**跨网络和不同主机上的进程**进行通信，则需要用到socket。
  - socket的系统调用    int socket(int domain, int type, int protocal)


### 5.3 多线程冲突怎么办？

#### 竞争与协作

##### 互斥

由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。

##### 同步

所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

#### 互斥与同步的实现和使用 

##### 锁（可以实现进程、线程互斥）

任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。

- 忙等待锁
  - 当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（spin lock）。
- 无忙等待锁
  - 无等待锁顾明思议就是获取不到锁的时候，不用自旋。
  - 既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。

##### 信号量（可以实现进程、线程 互斥+同步）

互斥信号量取值

- 1、0、-1

##### 生产者-消费者问题

生产者在生成数据后，放在一个缓冲区中；
消费者从缓冲区取出数据处理；
任何时刻，只能有一个生产者或消费者可以访问缓冲区；

##### 哲学家就餐

5 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；
巧就巧在，这个桌子只有 5 支叉子，每两个哲学家之间放一支叉子；
哲学家围在一起先思考，思考中途饿了就会想进餐；
奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐；
吃完后，会把两支叉子放回原处，继续思考

##### 读者-写者问题

「读-读」允许：同一时刻，允许多个读者同时读
「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
「写-写」互斥：没有其他写者时，写者才能

### 5.4 怎么避免死锁？

#### 死锁的概念

当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。

死锁只有**同时满足**以下四个条件才会发生：

- 互斥条件；
- 持有并等待条件；
- 不可剥夺条件；
- 环路等待条件

#### 避免死锁问题的发生

那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是**使用资源有序分配法，来破环环路等待条件。**

#### 解决死锁的方法

解决死锁的方法可以从多个角度去分析，一般的情况下，有**预防，避免，检测和解除**四种。

- 预防 **是采用某种策略，限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间上都不满足。
  -  破坏第一个条件 互斥条件：使得资源是可以同时访问的，这是种简单的方法，磁盘就可以用这种方法管理，但是，有很多资源 往往是不能同时访问的 ，所以这种做法在大多数的场合是行不通的。
  - 破坏第三个条件 非抢占：也就是说可以采用 剥夺式调度算法，但剥夺式调度方法目前一般仅适用于 主存资源 和 处理器资源 的分配，并不适用于所有的资源，会导致 资源利用率下降。
  - 所以一般比较实用的 预防死锁的方法，是通过考虑**破坏第二个条件和第四个条件**
    1. **静态分配策略要求进程在开始执行前申请并获得所有需要的资源，**这样可以避免占有并等待的情况，但可能导致资源利用率低下，因为进程可能会占用暂时不使用的资源。
    2. **层次分配策略**通过给资源分配不同的层次来避免循环等待，**进程只能按照从低到高的顺序申请资源，并在释放高层资源前不能释放低层资源，**这样可以防止死锁的发生。
- 避免则是**系统在分配资源时，根据资源的使用情况提前做出预测，**从而避免死锁的发生
  - 系统状态可分为安全状态和不安全状态，安全状态能确保所有进程在有限时间内获取所需资源，而不安全状态则可能导致死锁。为了避免死锁，**可采用Dijkstra的银行家算法，该算法在分配资源前会先试探性分配，并检查系统是否仍处于安全状态**，如果是，则正式分配资源，否则取消试探性分配，让进程继续等待。虽然银行家算法提高了资源利用率，但它需要频繁进行安全性检查，增加了计算开销。

- 检测是指**系统设有专门的机构，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。**
  - 这种方法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 定时地运行一个 “死锁检测” 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它
- 解除 是与检测相配套的一种措施，**用于将进程从死锁状态下解脱出来**
  - **立即结束所有进程的执行，重新启动操作系统**：这种方法简单，但以前所在的工作全部作废，损失很大。
  - **撤销涉及死锁的所有进程，解除死锁后继续运行**：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
  - **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
  - **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。

#### 模拟死锁产生的代码

```java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}
```

output

```java
Thread[线程 1,5,main]get resource1
Thread[线程 2,5,main]get resource2
Thread[线程 1,5,main]waiting get resource2
Thread[线程 2,5,main]waiting get resource1
```

线程 A 通过 `synchronized (resource1)` 获得 `resource1` 的监视器锁，然后通过`Thread.sleep(1000);`让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 `resource2` 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁

### 5.5 什么是悲观锁、乐观锁？

#### 互斥锁与自旋锁

互斥锁

- 互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。
- 对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行

如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。

- 会有两次线程上下文切换的成本：会从用户态陷入到内核态，让内核帮我们切换线程
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

自旋锁

自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；
- caS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行

**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现**

#### 读写锁

公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。

- 读优先锁
- 写优先锁
- 公平读写锁

#### 乐观锁与悲观锁

互斥锁、自旋锁、读写锁，都是属于悲观锁。

- 悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，**所以访问共享资源前，先要上锁。**
- 乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突**，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
  - 你会发现乐观锁全程并没有加锁，所以它也叫无锁编程。
  - 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁

### 5.6 一个进程最多可以创建多少个线程？

与进程的虚拟内存空间上限和系统参数限制有关。

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

### 5.7 线程崩溃了、进程也会崩溃吗？

#### 线程崩溃，进程一定会崩溃吗

一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，各个线程的地址空间是共享的，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃

#### 进程是如何崩溃的-信号机制

1. CPU 执行正常的进程指令
2. 调用 kill 系统调用向进程发送信号
3. 进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统
4. 调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）
5. 操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出

#### 为什么线程崩溃不会导致JVM进程崩溃

因为 JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这NPE和StackoverflowError不让它们崩溃。

### 5.8 僵尸进程和孤儿进程

1. 僵尸进程：**子进程已经终止，但是其父进程仍在运行，且父进程没有调用 wait()或 waitpid()等系统调用来获取子进程的状态信息，释放子进程占用的资源，导致子进程的 PCB 依然存在于系统中，但无法被进一步使用。**这种情况下，子进程被称为“僵尸进程”。避免僵尸进程的产生，父进程需要及时调用 wait()或 waitpid()系统调用来回收子进程。

2. 孤儿进程：**一个进程的父进程已经终止或者不存在，但是该进程仍在运行。**这种情况下，该进程就是孤儿进程。孤儿进程通常是由于父进程意外终止或未及时调用 wait()或 waitpid()等系统调用来回收子进程导致的。为了避免孤儿进程占用系统资源**，操作系统会将孤儿进程的父进程设置为 init 进程**（进程号为 1），由 init 进程来回收孤儿进程的资源。

3. Linux 下可以使用 Top 命令查找，zombie 值表示僵尸进程的数量，为 0 则代表没有僵尸进程。

4. 下面这个命令可以定位僵尸进程以及该僵尸进程的父进程：

   ``ps -A -ostat,ppid,pid,cmd |grep -e '^[Zz]'

## 六、调度算法

### 进程调度算法

![image-20240910163459350](D:\2024\Notes\Typora\八股\计算机系统.assets\image-20240910163459350.png)

### 内存页面置换算法

最佳页面置换算法、先进先出置换算法、最近最久未使用的置换算法、时钟页面置换算法、最不常用算法

### 磁盘调度算法

先来先服务、最短寻道时间优先、扫描算法、循环扫描算法、LOOk\CLook算法

## 七、文件系统

### 7.1 文件系统全家桶

#### 文件系统的基本组成

- Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry）
  - 索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。
  - 目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。
  - 由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别名
  - 目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。
- 目录是个文件，持久化存储在磁盘，而目录项是内核一个数据结构，缓存在内存。

#### 虚拟文件系统

文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。

Linux 支持的文件系统也不少，根据存储位置的不同，可以把文件系统分为三类：

- 磁盘文件系统
- 内存文件系统
- 网络文件系统

#### 文件的使用

操作系统会跟踪进程打开的所有文件，所谓的跟踪呢，就是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「文件描述符」，所以说文件描述符是打开文件的标识。

文件系统的基本操作单位是数据块。

#### 文件的存储

##### 连续空间存放方式

- 文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。
- 连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。

##### 非连续空间存放方式

###### 链表方式

链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。

- ​	「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置.
- ​	隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失
- ​	如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号.
- ​	由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。

###### 索引方式

- 索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。
- 文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。
- 由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。

###### 链表+索引

链式索引块

###### 索引+索引

多级索引块

##### Unix文件的实现方式

- 如果存放文件所需的数据块小于 10 块，则采用直接查找的方式；
  如果存放文件所需的数据块超过 10 块，则采用一级间接索引方式；
  如果前面两种方式都不够存放大文件，则采用二级间接索引方式；
  如果二级间接索引也不够存放大文件，这采用三级间接索引方式；

#### 空闲空间管理

##### 空闲表法

空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。

##### 空闲链表法

我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块

##### 位图法

位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。

#### 文件系统的结构

最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：
超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。
块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。
数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。
inode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。
数据块，包含文件的有用数据。

#### 目录的存储

#### 软连接和硬链接

给某个文件取个别名

- 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。
- 软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。

#### 文件IO

##### 缓冲与非缓冲io

根据「是否利用标准库缓冲」，可以把文件 I/O 分为缓冲 I/O 和非缓冲 I/O：

##### 直接与非直接io

根据是「否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O：

以下几种场景会触发内核缓存的数据写入磁盘：
在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；
用户主动调用 sync，内核缓存会刷到磁盘上；
当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；
内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上

##### 阻塞与非阻塞io    同步与异步io

### 7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗

- 因为进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。
- 内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。
- 我们也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。



- **Page Cache**：主要用于文件系统的缓存，提高读写性能。如果页面未被修改，不需要写回磁盘；如果被修改（脏页），则需要写回。
- **Anonymous pages**：用于非文件映射的内存区域，无论是否被修改，都需要写入交换分区，以防止数据丢失



- swap 机制指的是当物理内存不够用，内存管理单元（Memory Mangament Unit，MMU）需要提供调度算法来回收相关内存空间，然后将清理出来的内存空间给当前内存申请方。
- 所有进程的内存空间之和超过物理内存的部分就需要交换到磁盘上。



- Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。
  - 页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；
  - 块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。



文件 = 数据 + 元数据。元数据用来描述文件的各种属性，也必须存储在磁盘上。因此，我们说保证文件一致性其实包含了两个方面：数据一致+元数据一致。

- Write Through（写穿）：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；
- Write back（写回）：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；
- Write Through 与 Write back 在持久化的可靠性上有所不同：



- fsync(intfd) fsync(fd)：将 fd 代表的文件的脏数据和脏元数据全部刷新至磁盘中。
  fdatasync(int fd)	fdatasync(fd)：将 fd 代表的文件的脏数据刷新至磁盘，同时对必要的元数据刷新至磁盘中，这里所说的必要的概念是指：对接下来访问文件有关键作用的信息，如文件大小，而文件修改时间等不属于必要信息
  sync() sync()：则是对系统中所有的脏的文件数据元数据刷新至磁盘中

## 八、设备管理

### 8.1 键盘键入A字母时，操作系统期间发生了什么？

#### 设备控制器

设备控制器有三类寄存器

- 状态寄存器
- 命令寄存器
- 数据寄存器

输入输出设备

- 块设备
  - 数据缓冲区
- 字符设备

CPu如何与设备的控制寄存器和数据缓冲器通信？

- 端口 I/O，每个控制寄存器被分配一个 I/O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 in/out 类似的指令。
- 内存映射 I/O，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。

#### IO控制方式

- 轮询
- 中断
  - 硬件中断 硬件通过中断控制器触发
  - 软中断 调用int指令触发

#### 设备驱动程序

虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了设备驱动程序。

#### 通用块层

通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：

- 第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；
- 第二功能，通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。

#### 存储系统IO软件分层

可以把 Linux 存储系统的 I/O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层

#### 键盘敲入字母时，期间发生了什么？

## 九、网络系统

### 9.1 什么是零拷贝

什么是 DMA 技术？简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。

要想提高文件传输的性能，

- 就需要减少「用户态与内核态的上下文切换」
  - 减少系统调用的次数
- 和「内存拷贝」的次数。
  - 用户缓冲区是没有必要的

#### 如何实现零拷贝？

- mmap+write
  - 我们可以用 mmap() 替换 read() 系统调用函数，mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。
  - 通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。
- sendfile
  - 前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。
    - 替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。
    - 该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，
  - 只有 2 次上下文切换，和 3 次数据拷贝
- 如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。
  - 零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的
    - 通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
    - 缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里

#### Page Cache的作用

第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（PageCache）。

PageCache 的优点主要是两个：

- 缓存最近被访问的数据；
- 预读功能

#### 大文件传输用什么方式实现

- 异步 I/O 并没有涉及到 PageCache，所以使用异步 I/O 就意味着要绕开 PageCache。
- 绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。
- 在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。

传输大文件的时候，使用「异步 I/O + 直接 I/O」；
传输小文件的时候，则使用「零拷贝技术」

### 9.2 IO多路复用 select/poll/epoll

#### 最基本的Socket模型

- socket\bind\listen\accept
- socket\connect

#### 如何服务更多用户

所以最大 TCP 连接数 = 客户端 IP 数×客户端端口数。

受限制

- 文件描述符
- 系统内存

#### 多进程模型

务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。

#### 多线程模型

当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。

我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。

#### IO多路复用

把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。

我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可

#### select/poll

- select 实现多路复用的方式是**，将已连接的 Socket 都放到一个文件描述符集合**，**然后调用 select 函数将文件描述符集合拷贝到内核里**，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当**检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里**，**然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。**
- 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
- select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。
- poll不用bitsmap，用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

#### epoll

- 第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，
- 第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，

##### 边缘触发和水平触发

边缘触发模式一般和非阻塞 I/O 搭配使用

### 9.3 高性能网络模式：Reactor和Proactor

#### 演进

Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；

#### Reactor

##### 单Reactor单进程/线程

 Java 语言实现的是「单 Reactor 单线程」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。

单进程：

- Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；
- 如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；
- 如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

##### 单Reactor多进程/多线程

多线程：

- Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；
- 子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；

##### 多Reactor多进程/线程

多线程

- 主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；
- 子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。
- 如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

#### Proactor

- 无论 read 和 send 是阻塞 I/O，还是非阻塞 I/O 都是同步调用。因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的
- 而真正的异步 I/O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。

- Proactor 正是采用了异步 I/O 技术，所以被称为异步网络模型。
- Reactor是非阻塞同步网络模型
- Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I/O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。

Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；
Asynchronous Operation Processor 负责处理注册请求，并处理 I/O 操作；
Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor；
Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；
Handler 完成业务处理；

### 9.4 什么是一致性哈希

#### 如何分配请求

轮询-》加权轮询（无法应对分布式系统）-》哈希-》一致性哈希

#### 使用哈希算法有什么问题

如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。

#### 使用一致性哈希算法有什么问题

- 一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。
- 一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。
- 但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。

#### 如何通过虚拟节点提高均衡度

不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。

## 十、Linux命令

### 10.1 如何查看网络的性能指标？

#### 性能指标有哪些？

带宽、延时、吞吐率、PPS

网络可用性、并发连接数、丢包率、重传率

#### 网络配置如何看？

ifconfig、ip

#### socket信息如何查看？

netstat、ss

比如都包含了 socket 的状态（State）、接收队列（Recv-Q）、发送队列（Send-Q）、本地地址（Local Address）、远端地址（Foreign Address）、进程 PID 和进程名称（PID/Program name）等。

- socket处于establish
  - Recv-Q 表示 socket 缓冲区中还没有被应用程序读取的字节数；
    Send-Q 表示 socket 缓冲区中还没有被远端主机确认的字节数；
- socket处于listen
  - Recv-Q 表示全连接队列的长度；
    Send-Q 表示全连接队列的最大长度；

#### 网络吞吐率和PRS如何查看？

sar

- sar -n DEV，显示网口的统计数据；
- sar -n EDEV，显示关于网络错误的统计数据；
- sar -n TCP，显示 TCP 的统计数据

对于带宽，我们可以使用 ethtool 命令来查询

#### 连通性和延时如何查看？

要测试本机与远程主机的连通性和延时，通常是使用 ping 命令，它是基于 ICMP 协议的，工作在网络层。

### 10.2 如何从日志分析PV、UV？

- 先用 ls -lh 命令查看日志文件的大小，如果日志文件大小非常大，最好不要在线上环境做。
- 我们可以使用 `scp` 命令将文件传输到闲置的服务器再分析


- 用 less 命令去读文件里的内容，因为 less 并不会加载整个文件，而是按需加载，先是输出一小页的内容，当你要往下看的时候，才会继续加载。
- 不过，有时候我们想看日志最新部分的内容，可以使用 tail 命令

#### PV分析

pageview 点击量。直接使用 wc -l 命令，就可以查看整体的 PV 了

#### PV分组

awk+sort+uniq

#### UV分析

uniqvisitor 访问人数  我们可以用「客户端 IP 地址」来近似统计 UV。

awk+sort+uniq+wc-l

#### 终端分析

nginx 的 access.log 日志最末尾关于 User Agent 的信息，主要是客户端访问服务器使用的工具，可能是手机、浏览器等。

我们可以利用这一信息来分析有哪些终端访问了服务器

#### 分析TOP3的请求

### 10.3 Linux 常用命令

#### 目录切换

1. `cd usr`：切换到该目录下 usr 目录
2. `cd ..（或cd../）`：切换到上一层目录
3. `cd /`：切换到系统根目录
4. `cd ~`：切换到用户主目录
5. **`cd -`：** 切换到上一个操作所在目录

#### 目录操作

1. `cd usr`：切换到该目录下 usr 目录
2. `cd ..（或cd../）`：切换到上一层目录
3. `cd /`：切换到系统根目录
4. `cd ~`：切换到用户主目录
5. **`cd -`：** 切换到上一个操作所在目录

#### 文件操作

1. 像 mv、cp、rm 等文件和目录都适用的命令，这里就不重复列举了。
2. touch [选项] 文件名..：创建新文件或更新已存在文件（增）。例如：touch file1.txt file2.txt file3.txt ，创建 3 个文件。
3. ln [选项] <源文件> <硬链接/软链接文件>：创建硬链接/软链接。例如：ln -s file.txt file_link，创建名为 file_link 的软链接，指向 file.txt 文件。-s 选项代表的就是创建软链接，s 即 symbolic（软链接又名符号链接） 。
4. cat/more/less/tail 文件名：文件的查看（查） 。命令 tail -f 文件 可以对某个文件进行动态监控，例如 Tomcat 的日志文件， 会随着程序的运行，日志会变化，可以使用 tail -f catalina-2016-11-11.log 监控 文 件的变化 。
5. vim 文件名：修改文件的内容（改）。vim 编辑器是 Linux 中的强大组件，是 vi 编辑器的加强版，vim 编辑器的命令和快捷方式有很多，但此处不一一阐述，大家也无需研究的很透彻，使用 vim 编辑修改文件的方式基本会使用就可以了。在实际开发中，使用 vim 编辑器主要作用就是修改配置文件，下面是一般步骤：vim 文件------>进入文件----->命令模式------>按i进入编辑模式----->编辑文件 ------->按Esc进入底行模式----->输入：wq/q! （输入 wq 代表写入内容并退出，即保存；输入 q!代表强制退出不保存）。

#### 文件压缩

**1）打包并压缩文件：**

Linux 中的打包文件一般是以 `.tar` 结尾的，压缩的命令一般是以 `.gz` 结尾的。而一般情况下打包和压缩是一起进行的，打包并压缩后的文件的后缀名一般 `.tar.gz`。

命令：`tar -zcvf 打包压缩后的文件名 要打包压缩的文件` ，其中：

- z：调用 gzip 压缩命令进行压缩
- c：打包文件
- v：显示运行过程
- f：指定文件名

比如：假如 test 目录下有三个文件分别是：`aaa.txt`、 `bbb.txt`、`ccc.txt`，如果我们要打包 `test` 目录并指定压缩后的压缩包名称为 `test.tar.gz` 可以使用命令：`tar -zcvf test.tar.gz aaa.txt bbb.txt ccc.txt` 或 `tar -zcvf test.tar.gz /test/` 。

**2）解压压缩包：**

命令：`tar [-xvf] 压缩文件`

其中 x 代表解压

示例：

- 将 `/test` 下的 `test.tar.gz` 解压到当前目录下可以使用命令：`tar -xvf test.tar.gz`
- 将 /test 下的 test.tar.gz 解压到根目录/usr 下:`tar -xvf test.tar.gz -C /usr`（`-C` 代表指定解压的位置）

#### 文件传输

1. `scp [选项] 源文件 远程文件` （scp 即 secure copy，安全复制）：用于通过 SSH 协议进行安全的文件传输，可以实现从本地到远程主机的上传和从远程主机到本地的下载。例如：`scp -r my_directory `
2. `user@remote:/home/user` ，将本地目录`my_directory`上传到远程服务器 `/home/user` 目录下。`scp -r user@remote:/home/user/my_directory` ，将远程服务器的 `/home/user` 目录下的`my_directory`目录下载到本地。需要注意的是，`scp` 命令需要在本地和远程系统之间建立 SSH 连接进行文件传输，因此需要确保远程服务器已经配置了 SSH 服务，并且具有正确的权限和认证方式。
3. `rsync [选项] 源文件 远程文件` : 可以在本地和远程系统之间高效地进行文件复制，并且能够智能地处理增量复制，节省带宽和时间。例如：`rsync -r my_directory user@remote:/home/user`，将本地目录`my_directory`上传到远程服务器 `/home/user` 目录下。
4. `ftp` (File Transfer Protocol)：提供了一种简单的方式来连接到远程 FTP 服务器并进行文件上传、下载、删除等操作。使用之前需要先连接登录远程 FTP 服务器，进入 FTP 命令行界面后，可以使用 `put` 命令将本地文件上传到远程主机，可以使用`get`命令将远程主机的文件下载到本地，可以使用 `delete` 命令删除远程主机的文件。这里就不进行演示了。

#### 文件权限

1. 操作系统中每个文件都拥有特定的权限、所属用户和所属组。权限是操作系统用来限制资源访问的机制，在 Linux 中权限一般分为读(readable)、写(writable)和执行(executable)，分为三组。分别对应文件的属主(owner)，属组(group)和其他用户(other)，通过这样的机制来限制哪些用户、哪些组可以对特定的文件进行什么样的操作

2. ![img](D:\2024\Notes\Typora\八股\计算机系统.assets\Linux权限解读-BGnXOuG0.png)

3. **文件的类型：**

   1. d：代表目录
   2. -：代表文件
   3. l：代表软链接（可以认为是 window 中的快捷方式）

4. *Linux 中权限分为以下几种：**

   - r：代表权限是可读，r 也可以用数字 4 表示
   - w：代表权限是可写，w 也可以用数字 2 表示
   - x：代表权限是可执行，x 也可以用数字 1 表示

   **文件和目录权限的区别：**

   对文件和目录而言，读写执行表示不同的意义。

   对于文件：

   | 权限名称 |         可执行操作          |
   | :------: | :-------------------------: |
   |    r     | 可以使用 cat 查看文件的内容 |
   |    w     |     可以修改文件的内容      |
   |    x     |  可以将其运行为二进制文件   |

   对于目录：

   | 权限名称 |        可执行操作        |
   | :------: | :----------------------: |
   |    r     |    可以查看目录下列表    |
   |    w     | 可以创建和删除目录下文件 |
   |    x     |   可以使用 cd 进入目录   |

   需要注意的是：**超级用户可以无视普通用户的权限，即使文件目录权限是 000，依旧可以访问。**

   **在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念。**

   - **所有者(u)**：一般为文件的创建者，谁创建了该文件，就天然的成为该文件的所有者，用 `ls ‐ahl` 命令可以看到文件的所有者 也可以使用 chown 用户名 文件名来修改文件的所有者 。
   - **文件所在组(g)**：当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组用 `ls ‐ahl`命令可以看到文件的所有组也可以使用 chgrp 组名 文件名来修改文件所在的组。
   - **其它组(o)**：除开文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组。

5. **修改文件/目录的权限的命令：`chmod`**

   示例：修改/test 下的 aaa.txt 的权限为文件所有者有全部权限，文件所有者所在的组有读写权限，其他用户只有读的权限。

   **`chmod u=rwx,g=rw,o=r aaa.txt`** 或者 **`chmod 764 aaa.txt

#### 用户管理

1. `useradd [选项] 用户名`:创建用户账号。使用`useradd`指令所建立的帐号，实际上是保存在 `/etc/passwd`文本文件中。
2. `userdel [选项] 用户名`:删除用户帐号。、
3. `usermod [选项] 用户名`:修改用户账号的属性和配置比如用户名、用户 ID、家目录。
4. `passwd [选项] 用户名`: 设置用户的认证信息，包括用户密码、密码过期时间等。。例如：`passwd -S 用户名` ，显示用户账号密码信息。`passwd -d 用户名`: 清除用户密码，会导致用户无法登录。`passwd 用户名`，修改用户密码，随后系统会提示输入新密码并确认密码。
5. `su [选项] 用户名`（su 即 Switch User，切换用户）：在当前登录的用户和其他用户之间切换身份

#### 用户组管理

**Linux 系统用户组的管理相关命令:**

1. `groupadd [选项] 用户组` :增加一个新的用户组。
2. `groupdel 用户组`:要删除一个已有的用户组。
3. `groupmod [选项] 用户组` : 修改用户组的属性

#### 系统状态

1. top [选项]：用于实时查看系统的 CPU 使用率、内存使用率、进程信息等。
2. htop [选项]：类似于 top，但提供了更加交互式和友好的界面，可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。
3. uptime [选项]：用于查看系统总共运行了多长时间、系统的平均负载等信息。
4. vmstat [间隔时间] [重复次数]：vmstat （Virtual Memory Statistics） 的含义为显示虚拟内存状态，但是它可以报告关于进程、内存、I/O 等系统整体运行状态。
5. free [选项]：用于查看系统的内存使用情况，包括已用内存、可用内存、缓冲区和缓存等。
6. df [选项] [文件系统]：用于查看系统的磁盘空间使用情况，包括磁盘空间的总量、已使用量和可用量等，可以指定文件系统上。例如：df -a，查看全部文件系统。
7. du [选项] [文件]：用于查看指定目录或文件的磁盘空间使用情况，可以指定不同的选项来控制输出格式和单位。
8. sar [选项] [时间间隔] [重复次数]：用于收集、报告和分析系统的性能统计信息，包括系统的 CPU 使用、内存使用、磁盘 I/O、网络活动等详细信息。它的特点是可以连续对系统取样，获得大量的取样数据。取样数据和分析的结果都可以存入文件，使用它时消耗的系统资源很小。
9. ps [选项]：用于查看系统中的进程信息，包括进程的 ID、状态、资源使用情况等。ps -ef/ps -aux：这两个命令都是查看当前系统正在运行进程，两者的区别是展示格式不同。如果想要查看特定的进程可以使用这样的格式：ps aux|grep redis （查看包括 redis 字符串的进程），也可使用 pgrep redis -a。
10. systemctl [命令] [服务名称]：用于管理系统的服务和单元，可以查看系统服务的状态、启动、停止、重启等

#### 网络通信

1. `ping [选项] 目标主机`：测试与目标主机的网络连接。
2. `ifconfig` 或 `ip`：用于查看系统的网络接口信息，包括网络接口的 IP 地址、MAC 地址、状态等
3. `netstat [选项]`：用于查看系统的网络连接状态和网络统计信息，可以查看当前的网络连接情况、监听端口、网络协议等。
4. `ss [选项]`：比 `netstat` 更好用，提供了更快速、更详细的网络连接信息

#### 其他

1. `sudo + 其他命令`：以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。
2. `grep 要搜索的字符串 要搜索的文件 --color`：搜索命令，--color 代表高亮显示。
3. `kill -9 进程的pid`：杀死进程（-9 表示强制终止）先用 ps 查找进程，然后用 kill 杀掉。
4. `shutdown`：`shutdown -h now`：指定现在立即关机；`shutdown +5 "System will shutdown after 5 minutes"`：指定 5 分钟后关机，同时送出警告信息给登入用户。
5. `reboot`：`reboot`：重开机。`reboot -w`：做个重开机的模拟（只有纪录并不会真的重开机）

### 10.4 Linux文件系统

#### inode 介绍

inode 是 Linux/Unix 文件系统的基础。那 inode 到是什么?有什么作用呢?

通过以下五点可以概括 inode 到底是什么：

1. 硬盘的最小存储单位是扇区(Sector)，块(block)由多个扇区组成。文件数据存储在块中。块的最常见的大小是 4kb，约为 8 个连续的扇区组成（每个扇区存储 512 字节）。一个文件可能会占用多个 block，但是一个块只能存放一个文件。虽然，我们将文件存储在了块(block)中，但是我们还需要一个空间来存储文件的 元信息 metadata：如某个文件被分成几块、每一块在的地址、文件拥有者，创建时间，权限，大小等。这种 存储文件元信息的区域就叫 inode，译为索引节点：i（index）+node。 每个文件都有一个唯一的 inode，存储文件的元信息。
2. inode 是一种固定大小的数据结构，其大小在文件系统创建时就确定了，并且在文件的生命周期内保持不变。
3. inode 的访问速度非常快，因为系统可以直接通过 inode 号码定位到文件的元数据信息，无需遍历整个文件系统。
4. inode 的数量是有限的，每个文件系统只能包含固定数量的 inode。这意味着当文件系统中的 inode 用完时，无法再创建新的文件或目录，即使磁盘上还有可用空间。因此，在创建文件系统时，需要根据文件和目录的预期数量来合理分配 inode 的数量。
5. 可以使用 stat 命令可以查看文件的 inode 信息，包括文件的 inode 号、文件类型、权限、所有者、文件大小、修改时间。

简单来说：inode 就是用来维护某个文件被分成几块、每一块在的地址、文件拥有者，创建时间，权限，大小等信息。

再总结一下 inode 和 block：

1. inode：记录文件的属性信息，可以使用 stat 命令查看 inode 信息。
2. block：实际文件的内容，如果一个文件大于一个块时候，那么将占用多个 block，但是一个块只能存放一个文件。（因为数据是由 inode 指向的，如果有两个文件的数据存放在同一个块中，就会乱套了）

可以看出，Linux/Unix 操作系统使用 inode 区分不同的文件。这样做的好处是，即使文件名被修改或删除，文件的 inode 号码不会改变，从而可以避免一些因文件重命名、移动或删除导致的错误。同时，inode 也可以提供更高的文件系统性能，因为 inode 的访问速度非常快，可以直接通过 inode 号码定位到文件的元数据信息，无需遍历整个文件系统。

不过，使用 inode 号码也使得文件系统在用户和应用程序层面更加抽象和复杂，需要通过系统命令或文件系统接口来访问和管理文件的 inode 信息。

#### 硬链接和软链接

在 Linux/类 Unix 系统上，文件链接（File Link）是一种特殊的文件类型，可以在文件系统中指向另一个文件。常见的文件链接类型有两种：
1、硬链接（Hard Link）

- 在 Linux/类 Unix 文件系统中，每个文件和目录都有一个唯一的索引节点（inode）号，用来标识该文件或目录。硬链接通过 inode 节点号建立连接，硬链接和源文件的 inode 节点号相同，两者对文件系统来说是完全平等的（可以看作是互为硬链接，源头是同一份文件），删除其中任何一个对另外一个没有影响，可以通过给文件设置硬链接文件来防止重要文件被误删。
- 只有删除了源文件和所有对应的硬链接文件，该文件才会被真正删除。
- 硬链接具有一些限制，不能对目录以及不存在的文件创建硬链接，并且，硬链接也不能跨越文件系统。
- ln 命令用于创建硬链接。

2、软链接（Symbolic Link 或 Symlink）

- 软链接和源文件的 inode 节点号不同，而是指向一个文件路径。
- 源文件删除后，软链接依然存在，但是指向的是一个无效的文件路径。
- 软连接类似于 Windows 系统中的快捷方式。
- 不同于硬链接，可以对目录或者不存在的文件创建软链接，并且，软链接可以跨越文件系统。
- ln -s 命令用于创建软链接。

硬链接为什么不能跨文件系统？
	

​	我们之前提到过，硬链接是通过 inode 节点号建立连接的，而硬链接和源文件共享相同的 inode 节点号。
​	然而，每个文件系统都有自己的独立 inode 表，且每个 inode 表只维护该文件系统内的 inode。如果在不同的文件系统之间创建硬链接，可能会导致 inode 节点号冲突的问题，即目标文件的 inode 节点号已经在该文件系统中被使用。

#### Linux 文件类型

Linux 支持很多文件类型，其中非常重要的文件类型有: 普通文件，目录文件，链接文件，设备文件，管道文件，Socket 套接字文件 等。

- 普通文件（-）：用于存储信息和数据， Linux 用户可以根据访问权限对普通文件进行查看、更改和删除。比如：图片、声音、PDF、text、视频、源代码等等。
- 目录文件（d，directory file）：目录也是文件的一种，用于表示和管理系统中的文件，目录文件中包含一些文件名和子目录名。打开目录事实上就是打开目录文件。
- 符号链接文件（l，symbolic link）：保留了指向文件的地址而不是文件本身。
- 字符设备（c，char）：用来访问字符设备比如键盘。
- 设备文件（b，block）：用来访问块设备比如硬盘、软盘。
- 管道文件(p，pipe) : 一种特殊类型的文件，用于进程之间的通信。
- 套接字文件(s，socket)：用于进程间的网络通信，也可以用于本机之间的非网络通信。
- 每种文件类型都有不同的用途和属性，可以通过命令如ls、file等来查看文件的类型信息。

```bash
# 普通文件（-）

-rw-r--r-- 1 user  group  1024 Apr 14 10:00 file.txt

# 目录文件（d，directory file）*

drwxr-xr-x 2 user  group  4096 Apr 14 10:00 directory/

# 套接字文件(s，socket)

srwxrwxrwx 1 user  group    0 Apr 14 10:00 socket
```

#### Linux 目录树

Linux 使用一种称为目录树的层次结构来组织文件和目录。目录树由根目录（/）作为起始点，向下延伸，形成一系列的目录和子目录。每个目录可以包含文件和其他子目录。结构层次鲜明，就像一棵倒立的树。
常见目录说明：

- /bin： 存放二进制可执行文件(ls、cat、mkdir 等)，常用命令一般都在这里；
- /etc： 存放系统管理和配置文件；
- /home： 存放所有用户文件的根目录，是用户主目录的基点，比如用户 user 的主目录就是/home/user，可以用~user 表示；
- /usr： 用于存放系统应用程序；
- /opt： 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把 tomcat 等都安装到这里；
- /proc： 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息；
- /root： 超级用户（系统管理员）的主目录（特权阶级^o^）；
- /sbin: 存放二进制可执行文件，只有 root 才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如 ifconfig 等；
- /dev： 用于存放设备文件；
- /mnt： 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统；
- /boot： 存放用于系统引导时使用的各种文件；
- /lib 和/lib64： 存放着和系统运行相关的库文件 ；
- /tmp： 用于存放各种临时文件，是公用的临时文件存储点；
- /var： 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等；
- /lost+found： 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows 下叫什么.chk）就在这里。























