# 自我介绍 

面试官您好，我是来自西安邮电大学计算机科学与技术专业的一名大三学生。
首先我来介绍一下我的大学经历：

在大一期间，我加入了我们学校的兴趣编程小组：软件科技协会，
在加入协会后我相继学习了c语言，数据结构与算法等基础知识，
参加了数模，蓝桥杯，程序设计天梯赛，并取得了一些奖项。
在校期间我也参与了四六级考试，获得了均分620+的成绩。

进入大二后我选择我们协会后台开发方向中的java方向，开始接触javaweb，
也学习了spring，springboot等框架、mysql，redis等数据库，
rabbitMQ等中间件和操作系统，计算机网络，等计算机基础知识。

学习期间我自己开发独立开发了一些项目，目前感觉自己的开发能力还是比较有限，
希望能在贵公司进一步提升自己的开发能力和项目经验，谢谢面试官。

## 未来规划

希望能在这个业务领域里深耕,在未来3-5年内有一定的行业认可度; 
技术栈继续沉淀,空余时间研究些底层源码,
了解下目前的AI 大模型相的技术及应用方向

# 专业技能

- Java：熟悉Java基础知识、Java并发编程，掌握JUC中常用的工具类，如ConcurrentHashMap等。

- JVM：熟悉JVM的垃圾回收机制、类加载机制，了解Java的内存模型。

- MySQL：熟练使用 MySQL，熟悉 MySQL 索引、事务、存储引擎、锁机制。

- Redis：熟悉Redis常见数据类型，熟悉持久化和过期淘汰策略，掌握缓存穿透、缓存击穿、缓存雪崩。

- 常用框架：熟练使用Spring、SpringBoot、MyBatis等常用框架，熟悉 IoC 、AOP 原理，了解 Netty、

  Zookeeper、RabbitMQ等常见组件。

- 计算机网络：熟悉TCP/IP四层体系分层结构，掌握常见网络协议，如HTTP/HTTPS、TCP等。

- 操作系统：了解操作系统的进程管理、同步机制、虚拟内存等基础知识。

## ConcurrentHashMap

- ConcurrentHashMap是一个**线程安全**的HashMap

- **HashMap**

  - JDK1.8之前由数组+链表组成
    - 数组是主体
    - 链表是为了解决哈希冲突存在的
  - JDK1.8之后更新解决冲突的办法
    - 链表长度大于阈值（默认为8）
      - 当前数组长度小于64 
        - 进行数组扩容
      - 将链表转化为红黑树

- **Concurrent HashMap**

  - JDL1.8之前，使用**segment数组+HashEntry数组+链表**的底层数据结构，
    Segment 的每个元素包含一个 HashEntry 数组，每个 HashEntry 数组属于链表结构。
    Segment 继承了 ReentrantLock, 是一种可重入锁。HashEntry 用于存储键值对数据。
    每一把segment锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。

  - JDK1.8 的时候，摒弃了 Segment，**用 Node 数组+链表+红黑树的数据结构来实现，**

    - Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。当冲突链表达到一定长度时，链表会转换成红黑树。
    - 存储红黑树节点TreeNode被TreeBin包装。
      TreeBin通过root属性维护红黑树的根结点，因为红黑树在旋转的时候，根结点可能会被它原来的子节点替换掉，在这个时间点，如果有其他线程要写这棵红黑树就会发生线程不安全问题，
      所以在 ConcurrentHashMap 中TreeBin通过waiter属性维护当前使用这棵红黑树的线程，来防止其他线程的进入。
    - 锁粒度更细，**synchronized 只锁定当前链表或红黑二叉树的首节点**，只要 hash 不冲突，就不会产生并发，不会影响其他 Node 读写，效率提升。

  - JDK 1.8 主**要通过 volatile + CAS 或者 synchronized 来实现的线程安全的**。

    添加元素时**首先会判断容器是否为空：**

    1. **如果为空则使用 volatile 加 CAS 来初始化**
       如果容器不为空，则根据存储的元素**计算该位置是否为空。**
    2. **如果根据存储的元素计算结果为空，则利用 CAS 设置该节点；**
       1. 如果根据存储的元素计算结果不为空，**则使用 synchronized锁定当前链表或者红黑二叉树的首节点**，然后，遍历桶中的数据，并替换或新增节点到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。
       2. JDK 1.8 使用的是红黑树优化了之前的固定链表，当数据量比较大的时候，查询性能也得到提升，从 **O(n) 优化到了 O(logn) 的**时间复杂度。

- **LinkedHashMap：LinkedHashMap 继承自 HashMap，**增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑
- **Hashtable：数组+链表组成的，数组是 Hashtable 的主体，链表则主要为解决哈希冲突而存在的。**

## ConcurrentHashMap源码

[ConcurrentHashMap 源码分析 | JavaGuide](https://javaguide.cn/java/collection/concurrent-hash-map-source-code.html)

### 1.7 存储结构

ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 **Segment 的个数一旦初始化就不能改变**，默认 Segment 的个数是 16 个，也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发处理。

### 1.7 初始化

1. 对初始化容量、负载因子、默认并发级别进行参数校验

2. 校验并发级别 concurrencyLevel 大小，如果大于最大值，重置为最大值。无参构造默认值是 16.

3. 寻找并发级别 concurrencyLevel 之上最近的 2 的幂次方值，作为初始化容量大小，默认是 16。

4. 记录 segmentShift 偏移量，这个值为【容量 = 2 的 N 次方】中的 N，在后面 Put 时计算位置时会用到。默认是 32 - sshift = 28.

   > segmentShift记录的是每个段(segment)的哈希码空间的左移位数，它决定了如何根据哈希码来计算元素应该放置在哪一个段中

5. 记录 segmentMask，默认是 ssize - 1 = 16 -1 = 15.

   > segmentMask是用来辅助计算元素应该放置在哪个段的位置

6. 初始化 segments[0]，默认大小为 2，负载因子 0.75，扩容阀值是 2*0.75=1.5，插入第二个值时才会进行扩容

### 1.7 put

1. **计算要 put 的 key 的位置，获取指定位置的 Segment。**

2. **如果指定位置的 Segment 为空，则初始化这个 Segment.**

   初始化 Segment 流程：

   1. 检查计算得到的位置的 Segment 是否为 null.
   2. 为 null 继续初始化，使用 Segment[0] 的容量和负载因子创建一个 HashEntry 数组。
   3. 再次检查计算得到的指定位置的 Segment 是否为 null.
   4. 使用创建的 HashEntry 数组初始化这个 Segment.
   5. 自旋判断计算得到的指定位置的 Segment 是否为 null，使用 CAS 在这个位置赋值为 Segment.

3. **Segment.put 插入 key,value 值。**

   由于 Segment 继承了 ReentrantLock，所以 Segment 内部可以很方便的获取锁，put 流程就用到了这个功能。

   1. tryLock() 获取锁，获取不到使用 scanAndLockForPut 方法继续获取。

   2. 计算 put 的数据要放入的 index 位置，然后获取这个位置上的 HashEntry 。

   3. 遍历 put 新元素，为什么要遍历？因为这里获取的 HashEntry 可能是一个空元素，也可能是链表已存在，所以要区别对待。
      如果这个位置上的 HashEntry 不存在：

      1. 如果当前容量大于扩容阀值，小于最大容量，进行扩容。
      2. 直接头插法插入。

      如果这个位置上的 HashEntry 存在：

      1. 判断链表当前元素 key 和 hash 值是否和要 put 的 key 和 hash 值一致。一致则替换值
      2. 不一致，获取链表下一个节点，直到发现相同进行值替换，或者链表表里完毕没有相同的。
         1. 如果当前容量大于扩容阀值，小于最大容量，进行扩容。
         2. 直接链表头插法插入。

4. **如果要插入的位置之前已经存在，替换后返回旧值，否则返回 null.**
   这里面的第一步中的 scanAndLockForPut 操作这里没有介绍，这个方法做的操作就是不断的自旋 tryLock() 获取锁。当自旋次数大于指定次数时，使用 lock() 阻塞获取锁。在自旋时顺表获取下 hash 位置的 HashEntry。

### 1.7 扩容rehash

ConcurrentHashMap 的扩容只会扩容到原来的两倍。
老数组里的数据移动到新的数组时，位置要么不变，要么变为 `index+ oldSize`，参数里的 node 会在扩容之后使用链表**头插法**插入到指定位置。

- 如果元素的哈希值与旧数组的大小（oldSize）进行计算后的结果使得它落在了原来的位置，那么这个元素的新位置就不会改变。
  如果元素的哈希值经过某种运算后，使得它需要移动到新位置，那么这个新位置可以通过原来的索引加上旧数组的大小（index + oldSize）来计算得出。

### 1.7 get

- 计算得到 key 的存放位置。
- 遍历指定位置查找相同 key 的 value 值。

### 1.8 存储结构

### 1.8 初始化initTable

从源码中可以发现 `ConcurrentHashMap` 的初始化是通过**自旋和 CAS** 操作完成的。里面需要注意的是变量 `sizeCtl` （sizeControl 的缩写），它的值决定着当前的初始化状态。

1. -1 说明正在初始化，其他线程需要自旋等待
2. -N 说明 table 正在进行扩容，高 16 位表示扩容的标识戳，低 16 位减 1 为正在进行扩容的线程数
3. 0 表示 table 初始化大小，如果 table 没有初始化
4. \>0 表示 table 扩容的阈值，如果 table 已经初始化

### 1.8 put

1. 根据 key 计算出 hashcode 。
2. 判断是否需要进行初始化。
3. 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
4. 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。
5. 如果都不满足，则利用 synchronized 锁写入数据。
6. 如果数量大于 TREEIFY_THRESHOLD 则要执行树化方法，在 treeifyBin 中会首先判断当前数组长度 ≥64 时才会将链表转换为红黑树

### 1.8 get

1. 根据 hash 值计算位置。
2. 查找到指定位置，如果头节点就是要找的，直接返回它的 value.
3. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。
4. 如果是链表，遍历查找

## 垃圾回收机制

**垃圾回收（Garbage Collection, GC）是自动管理内存的一种机制，**它负责自动释放不再被程序引用的对象所占用的内存。



### 垃圾回收触发

- **内存不足时：**当JVM检测到堆内存不足，无法为新的对象分配内存时，会自动触发垃圾回收。
- **手动请求：**虽然垃圾回收是自动的，开发者可以通过调用 System.gc() 或 Runtime.getRuntime().gc() 建议 JVM 进行垃圾回收。不过这只是一个建议，并不能保证立即执行。
- JVM参数：启动 Java 应用时可以**通过 JVM 参数来调整垃圾回收的行为，**比如：-Xmx（最大堆大小）、-Xms（初始堆大小）等。
- **对象数量或内存使用达到阈值**：垃圾收集器内部实现了一些策略，以监控对象的创建和内存使用，达到某个阈值时触发垃圾回收



### 垃圾收集算法

1. 标记-清除算法

标记-清除（Mark-and-Sweep）算法分为“标记（Mark）”和“清除（Sweep）”阶段：首先通过可达性分析，**标记出所有需要回收的对象，然后统一回收所有被标记的对象。**

- 效率问题：标记和清除两个过程**效率都不高。**
- 空间问题：标记清除后**会产生大量不连续的内存碎片。**

2. 复制算法

为了解决标记-清除算法的效率和内存碎片问题，复制（Copying）收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。**当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。**这样就使每次的内存回收都是对内存区间的一半进行回收。

- **可用内存变小**：可用内存缩小为原来的一半。
- **不适合老年代：**如果存活对象数量比较大，复制性能会变得很差。

3. 标记-整理（压缩）算法

标记-整理（Mark-and-Compact）算法是**根据老年代的特点提出的一种标记算法**，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是**让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。**

4. 分代收集算法

当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，**只是根据对象存活周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。**

比如**在新生代中，每次收集都会有大量对象死去，所以可以选择“复制”算法**，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而**老年代的对象存活几率是比较高的**，而且没有额外的空间对它进行分配担保，所以我们必须选择“**标记-清除”或“标记-整理”算法进行垃圾收集。**



### minorGC、majorGC、fullGC的区别，什么场景触发fullGC

在Java中，垃圾回收机制是自动管理内存的重要组成部分。根据其作用范围和触发条件的不同，可以将GC分为三种类型：Minor GC（也称为Young GC）、Major GC（有时也称为Old GC）、以及Full GC。以下是这三种GC的区别和触发场景：

- Minor GC (Young GC)

  - 作用范围：只**针对年轻代进行回收，包括Eden区和两个Survivor区（S0和S1）。**
  - 触发条件：**当Eden区空间不足时，JVM会触发一次Minor GC，将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代（Old Generation）**。
  - 特点：通常发生得非常频繁，因为年轻代中对象的生命周期较短，回收效率高，暂停时间相对较短。

- Major GC

  - 作用范围：**主要针对老年代进行回收，但不一定只回收老年代**。
  - 触发条件：当老年代空间不足时，或者系统检测到年轻代对象晋升到老年代的速度过快，可能会触发Major GC。
  - 特点：相比Minor GC，Major GC发生的频率较低，但每次回收可能需要更长的时间，因为老年代中的对象存活率较高。

- Full GC

  - 作用范围：**对整个堆内存（包括年轻代、老年代以及永久代/元空间）进行回收。**

  - 触发条件：

    - **直接调用System.gc()或Runtime.getRuntime().gc()方法时，虽然不能保证立即执行，但JVM会尝试执行Full GC。**
    - Minor GC（新生代垃圾回收）时**，如果存活的对象无法全部放入老年代，或者老年代空间不足以容纳存活的对象，则会触发Full GC，对整个堆内存进行回收。**
    - **当永久代（Java 8之前的版本）或元空间（Java 8及以后的版本）空间不足时**。

  - 特点：Full GC是最昂贵的操作，因为它需要停止所有的工作线程（Stop The World），遍历整个堆内存来查找和回收不再使用的对象，因此应尽量减少Full GC的触发

    

### 垃圾收集算法

![image-20241018172612193](D:\2024\Notes\Typora\项目rpc+im\image-20241018172612193.png)

### G1和CMS区别

##### CMS和G1区别？

1. 区别一：使用的范围不一样：

   **CMS收集器是老年代的收集器，**可以配合新生代的Serial和ParNew收集器一起使用

   **G1收集器收集范围是老年代和新生代。**不需要结合其他收集器使用

2. 区别二：STW的时间：

   **CMS收集器以最小的停顿时间为目标的收集器**。

   **G1收集器可预测垃圾回收 (opens new window)的停顿时间**（建立可预测的停顿时间模型）

3. 区别三： 垃圾碎片

   CMS收集器是使用“**标记-清除”算法进行的垃圾回收，容易产生内存碎片**

   G1收集器使用的是“**标记-整理”算法，进行了空间整合，没有内存空间碎**片。

4. 区别四： **垃圾回收的过程不一样**

   CMS收集器：初始标记、并发标记、重新标记、并发清楚

   G1收集器：初始标记、并发标记、最终标记、筛选回收

5. 区别五: CMS会产生浮动垃圾
   **CMS产生浮动垃圾过多时会退化为serial old**，效率低，因为在上图的第四阶段，CMS清除垃圾时是并发清除的，这个时候，垃圾回收线程和用户**线程同时工作会产生浮动垃圾，也**就意味着CMS垃圾回收器必须预留一部分内存空间用于存放浮动垃圾
   而G1没有浮动垃圾，**G1的筛选回收是多个垃圾回收线程并行gc的，没有浮动垃圾的回收，在执行‘并发清理’步骤时，用户线程也会同时产生一部分可回收对象，但是这部分可回收对象只能在下次执行清理是才会被回收**。如果在清理过程中预留给用户线程的内存不足就会出现‘Concurrent Mode Failure’,一旦出现此错误时便会切换到SerialOld收集方式

## 类加载机制

### 类加载过程

#### 加载

1. **通过全类名获取定义此类的二进制字节流。**
2. **将字节流所代表的静态存储结构转换为方法区的运行时数据结构。**
3. 在**内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口。**

加载这一步主要是通过我们后面要讲到的 **类加载器** 完成的。类加载器有很多种，当我们想要加载一个类的时候，具体是**哪个类加载器加载由 双亲委派模型 决定**

#### 验证

验证是连接阶段的第一步，这一阶段的目的是确保 Class 文件的字节流中包含的信息符合《Java 虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。

1. **文件格式验证**（Class 文件格式检查）
2. **元数据验证**（字节码语义检查）
3. **字节码验证**（程序语义检查）
4. **符号引用验证**（类的正确性检查）

#### 准备

准备阶段是正式为类变量分配内存并设置类变量初始值的阶段

#### 解析

解析阶段是虚拟机将常量池内的**符号引用替换为直接引用的**过程

#### 初始化

初始化阶段是执行初始化方法 <clinit> ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。

#### 类卸载

卸载类即该类的 Class 对象被 GC。
卸载类需要满足 3 个要求:

- 该类的**所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。**
- 该类**没有在其他任何地方被引用**
- 该类的类加载器的**实例已被 GC**

所以，在 JVM 生命周期内**，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。**

### 类加载器详解

#### 类加载器

##### 类加载器介绍

类加载器的主要作用是**加载 Java 类的字节码（ .class 文件）到 JVM 中（**在内存中生成一个代表该类的 Class 对象）。

- 类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步。
- **每个 Java 类都有一个引用指向加载它的 ClassLoader。**
- **数组类不是通过 ClassLoader 创建的**（数组类没有对应的二进制字节流），**是由 JVM 直接生成**

##### 类加载器加载规则

- JVM 启动的时候，并不会一次性加载所有的类，**而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载，这样对内存更加友好。**
- 对于已经加载的类会被放在 ClassLoader 中。在类加载的时候，系统**会首先判断当前类是否被加载过**。已经被加载的类会直接返回，否则才会尝试加载。也就是说，对于一个类加载器来说，相同二进制名称的类只会被加载一次。

##### 类加载器总结

- **BootstrapClassLoader(启动类加载器)：**最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要**用来加载 JDK 内部的核心类库**（ %JAVA_HOME%/lib目录下的 rt.jar、resources.jar、charsets.jar等 jar 包和类）以及被 -Xbootclasspath参数指定的路径下的所有类。
- **ExtensionClassLoader(扩展类加载器)**：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类以及被 java.ext.dirs 系统变量所指定的路径下的所有类。
- **SystemClassLoader系统类加载器/AppClassLoader(应用程序类加载器)**：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。
- 用户自定义类加载器

> 这些类加载器之间的关系形成了**双亲委派模型，其核心思想是当一个类加载器收到类加载的请求时，首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中。**
> 只有**当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载**

除了 BootstrapClassLoader 是 JVM 自身的一部分之外，其他所有的类加载器都是在 JVM 外部实现的，并且全都继承自 ClassLoader抽象类。这样做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。

为什么 获取到 ClassLoader 为null就是 BootstrapClassLoader 加载的呢？ 这是因为BootstrapClassLoader 由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null。

##### 自定义类加载器

- 除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。如果我们要自定义自己的类加载器，很明显需要继承 ClassLoader抽象类。
- ClassLoader 类有两个关键的方法：
  - protected Class loadClass(String name, boolean resolve)：**加载指定二进制名称的类，实现了双亲委派机制** 。name 为类的二进制名称，resolve 如果为 true，在加载时调用 resolveClass(Class<?> c) 方法解析该类。
  - protected Class findClass(String name)：根据类的二进制名称来查找类，默认实现是空方法。
  - 如果我们不**想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可**，无法被父类加载器加载的类最终会通过这个方法被加载。但是，**如果想打破双亲委派模型则需要重写 loadClass()** 方法。

#### 双亲委派模型

##### 双亲委派模型介绍

- ClassLoader 类使用委托模型来搜索类和资源。
- 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。
- ClassLoader 实例会在试图亲自查找类或资源之前，将搜索类或资源的任务委托给其父类加载器。

​		**自顶向下尝试加载类、自底向上查找判断类是否被加载**

- 类加载器之间的父子关系一般不是以继承的关系来实现的，而是**通常使用组合关系来复用父加载器的代码。**
- 在面向对象编程中，有一条非常经典的设计原则：**组合优于继承，多用组合少用继承**

##### 执行流程

1. 在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载（每个父类加载器都会走一遍这个流程）。
2. 类加载器在进行类加载的时候，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成（调用父加载器 loadClass()方法来加载类）。这样的话，所有的请求最终都会传送到顶层的启动类加载器 BootstrapClassLoader 中。
3. 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 findClass() 方法来加载类）。
4. 如果子类加载器也无法加载这个类，那么它会抛出一个 ClassNotFoundException 异常

JVM 判定两个 Java 类是否相同的具体规则：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。

##### 好处

1. **保证类的唯一性：**通过委托机制，确保了所有加载请求都会传递到启动类加载器，避免了不同类加载器重复加载相同类的情况，**保证了Java核心类库的统一性，也防止了用户自定义类覆盖核心类库的可能。**
2. **保证安全性**：由于Java核心库被启动类加载器加载，而启动类加载器只加载信任的类路径中的类，这样可以**防止不可信的类假冒核心类**，增强了系统的安全性。例如，恶意代码无法自定义一个java.lang.System类并加载到JVM中，因为这个请求会被委托给启动类加载器，而启动类加载器只会加载标准的Java库中的类。
3. **支持隔离和层次划分**：双亲委派模型支持不同层次的类加载器服务于不同的类加载需求，如应用程序类加载器加载用户代码，扩展类加载器加载扩展框架，启动类加载器加载核心库。这种层次化的划分有助于实现沙箱安全机制，保证了各个层级类加载器的职责清晰，也便于维护和扩展。
4. **简化了加载流程**：通过委派，大部分类能够被正确的类加载器加载，减少了每个加载器需要处理的类的数量，简化了类的加载过程，提高了加载效率

##### 打破双亲委派模型方法

**如果想打破双亲委派模型则需要重写父类 loadClass()** 方法。

## Java的内存模型

在虚拟机自动内存管理机制下， Java 程序员**把内存控制权利交给 Java 虚拟机**

JDK1.7 

- - 线程共享
    - 堆
      - 字符串常量池
    - 方法区
      - 运行时常量池
  - 线程私有
    - 虚拟机栈
    - 本地方法栈
    - 程序计数器
  - 本地内存-属于操作系统的本地内存，可以直接操作。
    - 直接内存
- JDK1.8
  - 线程共享
    - 堆
      - 字符串常量池
  - 线程私有不变
    - 虚拟机栈
    - 本地方法栈
    - 程序计数器
  - 本地内存
    - 直接内存
    - 元空间
      - 运行时常量池

### 程序计数器

程序计数器主要有两个作用：

- 字节码解释器**通过改变程序计数器来依次读取指令，从而实现代码的流程控制**，如：顺序执行、选择、循环、异常处理。
- 在多线程的情况下，程序计数器**用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。**

⚠️ 注意：程序计数器是唯一一个**不会出现 OutOfMemoryError** 的内存区域**，它的生命周期随着线程的创建而创建，随着线程的结束而死亡**

### Java虚拟机栈

- Java 虚拟机栈（后文简称栈）也是线程私有的，它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。
- **除了一些 Native 方法调用是通过本地方法栈实现的(后面会提到)，其他所有的 Java 方法调用都是通过栈来实现**的（也需要和其他运行时数据区域比如程序计数器配合）。
- 方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。
  - 每个栈帧中都拥有：**局部变量表、操作数栈、动态链接、方法返回地址**
    - 局部变量表
      - **存放了编译期可知的各种数据类型**
        （boolean、byte、char、short、int、float、long、double）、
      - **对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用**指针**，也可能是指向一个代表对象的**句柄**或其他与此对象相关的位置）。
    - 操作数栈
      - 主要作为方法调用的中转站使用，用于**存放方法执行过程中产生的中间计算结果。**
      - 另外，计算过程中**产生的临时变量也**会放在操作数栈中。
    - 动态链接
      - Class 文件的常量池里保存有大量的符号引用。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用
      - 动态链接的作用就是为了**将符号引用转换为调用方法的直接引用，**这个过程也被称为 动态连接 。
    - 方法返回地址
- 简单总结一下程序运行中栈可能会出现两种错误：
  - StackOverFlowError： 若栈的内存大小**不允许动态扩展**，那么当线程请求栈的深度超过当前 Java 虚拟机栈的**最大深度**的时候，就抛出 StackOverFlowError 错误。
  - OutOfMemoryError： 如果栈的内存大小**可以动态扩展**， 如果虚拟机在动态扩展栈时**无法申请到足够的内存空间**，则抛出OutOfMemoryError异常。

### 本地方法栈

虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而**本地方法栈则为虚拟机使用到的 Native 方法服务**。在 **HotSpot 虚拟机中和 Java 虚拟机栈合二为一。**

### 堆

在**虚拟机启动时创建**。此内存区域的唯一目的就是**存放对象实例**，**几乎**所有的对象实例以及数组都在这里分配内存

- 从 JDK 1.7 开始已经默认开启逃逸分析，**如果某些方法中的对象引用没有被返回或者未被外面使用（**也就是未逃逸出去），那么**对象可以直接在栈上分配内存。**

Java 堆是**垃圾收集器管理的主要区域**，因此也被称作 **GC 堆（Garbage Collected Heap）**

- 由于现在收集器基本都采用**分代垃圾收集算法**，所以 Java 堆还可以细分为：**新生代和老年代；**再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是**更好地回收内存，或者更快地分配内存。**

- JDk7及以前，堆内存被分配为以下部分

  - **新生代内存(Young Generation)**

    - **eden**

      在Eden Space中， 大多数新创建的对象首先存放在这里**。Eden区相对较小，当Eden区满时，会触发一次Minor GC（新生代垃圾回收）**

    - **survivor**

      在Survivor Spaces中，通常分为两个相等大小的区域，称为S0（Survivor 0）和S1（Survivor 1）。

      **在每次Minor GC后，存活下来的对象会被移动到其中一个Survivor空间**，以继续它们的生命周期**。这两个区域轮流充当对象的中转站，帮助区分短暂存活的对象和长期存活的对象。**

  - **老生代(Old Generation)（15岁之后）**

    **存放过一次或多次Minor GC仍存活的对象会被移动到老年代。老年代中的对象生命周期较长，因此Major GC（也称为Full GC，涉及老年代的垃圾回收）发生的频率相对较低，但其执行时间通常比Minor GC长**。老年代的空间通常比新生代大，以存储更多的长期存活对象。

  - **永久代(Permanent Generation)**

- JDK 8 版本之后 **PermGen(永久代) 已被 Metaspace(元空间) 取代，元空间使用的是本地内存。**

  **元空间用于存储类的元数据信息，如类的结构信息（如字段、方法信息等）。**元空间并不在Java堆中，而是使用本地内存，这解决了永久代容易出现的内存溢出问题。

- 大对象区（Large Object Space / Humongous Objects）:**在某些JVM实现中（如G1垃圾收集器），为大对象分配了专门的区域，称为大对象区或Humongous Objects区域。**大对象是指需要**大量连续内存空间的对象**，如大数组。这**类对象直接分配在老年代，以避免因频繁的年轻代晋升而导致的内存碎片化问题。**

#### 字符串常量池

字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

JDK 1.7 为什么要将字符串常量池移动到堆中？

主要是因为**永久代（方法区实现）的 GC 回收效率太低**，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，**将字符串常量池放到堆中，能够更高效及时地回收字符串内存。**

### 方法区

当虚拟机要使用一个类时，它需要**读取并解析 Class 文件获取相关信息，再将信息存入到方法区。**方法区会存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存**等数据。

- **类信息：**包括类的结构信息、类的访问修饰符、父类与接口等信息。
- **常量池**：存储类和接口中的常量，包括字面值常量、符号引用，以及运行时常量池。
- **静态变量**：存储类的静态变量，这些变量在类初始化的时候被赋值。
- **方法字节码**：存储类的方法字节码，即编译后的代码。
- **符号引用**：存储类和方法的符号引用，是一种直接引用不同于直接引用的引用类型。
- **运行时常量池**：存储着在类文件中的常量池数据，在类加载后在方法区生成该运行时常量池。
- **常量池缓**存：用于提升类加载的效率，将常用的常量缓存起来方便使用

- **永久代以及元空间**是 HotSpot 虚拟机对虚拟**机规范中方法区**的两种实现方式
- 并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。
  - 整个**永久代有一个 JVM 本身设置的固定大小上限，无法进行调整**（也就是受到 JVM 内存的限制），而元空间**使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。**
  - **元空间里面存放的是类的元数据**，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由**系统的实际可用空间来控制，这样能加载的类就更多了。**
  - 在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。
  - **永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。**

#### 运行时常量池

Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于**存放编译期生成的**各种**字面量**（Literal）和**符号引用**（Symbolic Reference）的 **常量池表**(Constant Pool Table) 。

常量池表会在类加载后存放到方法区的运行时常量池中.

### 直接内存

直接内存**是一种特殊的内存缓冲区**，并不在 Java 堆或方法区中分配的，而是通过 JNI 的方式在本地内存上分配的。

### Java内存模型里的堆和栈有什么区别？

- 用途**：栈主要用于存储局部变量、方法调用的参数、方法返回地址以及一些临时数据。**每当一个方法被调用，一个栈帧（stack frame）就会在栈中创建，用于存储该方法的信息，当方法执行完毕，栈帧也会被移除。堆**用于存储对象的实例（包括类的实例和数组）。**当你使用new关键字创建一个对象时，对象的实例就会在堆上分配空间。
- 生命周期：栈中的数据具有确定的生命周期，**当一个方法调用结束时，其对应的栈帧就会被销毁，栈中存储的局部变量也会随之消失**。堆**中的对象生命周期不确定，对象会在垃圾回收机制（Garbage Collection, GC）检测到对象不再被引用时才被回收。**
- 存取速度：**栈的存取速度通常比堆快，因为栈遵循先进后出**（LIFO, Last In First Out）的原则，操作简单快速。堆的存取速度相对较慢，因为对象在堆上的分配和回收需要更多的时间，而**且垃圾回收机制的运行也会影响性能。**
- 存储空间：**栈的空间相对较小，且固定，由操作系统管理。当栈溢出时，通常是因为递归过深或局部变量过大**。堆的**空间较大，动态扩展，由JVM管理。**堆溢出通常是由于创建了太多的大对象或未能及时回收不再使用的对象。
- 可见性：**栈中的数据对线程是私有的**，每个线程有自己的栈空间。**堆中的数据对线程是共享的**，所有线程都可以访问堆上的对象

### 内存泄漏和内存溢出的理解？

#### 内存泄漏

内存泄漏是指**程序在运行过程中不再使用的对象仍然被引用，而无法被垃圾收集器回收，从而导致可用内存逐渐减少。**虽然在Java中，垃圾回收机制会自动回收不再使用的对象，**但如果有对象仍被不再使用的引用持有，垃圾收集器无法回收这些内存，最终可能导致程序的内存使用不断增加。**

内存泄漏常见原因?

- 静态集合：**使用静态数据结构（如HashMap或ArrayList）存储对象，且未清理。**
- 事件监听：**未取消对事件源的监听，导致对象持续被引用**。
- 线程：**未停止的线程可能持有对象引用，无法被回收。**

#### 内存溢出

内存溢出是指Java虚拟机（JVM）在申请内存时，无法找到足够的内存，最终引发OutOfMemoryError。这通常**发生在堆内存不足以存放新创建的对象时。**

内存溢出常见原因？

- **大量对象创建**：程序中不断创建大量对象，超出JVM堆的限制。
- **持久引**用：大型数据结构（如缓存、集合等）长时间持有对象引用，导致内存累积。
- **递归调用**：深度递归导致栈溢出

### jvm内存结构有哪几种内存溢出的情况

- **堆内存溢出：**当出现java.lang.OutOfMemoryError:Java heap space异常时，就是堆内存溢出了。原因是**代码中可能存在大对象分配，或者发生了内存泄露，**导致**在多次GC之后，还是无法找到一块足够大的内存容纳当前对象。**
- **栈溢出**：如果我们写一段程序**不断的进行递归调用**，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。
- **元空间溢出：**元空间的溢出，系统会抛出java.lang.OutOfMemoryError: Metaspace。出现这个异常的问题的原因是**系统的代码非常多或引用的第三方包非常多或者通过动态代码生成类加载等方法，**导致元空间的内存占用很大。
- **直接内存内存溢出**：在使用ByteBuffer中的allocateDirect()的时候会用到，很多javaNIO(像netty)的框架中被封装为其他的方法，出现该问题时会抛出java.lang.OutOfMemoryError: Direct buffer memory异常。

## MYSQL索引

### 索引的分类？

- **按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。**
- 为什么InnoDB选择B+tree作为索引的数据结构？
  - b tree：B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。
  - 二叉树：对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。**数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操。**而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。
  - hash：**Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询，它更适合做等值的查**
- **按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）（唯一索引、普通索引、前缀索引都属于二级索引）。**
- **按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。**
- **按「字段个数」分类：单列索引、联合索引。**

### 索引优化和索引失效

- 前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。
- 覆盖索引优化：覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。
- 主键索引最好是自增的：
  - 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。**因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。**
  - 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，**因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。**
- 防止索引失效：
  - 当我们使**用左或者左右模糊匹配**的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；
  - 当我们在查询条件中**对索引列做了计算、函数、类型转换操作，**这些情况下都会造成索引失效；
  - **联合索引要能正确使用需要遵循最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
  - **在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，**那么索引会失效

### **count(*) = count(1)>count(主键字段)>count(字段)**

## MYSQL事务

### 事务有哪些特性？

1. 原子性是通过 **undo log（回滚日志）** 来保证的；
2. 隔离性是通过 **MVCC（多版本并发控制） 或锁机制**来保证的；
3. 持久性是通过 **redo log （重做日志**）来保证的；
4. 一致性则是通过持久性+原子性+隔离性来保证；

### 并行事务会引发什么问题？

#### 脏读

- 如果一个事务「**读到」了另一个「未提交事务修改过的数据」，**就意味着发生了「脏读」现象。
- 即a修改了没提交被b读到

#### 不可重复读

- 在一个事务内多次读取同一个数据，如果出现前后两次读到的**数据不一样**的情况，就意味着发生了「不可重复读」现象。
  - 描述的是在一个事务内，对某条数据的两次**读取**之间，由于其他事务对该数据进**行了修改或删除，导致第一次读取和第二次读取的结果不同。**

- b先读，a提交b再读，前后读取数据不一样

#### 幻读

- 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的**记录数量不一样**的情况，就意味着发生了「幻读」现象。
  - 描述的是在一个事务内，对一组数据（如通过范围查询得到的数据集合）的两次读取之间，**由于其他事务插入了新的数据，**导致第一次**读取**和第二次读取的**结果集数量不同。**

- 前后读取的记录数量不一致

**幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。**执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。

### 事务的隔离级别

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；

- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；

  读提交隔离级别是在**每次读取数据时，都会生成一个新的 Read View。**

- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
  '可重复读隔离级别是**启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。**

- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

  - 实现：是通过行级锁来实现的，序列化隔离级别下，普通的 select 查询是会对记录加 S 型的 next-key 锁，其他事务就没没办法对这些已经加锁的记录进行增删改操作了，从而避免了脏读、不可重复读和幻读现象

### ReadView在MVCC里如何工作？

**当前活跃事务的事务id列表，当前活跃事务id最小的事务，创建readview时数据库给下一个事务的id，该事务的id**

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

1. 如果记录的 **trx_id** 值小于 Read View 中的 **min_trx_id** 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。

2. 如果记录的 trx_id 值大于等于 Read View 中的 **max_trx_id** 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。

3. 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 **m_ids** 列表中：

   1. 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
   2. 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

   这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。

### 可重复读隔离完全解决幻读了吗？

MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种：

- 针对快照读（**普通 select 语句**），**是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。**
- 针对当前读（**select ... for update 等语句**），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。**

**可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。**

- 第一个例子：**对于快照读**， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。
  - 在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。                                                                                                                                                                
  - **即a一开始查id为为5的，b插入一个id为5的，由于mvcc现在看不到，然后a对id为5的进行更新，这个时候b插入的记录隐藏列的值为a的id，对a可见，a再次查询，就和第一次查的不一样。**
- 第二个例子：**对于当前读**，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。
  - **即一开始select，后来b插入，这时selectforupdate**
- 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

## MYSQL存储引擎

| 区别                       | InnoDB                                                       |                            Memory                            | MyISAM                                                       |
| -------------------------- | ------------------------------------------------------------ | :----------------------------------------------------------: | ------------------------------------------------------------ |
| **行级锁**                 | **支持**                                                     |                          **不支持**                          | **不支持，只支持表级别**                                     |
| **事务**                   | **支持，提供四个隔离级别**                                   |                          **不支持**                          | **不支持**                                                   |
| 外键                       | 支持                                                         |                            不支持                            | 不支持                                                       |
| 数据库异常崩溃后的安全恢复 | 支持                                                         | 将数据存储在内存中，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失 | 不支持                                                       |
| MVCC                       | 支持                                                         |                                                              | 不支持                                                       |
| 索**引实现**               | **InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。**<br /><br /><br />Innodb是聚簇索引，聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大 |                                                              | **MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。**<br /><br /><br />myisam是非聚簇为索引，数据文件是分离的，**索引保存的是数据文件的指针。主键索引和辅助索引是独立的。** |
| count的效率****            | **InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描** |                                                              | **MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快** |
| 性能差别                   | 更强大                                                       |                                                              |                                                              |
| 数据缓存策略和机制         | 使用缓冲池（Buffer Pool）缓存数据页和索引页                  |                                                              | 只缓存索引页不缓存数据页                                     |

## MYSQL锁机制

#### 全局锁

- 执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞：
  - 对数据的增删改操作，比如 insert、delete、update等语句；
  - 对表结构的更改操作，比如 alter table、drop table 等语句。
- 会话断开，全局锁自动被释放
- 应用场景
  - 全库逻辑备份
- 加全局锁缺点
  - 数据多-》备份时间长-》只读状态-》业务不能更新数据-》业务停滞
  - 解决办法
    - 如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。
    - 但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。

#### 表级锁

##### 表锁

- 表锁限制别的线程和自己线程的读写
- 会话退出，释放所有锁
- 表锁颗粒度太大，影响并发性能，因此使用颗粒度更细的行级锁

##### 元数据锁（MDL）

- 不需要显式使用，对数据库表进行操作时，会自动给加上MDL
  - CRUD操作加MDL读锁
  - 对表进行结构操作的时候加MDL写锁
- MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。
- 在事务执行期间，MDL一直持有，事务提交后才会释放
- 一个线程因为写锁申请不到的时候，后续的申请读锁的查询操作也会被阻塞
  - 申请MDL锁形成队列，写锁优先级高。
  - 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。

##### 意向锁

- 在遍历对某些记录加上共享锁||独占锁之前，需要先在表级别上加上一个意向共享锁||意向独占锁
- **意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突**，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突。
- 意向锁的目的是为了快速判断表里是否有记录被加锁
- 意向锁是由数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InnoDB 会先获取该数据行所在在数据表的对应意向锁。

##### AUTO-INC锁

- Auto-Inc是特殊的表锁价值，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。

- 在插入数据的时候，可以不指定主键的值，数据库会自动给主键赋值递增的值

- 但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。

  - MySQL5.1.22后，提供了一种轻量级的锁来实现自增
  - 一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，**就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。**

- 通过 innodb_autoinc_lock_mode控制使用什么锁

  - 0

    auto-inc，语句结束后释放锁

  - 1

    - 普通insert语句，使用轻量级锁，申请主键后马上释放
    - insert-select批量插入数据，语句结束后释放

  - 2

    - 轻量级，申请主键后释放
    - 效率最高，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，**在「主从复制的场景」中会发生数据不一致的问题。**
    - 当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题。

#### 行级锁

InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。

- 普通的 select 语句是不会对记录加锁的，因为它属于**快照读。**

- 查询会加锁的语句称为**锁定读。**

  ```mysql
  //对读取的记录加共享锁
  select ... lock in share mode;
  //对读取的记录加独占锁
  select ... for update;
  上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。
  ```

- 共享锁（S锁,Shared lock）满足读读共享，读写互斥。独占锁（X锁,exclusive lock）满足写写互斥、读写互斥。

  - sx不兼容
  - ss兼容
  - xx不兼容

1. Record Lock，记录锁，也就是仅仅把一条记录锁上；
2. Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
3. Next-Key Lock：临键锁，Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身

##### Record Lock

当事务执行 commit 后，事务过程中生成的锁都会被释放。

##### Gap Lock

- Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。
- **间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的**，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。

##### Next-Key Lock

- next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中
- **next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。**

##### 插入意向锁

- 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。
- 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。
- 会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁）。此时事务 B 就会发生阻塞，直到事务 A 提交了事务。
- 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。

## Redis常见数据类型

|  数据类型   |                           应用场景                           |                        底层数据结构                         | 内部实现                                                     |
| :---------: | :----------------------------------------------------------: | :---------------------------------------------------------: | :----------------------------------------------------------- |
|   String    |        缓存对象、常规计数、分布式锁、共享session信息         |                     SDS(简单动态字符串)                     | 1.不仅**可以保存文本数据，还可以保持二进制数据**（记录len）2. 获取**字符串长度的时间复杂度是O（1）** 3.**API安全，拼接字符串不造成缓冲区溢出**<br /> |
|    Hash     |                       缓存对象、购物车                       |    Redis3.2以后改成quicklist实现，代替双向链表和压缩列表    | **quicklist**                                                |
|    List     | 消息队列（**问题1 生产者需要自行实现全局唯一ID** 问题**2 不能以消费组形式消费数据**） |  （Redis7.0以后改成**listpack**实现，代替压缩列表）+哈希表  | 小于512，每个小于64字节，listpack 否则哈希表                 |
|     Set     |           聚合计算场景（点赞、共同关注、抽奖活动）           |                     哈希表或者整数集合                      | 小于512 整数集合 否则哈希表                                  |
|    Zset     |                           排序场景                           | （Redis7.0以后改成**listpack**实现，代替压缩列表）**+跳表** | 小于128，每个小于64字节，listpack，否则跳表                  |
|   BitMap    | 二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等 |                                                             |                                                              |
| HyperLogLog |        海量数据基数统计的场景，比如百万级网页 UV 计数        |                                                             |                                                              |
|     GEO     |             存储地理位置信息的场景，比如滴滴叫车             |                                                             |                                                              |
|   Stream    | 消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：<br />**自动生成全局唯一消息ID，支持以消费组形式消费数据。** |                                                             |                                                              |

### SDS和c语言字符串

**O（1）复杂度获取字符串长度**

1. C 语言的字符串长度获取 strlen 函数，需要通过遍历的方式来统计字符串长度，时间复杂度是 O（N）。
2. 而 Redis 的 SDS 结构因为加入了 len 成员变量，那么**获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）。**

**二进制安全**

1. 因为 SDS 不需要用 “\0” 字符来标识字符串结尾了，**而是有个专门的 len 成员变量来记录长度，**所以可存储包含 “\0” 的数据。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。
2. 因此， **SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。**
3. **通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。**

**不会发生缓冲区溢出**

1. C 语言的字符串标准库提供的字符串操作函数，大**多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证**，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。
2. 所以，**Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 alloc - len 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，**就可以由程序内部判断缓冲区大小是否足够用。
3. 而且，**当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小，**以满足修改所需的大小

### ZSet

##### 底层为什么用跳表，而不用平衡树、红黑树或者b+树

这道面试题很多大厂比较喜欢问，难度还是有点大的。

- 平衡树 vs 跳表：
  - 主要是**从内存占用、对范围查找的支持、实现难易程度**这三方面总结的原因：

    1. 从**内存占用**上来比较，跳表比平衡树更灵活一些。**平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。**
    2. 在**做范围查找的**时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点**。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在**跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历**就可以实现。
    3. 从**算法实现难度**上来比较，跳表比平衡树要简单得多。**平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速

- 红黑树 vs 跳表：**相比较于红黑树来说，跳表的实现也更简单一些，不需要通过旋转和染色（红黑变换）来保证黑平衡。并且，按照区间来查找数据这个操作，红黑树的效率没有跳表高。**
- B+树 vs 跳表：B+树更适合作为数据库和文件系统中常用的索引结构之一，它的核心思想是通过可能少的 IO 定位到尽可能多的索引来获得查询数据。**对于 Redis 这种内存数据库来说，它对这些并不感冒，因为 Redis 作为内存数据库它不可能存储大量的数据**，所以对于索引不需要通过 B+树这种方式进行维护，只需按照概率进行随机维护即可，节约内存**。而且使用跳表实现 zset 时相较前者来说更简单一些，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要对节点分裂与合并。**

##### 跳表是怎么实现的

链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，**这样的好处是能快读定位数据。这个查找过程就是在多个层级上跳来跳去，最后定位到元素。**当数据量很大时，跳表的查找复杂度就是 O(logN)。**

## Redis持久化

三种持久化方式：

- **AOF日志：**每执行一条写**操作命令**，就把**该命令以追加的方式写入到一个文件里**
- **RDB快照：**将某一时刻的**内存数据**，以**二进制方式写入磁盘**
- **混合持久化方式：**Redis4.0新增的方式，继承了前两种的优点

### AOF（Append Only File）日志是如何实现的 

Redis 在**执行完一条写操作命令**后，就会**把该命令以追加的方式写入到一个文件**里，
然后 **Redis 重启时，会读取该文件记录的命令**，然后**逐一执行命令**的方式来进行数据恢复。

- **避免额外的检查开销**
- **不会阻塞当前写操作命令的执行**

- **数据可能会丢失**
- **可能阻塞其他的操作**

#### 1. AOF写回策略有几种？

- Redis 执行完写操作命令后，**会将命令追加到 server.aof_buf 缓冲区；**

- 然后通过 write() 系统调用，**将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；**

- 具体**内核缓冲区的数据什么时候写入到硬盘**，由内核决定。

  - **Redis.conf 配置文件中的 appendfsync** 配置项可以有以下 3 种参数可填。
    这三种策略只是在控制 fsync() 函数的调用时机。

    | 写回策略 |                             意思                             | 写回时机           | 优点                           | 缺点                               |
    | -------- | :----------------------------------------------------------: | ------------------ | ------------------------------ | ---------------------------------- |
    | Always   |     **每次写操作命令执行完后，将AOF日志数据写回磁盘。**      | 同步写回           | 可靠性高、最大程度保证数不丢失 | 每个写命令都要写回硬盘，性能开销大 |
    | EverySec | 每次写操作命令执行完后，**先将命令写入AOF文件的内核缓冲区，**然后**每隔一秒将缓冲区里的内容写回到硬盘** | 每秒写回           | 性能适中                       | 宕机时会丢失一秒内的数据           |
    | No       | 每次写操作命令执行完后，先将命令**写入到 AOF 文件的内核缓冲区**，再由**操作系统决定何时将缓冲区内容写回硬盘**。 | 由操作系统控制写回 | 性能好                         | 宕机时可能会丢失大量数据           |

#### 2. AOF日志过大会触发什么机制

- **提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，启用 AOF 重写机制，来压缩 AOF 文件。**
- **读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。**
  - 因为**如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染，可能无法用于恢复使用。所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响**

#### 3. 重写AOF日志的过程是怎样的

Redis 的**重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，**这么做可以达到两个好处

- **避免阻塞主进程**
- 父子进程内存以只读的的方式共享，当父子进程任意一方修改了该共享内存，发生写时复制，父子进程有了独立的数据副本，不用加锁来保存副本
  - 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把**主进程的「页表」复制一份**给子进程，这个页表记录着虚拟地址和物理地址映射关系，而**不会复制物理内存**，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。
  - 当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发**写保护中断**，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里**进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写**，最后才会对内存进行写操作，这个过程被称为「写时复制(Copy On Write)」
  - 写时复制顾名思义**，在发生写操作的时候，操作系统才会去复制物理内存**，这样是**为了防止** fork 创建子进程时，**由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。**

**触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）**

 在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

- 执行客户端发来的命令；
  - 如**果此时主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的。**
- 将执行后的写命令**追加到 「AOF 缓冲区」；**
- 将执行后的写命令**追加到 「AOF 重写缓冲区」；**

子进程完成重写工作，向主进程发信号，主进程收到信号，调用信号处理函数：

- **将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；**
- **新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。**

### RDB（Redis Database）快照是如何实现的呢

用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，**一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢**。为了解决这个问题，Redis 增加了 RDB 快照。

​	RDB 快照**就是记录某一个瞬间的内存数据**，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

​	RDB 快照的缺点**：在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多**，因为 RDB 快照是全量快照的方式，因此**执行的频率不能太频繁**，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少

#### RDB做快照时会阻塞线程吗

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行

- **save 在主线程生成RDB文件，会阻塞主线程**
- **bgsave 创建子线程来生成RDB文件，避免主线程的阻塞**
- 也可以通过配置文件的选项自动执行bgsave

#### RDB在执行快照的时候，数据能修改吗

​	执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write, COW）。

​	共享同一片内存数据，页表指向的物理内存还是一个，主线程可以直接修改原来的数据。

​	bgsave 快照过程中，如果主线程修改了共享数据，发生了写时复制后，RDB 快照保存的是原本的内存数据，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。
​	所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据
​	如果系统恰好在 RDB 快照文件创建完毕后崩溃了，那么 Redis 将会丢失主线程在快照期间修改的数据。

#### 为什么会有混合持久化

- **混合持久化工作在 AOF 日志重写过程，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。**
  - 当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。
- **既保证了 Redis 重启速度，又降低数据丢失风险。**
- **添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。**

### AOF和RDB优缺点

#### AOF

- **优点：**
  - 首先，AOF提供了**更好的数据安全性**，因为它默认每接收到一个写命令就会**追加**到文件末尾。即使Redis服务器宕机，也**只会丢失最后一次**写入前的数据。
  - 其次，AOF支**持多种同步策略**（如everysec、always等），可以根据需要调整**数据安全性和性能之间的平衡。**
  - 同时，**AOF文件在Redis启动时可以通过重写机制优化，减少**文件体积，加快恢复速度。
  - 并且，即使**文件发生损坏，AOF还提供了redis-check-aof工具来修复**损坏的文件。
- **缺点:**
  - 因为记录了每一个写操作，所以**AOF文件通常比RDB文件更大，消耗更多的磁盘空间。**
  - 并且，**频繁的磁盘IO操作（尤其是同步策略设置为always时）可能会对Redis的写入性能造成一定影响**。
  - 而且，当问个文件体积过大时，AOF会进行重写操作**，AOF如果没有开启AOF重写或者重写频率较低，恢复过程可能较慢，因为它需要重放所有的操作命令。**

#### RDB

- **优点:** 
  - **RDB通过快照的形式保存**某一时刻的数据状态，**文件体积小，**备份和恢复的速度非常快。
  - 并且，RDB是**在主线程之外通过fork子进程来进行的，不会阻塞服务器处理命令请求，**对Redis服务的性能影响较小。
  - 最后，由于是**定期快照，RDB文件通常比AOF文件小得多。**
- **缺点**: 
  - RDB方式**在两次快照之间，如果Redis服务器发生故障，这段时间的数据将会丢失。**
  - 并且，如果**在RDB创建快照到恢复期间有写操作，**恢复后的数据可能与故障前的数据**不完全一致**



### Redis大key对持久化有什么影响

#### 什么是大key问题

Redis大key问题指的是**某个key对应的value值所占的内存空间比较大，导致Redis的性能下降、内存不足、数据不均衡以及主从同步延迟等问题。**

到底多大的数据量才算是大key？没有固定的判别标准**，通常认为字符串类型的key对应的value值占用空间大于1M，或者集合类型的k元素数量超过1万个，就算是大key。**

Redis大key问题的定义及评判准则并非一成不变，而应根据Redis的实际运用以及业务需求来综合评估。

例如，在高并发且低延迟的场景中，仅10kb可能就已构成大key；然而在低并发、高容量的环境下，大key的界限可能在100kb。因此，在设计与运用Redis时，要依据业务需求与性能指标来确立合理的大key阈值

#### 大key对AOF日志的影响

- 在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。
  - 如果写入是一个大 Key，**主线程在执行 fsync() 函数的时候，阻塞的时间会比较久**，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。
- 当使用 **Everysec 策略**的时候，由于是**异步**执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）**不会影响**主线程。
- 当使用 No 策略的时候，由于**永不执**行 fsync() 函数，所以大 Key 持久化的过程**不会影响主线程。**

#### 大key对AOF重写和RDB的影响

**AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 fork() 函数创建一个子进程来处理任务**。会有两个阶段会导致阻塞父进程（主线程）：

1. 创建子进程的途中，由于要复制父进程的**页表**等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
2. 创建完子进程后，如**果父进程修改了共享数据中的大 Key**，就会发**生写时复制**，**这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，**那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程

#### 大key问题的缺点？

1. **内存占用过高。**大Key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。
2. **性能下降。**大Key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大Key的操作，如读取、写入、删除等，都会消耗更多的CPU时间和内存资源，进一步降低系统性能。
3. **阻塞其他操作**。某些对大Key的操作可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。
4. **网络拥塞。**每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。
5. **主从同步延迟。**当Redis实例配置了主从同步时，大Key可能导致主从同步延迟。由于大Key占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。
6. **数据倾斜。**在Redis集群模式中，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。另外也可能造成Redis内存达到maxmemory参数定义的上限导致重要的key被逐出，甚至引发内存溢出。

#### 如何避免大key

- **对大Key进行拆分**。例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。

- **监控Redis的内存水位**。可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。

- **对大Key进行清理。**将**不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。**

- **对过期数据进行定期清。**堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。**可以通过定时任务的方式对失效数据进行清**

- **定时检查** Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，**而是用 unlink 命令**（Redis 4.0+）删除大 key，**因为该命令的删除过程是异步的，不会阻塞主线程。**

###  热key

#### 什么是热key

通常以其接收到的**Key被请求频率来判定，**例如：

- **QPS集中在特定的Key**：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。
- **带宽使用率集中在特定的Key**：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。
- **CPU使用时间占比集中在特定的Key：**对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求

#### 如何解决热key问题

- 在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。**此时，可以将对应热Key进行复制并迁移至其他数据分片，**例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。
- **使用读写分离架构。**如果热Key的产生来自于读请求，您可以将实例改造**成读写分离架构来降低每个数据分片的读请求压力**，甚至可以不断地增加从节点。**但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。**要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。                                  

## Redis过期淘汰策略

### 过期删除策略和内存淘汰策略有什么区别？

- 内存淘汰策略是在**内存满了的时候，redis 会触发内存淘汰策略，来淘汰一些不必要的内存资源**，以腾出空间，来保存新的内容
- 过期键删除策略**是将已过期的键值对进行删除，Redis 采用的删除策略是惰性删除+定期删除**

### 如何设置过期时间

1. 对key设置过期时间的命令
   1. expire <key> <n>：设置 key 在 n 秒后过期
   2. pexpire <key> <n>：设置 key 在 n 毫秒后过期
   3. expireat <key> <n>：设置 key 在某个时间戳（精确到秒）之后过期，
   4. pexpireat <key> <n>：设置 key 在某个时间戳（精确到毫秒）之后过期
2. 设置字符串时，同时对key设置过期时间
   1. set <key> <value> ex <n> ：设置键值对的时候，同时指定过期时间（精确到秒）；
   2. set <key> <value> px <n> ：设置键值对的时候，同时指定过期时间（精确到毫秒）；
   3. setex <key> <n> <valule> ：设置键值对的时候，同时指定过期时间（精确到秒）
3. 如果你想查看某个 key 剩余的存活时间，可以使用 TTL <key> 命令。
4. 如果突然反悔，取消 key 的过期时间，则可以使用 PERSIST <key> 命令。

### Redis 使用的过期删除策略是什么？

- Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

- Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中（**过期字典存储在redisDb结构中**），也就是说「过期字典」保存了数据库中所有 key 的过期时间。Redis 选择**「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

  - **过期字典的 key 是一个指针，指向某个键对象；**
    **过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；**

- 当我们查询一个 key 时，**Redis 首先检查该 key 是否存在于过期字典中：**

  - **不存在，正常读取**
  - **存在，比对时间**

- 定时删除策略

  在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作

  优点：可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。

  缺点：在过期 key 比较多的情况下，**删除过期 key 可能会占用相当一部分 CPU 时间，**在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。

- **惰性删除策略**

  **不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

  优点：惰性删除策略**对 CPU 时间最友好。**

  缺点：只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的**内存空间浪费。**

- **定期删除策略**

  每隔一段时间**「随机」从数据库中取出一定数量**的 key 进行检查**，并删除其中的过期key。超过25%继续查。**

  **默认为每秒进行10次过期检查。**

  那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。

  优点：

  ​	通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响。

  ​	同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

  缺点：

  ​	难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

### Redis 持久化时，对过期键会如何处理的？

1. **RDB文件**
   1. **生成**阶段：**从内存状态持久化成RDB的时候，对key进行过期检查，不会保存到新的RDB文件中**
   2. **加载**阶段
      1. **主服务器，载入RDB文件时，对文件中保存的key进行检查，不会载入到数据库中**
      2. **从服务器，直接载入**。但是主从**服务器同步时候从服务器数据会被清空**，所以也没影响
2. **AOF文件**
   1. **写入**阶段：**以AOF模式持久化，过期键被保留，当此过期键被删除后，会向AOF文件追加一条DEL命令来显式地删除该键值**
   2. **重写**阶段**：执行AOF重写，对键进行检查，不会保存到重写的文件中。**

### Redis 主从模式中，对过期键会如何处理？

- 当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。
  - 小林哥，感觉redis有些东西有点老了。主从复制那里，**master删除过期键，但是slave不会删除过期键。这句话是redis3.2以前适用的。**
    **在4.0.11 以上版本，所有命令均已修复，过期 key 在 slave 上查询，均返回不存在了**
- **主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key**

### Redis 内存满了，会发生什么？

触发内存淘汰策略

### Redis 内存淘汰策略有哪些？

八种内存淘汰策略，大体分为不进行数据淘汰和进行数据淘汰两种策略。

1. **不进行数据淘汰的策略**

   **noeviction（**Redis3.0之后，默认的内存淘汰策略） ：它表示**当运行内存超过最大设置内存时，不淘汰任何数据**，这时如果**有新的数据**写入，会报错通知**禁止写入**，不淘汰任何数据，但是如果**没用数据写入**的话，只是单纯的查询或者删除操作的话，还是可以**正常工作**。

2. **进行数据淘汰的策略**

   1. **在设置了过期时间的数据中进行淘汰**
      1. **volatile-random**：随机淘汰设置了过期时间的任意键值；
      2. **volatile-ttl：**优先淘汰更早过期的键值。
      3. **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：**淘汰所有设置了过期时间的键值中，最久未使用的键值；**
      4. **volatile-lfu（**Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，**最少使用的键值；**
   2. **在所有数据范围内进行淘汰**
      1. **allkeys-random：**随机淘汰任意键值;
      2. **allkeys-lru：**淘汰整个键值中最久未使用的键值；
      3. **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

### LRU 算法和 LFU 算法有什么区别？

1. 传统的LRU算法：最近最少使用 Least Recently Used

   1. 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
   2. 当有数据被访问时，**需要在链表上把该数据移动到头端**，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

2. Redis实现的LRU算法 

   1. Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，**用于记录此数据的最后一次访问时间。**
   2. 当 Redis 进行内存淘汰时**，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。**
   3. 节省了空间占用，提升了缓存性能
   4. 但是 LRU 算法有一个问题，**无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。**

3. Redis实现的LFU算法 最近最不常用的 Least Frequently Used

   1. LFU 算法相比于 LRU 算法的实现，多记录了**「数据的访问频次」**的信息

   2. 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，**Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。**

   3. 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；**低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。**

      注意，logc 并不是单纯的访问次数，而是**访问频次（访问频率），因为 logc 会随时间推移而衰减的**

## Redis缓存雪崩、缓存击穿、缓存穿透

### 缓存雪崩

**大量缓存数据在同一时间过期（失效）时**，如果此时有大量的用户请求，都无法在 Redis 中处理，于是**全部请求都直接访问数据库，**从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。

发生原因和解决办法

- 大量数据同时过期

  - **随机打散缓存失效时间**

  - **互斥锁**

    - 当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就**加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里），**当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
    - 实现互斥锁的时候，**最好设置超时时间**，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。

  - **后台更新缓存**

    - 让缓存“永久有效”，并**将更新缓存的工作交由后台线程定时更新。**

      - 但是**这并不意味着数据一直能在内存里**，当系统**内存紧张的时候，有些缓存数据会被“淘汰”，**而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程**读取缓存失败就返回空值**，业务的视角就以为是数据丢失

        解决方法：

        1. 后台线程**不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效**，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要**马上从数据库读取数据，并更新到缓存**。
        2. 在业务线程**发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存**，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作**；不存在就读取数据库数据，并将数据加载到缓存。**

      - 业务刚上线的时候，我们·最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的**缓存预热**，后台更新缓存的机制刚好也适合干这个事情。

- Redis故障宕机

  - **服务熔断机制或者请求限流机制**
    - 服务熔断机制：**暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库**，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 **Redis 恢复正常后，再允许业务应用访问缓存服务。**
    - 请求限流机制：**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，**等到 Redis **恢复正常并把缓存预热完**后，再解除请求限流的机制。
  - **构建Redis缓存高可靠集群**
    - 通过**主从节点的方式构建 Redis 缓存高可靠集群**。如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。

### 缓存击穿

如果缓存中的**某个热点数据过期了**，此时**大量的请求访问了该热点数据**，就无法从缓存中读取，**直接访问数据库**，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。

- **互斥锁方案**（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），**保证同一时间只有一个业务线程请求缓存**，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值
- **不给热点数据设置过期时间，由后台异步更新缓存**，或者在热点数据**准备要过期前，提前通知后台线程**更新缓存以及重新设置过期时间；

### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再**去访问数据库时，发现数据库中也没有要访问的数据**，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；

- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

  

- 限制非法请求

- 设置空值或者默认值

- 使用布隆过滤器判断数据是否存在，避免通过查询数据库来判断数据是否存在。

  - 查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据
  - 布隆过滤器由**「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。**当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。
    布隆过滤器会通过 3 个操作完成标记：
    - 第一步，**使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；**
    - 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，**得到每个哈希值在位图数组的对应位置。**
    - 第三**步，将每个哈希值在位图数组的对应位置的值设置为 1；**

## Redis、Mysql缓存一致性问题

### 一、Redis缓存策略

|          |                           内存淘汰                           |                           超时剔除                           |                 主动更新                  |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------: |
|   说明   | 不用自己维护，利用Redis的内存淘汰机制，当内存不足时自动淘汰部分数据，下次查询时更新缓存。 | **给缓存数据添加TTL时间，到期后自动删除缓存，下次查询时更新缓存** | 编写业务逻辑，在修改数据的6同时，更新缓存 |
|  一致性  |                              差                              |                             一般                             |                    好                     |
| 维护成本 |                              无                              |                              低                              |                    高                     |

1. 在基本不会更新数据的情况下可以使用内存淘汰机制
2. 在频繁更新数据的情况下可以使用主动更新**，并以超时剔除作为兜底方案**

### 二、主动更新的三种方法

1. **（旁路缓存）Cache Aside Pattern**：由缓存的调用者，在更新数据库的同时更新缓存

2. **（读穿 / 写穿）Read/Write Through Pattern**：缓存**和数据库整合为一个服务**，由服务来维护一致性。调用者调用该服务，无需关心缓存一致性问题。

   1. 优点：整合的服务保证了数据的一致性

   2. 缺点：维护和开放成本高

      ###### 读穿

      先看能否命中缓存，没有命中，由缓存组件从数据库中读取数据，将数据写入缓存组件，最后缓存组件将数据返回给应用

      ###### 写穿

      - 如果缓存中数据不存在，直接更新数据库，然后返回
      - 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。

3. **（写回）Write Behind Caching Pattern：**调用者**只操作缓存，由其他线程异步的将缓存数据持久化到数据库，**最终保持一致。

   1. 优点：异步更新缓存数据，效率高。例如缓存多次更新，但是更新到的缓存并没有被使用，多次将数据持久化到数据库就相当于进行了无用的操作，异步更新相当于将前几次的更新合并为一次更新，因而提高了效率。

   2. 缺点：无法保证一致性，维护成本高

      Write Back（写回）策略在更新数据的时候，**只更新缓存，同时将缓存数据设置为脏的**，然后立马返回，并不会更新数据库。对于**数据库的更新，会通过批量异步更新**的方式进行。

      - Write Back 策略特别适合**写多**的场景，因为发**生写操作的时候， 只需要更新缓存，就立马返回了**。
      - 但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险，

### 三、Redis的读

如果缓存在[Redis](https://cloud.tencent.com/document/product/239?from=10680)中存在，即缓存命中，则直接返回数据

如果[Redis](https://cloud.tencent.com/document/product/239?from=10680)中没有对应缓存，则需要直接查询[数据库](https://cloud.tencent.com/document/product/236?from=10680)，然后存入[Redis](https://cloud.tencent.com/document/product/239?from=10680)，最后把数据返回

![image-20241015092601203](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092601203.png)

通常情况下，我们会为某个缓存设置一个key值，并针对key值设置一个过期时间，如果被查询的数据对应的key过期了，则直接查询[数据库](https://cloud.tencent.com/document/product/236?from=10680)，并将查询得到的数据存入[Redis](https://cloud.tencent.com/document/product/239?from=10680)，然后重置过期时间，最后将数据返回。

### 四、Redis的写

**一致性问题:** 

```
在Redis的key值未过期的情况下，用户修改了个人信息，我们此时既要操作数据库数据，也要操作Redis数据。
```

**到底是先更新数据库还是先更新缓存？**

```
从本质上讲，无论是先写数据库还是先写缓存，都是为了保证数据库和缓存的数据一致，也就是我们常说的数据一致性。
```

操作缓存和数据库时需要考虑的三个问题:

1. **删除缓存还是更新缓存？**
   更新缓存：每次更新数据库都更新缓存，无效写操作较多
   删除缓存：更新数据库时让缓存失效，查询时再更新缓存
   结论：推荐**直接使用「删除」操作。**

2. **如何保证缓存与数据库的操作的同时成功或者失败**
   对于单体系统：将缓存与数据库操作放在一个事务中
   对于分布式系统：利用TCC等分布式事务方案

3. **先操作缓存还是先操作数据库?**
   3-1. 先删除缓存，再操作数据库
   这种方式可能存在以下两种异常情况:

   1. 删除缓存失败，这时可以通过程序捕获异常，直接返回结果，不再继续更新数据库，所以不会出现数据不一致的问题

   2. **删除缓存成功，更新数据库失败。在多线程下可能会出现数据不一致的问题**

      <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092223313.png" alt="image-20241015092223313" style="zoom:50%;" />

       这时，Redis中存储的旧数据，数据库的值是新数据，导致数据不一致**。这时我们可以采用 延时双删 的策略，即更新数据库数据之后，再删除一次缓存。**

      <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092235976.png" alt="image-20241015092235976" style="zoom:50%;" />

   3-2. 先操作数据库，再删除缓存

   这种方式可能存在以下两种异常情况:

   1. 更新数据库失败，这时可以通过程序捕获异常，直接返回结果，不再继续删除缓存，所以不会出现数据不一致的问题
   2. **更新数据库成功，删除缓存失败。导致数据库是最新数据，缓存中的是旧数据，数据不一致**

   这里, 我们有两种方式来解决数据不一致问题：**失败重试** 和 **异步更新**。

   方式1. 失败重试

   <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092346479.png" alt="image-20241015092346479" style="zoom:50%;" />

   消息队列重试机制

   - 将删除缓存要操作的数据加入到消息队列，由消费者来操作数据
     - **如果删除缓存失败，从消息队列里再次读取，并重新删除。超过一定次数，向业务层报错**
     - **如果删除缓存成功，把数据从消息队列中移除，避免重复操作。**
   - 优点：保证缓存一致性问题
   - 缺点：对代码入侵性比较强，因为需要改造原本业务的代码

   方式2. 异步更新

   订阅MySQL binlog+消息队列+重试缓存

   - 更新数据库成功，就会产生一条变更日志，记录在 binlog 里。 订阅binlog日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。
   - **将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性。必须是删除缓存成功，再回 ack 机制给消息队列，否则可能会造成消息丢失的问题，比如消费服务从消息队列拿到事件之后，直接回了 ack，然后再执行删除缓存操作的话，如果删除缓存的操作还是失败了，那么因为提前给消息队列回 ack了，就没办重试了。**
   - 优点：规避了代码入侵的问题，保证缓存一致性问题
   - 缺点：引入组件较多，对运维有较高要求

   <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092406938.png" alt="image-20241015092406938" style="zoom:50%;" />

   总之，对于删除缓存失败的情况，我们的做法是不断地重试删除操作，直到成功。无论是重试还是异步删除，都是最终一致性的思想。
   如上图所示，两种方案在多线程的情况下都会产生数据不一致的问题
   在**先操作数据库再删除缓存的情况下，要发生数据不一致的问题，需要在缓存写入之前完成更新数据库和删除缓存的操作，而写入缓存的耗时非常短。因而发生的概率相对于另一种方案更低。所以优先选择先操作数据库，再删除缓存。**
   **结论：推荐直接使用「先更新数据库再删除缓存」操作。**

### 五、总结

缓存策略的最佳实践是 **Cache Aside 模式**。分别分为读缓存最佳实践和写缓存最佳实践。

**读缓存最佳实践**

```
先读缓存，命中则返回；
未命中则查询数据库，再写到缓存中。
```

**写缓存最佳实践**

```
先更新数据库，再操作缓存；
操作缓存采用直接删除缓存，而不是修改。
```

## IOC、AOP

### 什么是IoC

**IoC（Inversion of Control:控制反转） 是一种设计思想，将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理**

- 控制：指的是对象创建（实例化、管理）的权力
- 反转：控制权交给外部环境（Spring 框架、IoC 容器）

**将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。**

所谓**控制就是对象的创建、初始化、销毁。**

- 创建对象：原来是 new 一个，现在是由 Spring 容器创建。
- 初始化对象：原来是对象自己通过构造器或者 setter 方法给依赖的对象赋值，现在是由 Spring 容器自动注入。
- 销毁对象：原来是直接给对象赋值 null 或做一些销毁操作，现在是 Spring 容器管理生命周期负责销毁对象。

### IOC实现机制

- 反射：**Spring IOC容器利用Java的反射机制动态地加载类、创建对象实例及调用对象方法**，反射允许在运行时检查类、方法、属性等信息，从而实现灵活的对象实例化和管理。
- 依赖注入：**IOC的核心概念是依赖注入，即容器负责管理应用程序组件之间的依赖关系。Spring通过构造函数注入、属性注入或方法注入，**将组件之间的依赖关系描述在配置文件中或使用注解。
- 设计模式 - 工厂模式：Spring IOC容器通常采用工厂模式来管理对象的创建和生命周期。容**器作为工厂负责实例化Bean并管理它们的生命周期，将Bean的实例化过程交给容器来管理。**
- 容器实现：S**pring IOC容器是实现IOC的核心，通常使用BeanFactory或ApplicationContext来管理Bean。****BeanFactory是IOC容器的基本形式，提供基本的IOC功能；ApplicationContext是BeanFactory的扩展，**并提供更多企业级功能

### 什么是AOP

在面向切面编程中，核心业务功能和周边功能是分别独立进行开发，两者不是耦合的，然后把切面功能和核心业务功能 "编织" 在一起，这就叫AOP。

AOP(Aspect-Oriented Programming:**面向切面编程**)能够**将那些与业务无关**，**却为业务模块**所共同**调用的**逻辑或责任（例如事务处理、日志管理、权限控制等）**封装起来**，便于**减少系统的重复代码**，**降低**模块间的**耦合度**，并有利于未来的可拓展性和可维护性

### AOP应用场景

1. **日志记录**：自定义日志记录注解，利用 AOP，一行代码即可实现日志记录。
2. **性能统计：**利用 AOP 在目标方法的执行前后统计方法的执行时间，方便优化和分析。
3. **事务管理：**@Transactional 注解可以让 Spring 为我们进行事务管理比如回滚异常操作，免去了重复的事务管理逻辑。@Transactional注解就是基于 AOP 实现的。
4. **权限控制**：利用 AOP 在目标方法执行前判断用户是否具备所需要的权限，如果具备，就执行目标方法，否则就不执行。例如，SpringSecurity 利用@PreAuthorize 注解一行代码即可自定义权限校验。
5. **接口限流**：利用 AOP 在目标方法执行前通过具体的限流算法和实现对请求进行限流处理。
6. **缓存管理**：利用 AOP 在目标方法执行前后进行缓存的读取和更新。
   ……

### AOP实现机制

Spring AOP的实现依赖于动态代理技术。**动态代理是在运行时动态生成代理对象，而不是在编译时。**它允许开发者在运行**时指定要代理的接口和行为，从而实现在不修改源码的情况下增强方法的功能。**

Spring AOP支持两种动态代理：

- 基**于接口的代理（JDK动态代理）：** 这种类型的代理要求**目标对象必须实现至少一个接口**。**Java动态代理会创建一个实现了相同接口的代理类，然后在运行时动态生成该类的实例。这**种代理的实现核心是java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口**。每一个动态代理类都必须实现InvocationHandler接口，并且每个代理类的实例都关联到一个handler。当**通过代理对象**调用一个方法时，这个方法的调用会被转发为由InvocationHandler接口的invoke()方法来进行调用。**
- **基于类的代理（CGLIB动态代理）：** CGLIB（Code Generation Library）是一个强大的高性能的代码生成库，它可以在运行时动态生成一个目标类的子类。**CGLIB代理不需要目标类实现接口，而是通过继承的方式创建代理类。因此，如果目标对象没有实现任何接口，可以使用CGLIB来创建动态代理**

Spring AOP 是基于动态代理的

- 如果要代理的对象，**实现了某个接口**，那么 Spring AOP 会使用 **JDK Proxy，去创建代理对象**
- 而对**于没有实现接口**的对象，Spring AOP 会使用 **Cglib 生成一个被代理对象的子类来**作为代理

**专业术语**

|      术语       |                             含义                             |
| :-------------: | :----------------------------------------------------------: |
|   目标target    |                         被通知的对象                         |
|    代理proxy    |             向目标对象应用通知之后创建的代理对象             |
| 连接点joinpoint |       目标对象的所属类中**，定义的所有方法**均为连接点       |
| 切入点pointcut  | **被切面拦截 / 增强的连接点**（切入点一定是连接点，连接点不一定是切入点） |
|   通知advice    | **增强的逻辑 / 代码，也即拦**截到目标对象的连接点之后要做的事情 |
|   切面aspect    |                切入点(Pointcut)+通知(Advice)                 |
|   织入weaving   |       将通知应用到目标对象，进而生成代理对象的过程动作       |

### 动态代理和静态代理的区别

代理是一种常用的设计模式，目的是：**为其他对象提供一个代理以控制对某个对象的访问，将两个类的关系解耦。代理类和委托类都要实现相同的接口，因为代理真正调用的是委托类的方法。**
区别：

- 静态代理：由程序员创建或者是由特定工具创建，**在代码编译时就确定了被代理的类是一个静态代理**。静态代理**通常只代理一个类；**
- 动态代理：在**代码运行期间，运用反射机制动态创建生成**。动态代理**代理的是一个接口下的多个实现类。**

### Spring Aop和Aspect Aop的区别

- **Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP **基于代理(Proxying)**，而 AspectJ **基于字节码操作(Bytecode** Manipulation)。
- Spring AOP 集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。
- 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多

### AOP常见的通知类型有哪些

- **Before（前置通知）**：目标对象的方法调用之前触发
- **After （后置通知）**：目标对象的方法调用之后触发
- **AfterReturning（返回通知）：**目标对象的方法调用完成，在返回结果值之后触发
- **AfterThrowing（异常通知）：**目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
- **Around （环绕通知）**：编程式控制目标对象的方法调用。环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以**环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法**

### 多个切面的执行顺序如何控制？

1. **通常使用@Order注解直接定义切面顺序**
2. **实现Ordered接口重写getOrder方法**

### AOP实现有哪些注解？

常用的注解包括：

1. @Aspect：用于定义切面，标注在切面类上。
2. @Pointcut：定义切点，标注在方法上，用于指定连接点。
3. @Before：在方法执行之前执行通知。
4. @After：在方法执行之后执行通知。
5. @Around：在方法执行前后都执行通知。
6. @AfterReturning：在方法执行后返回结果后执行通知。
7. @AfterThrowing：在方法抛出异常后执行通知。
8. @Advice：通用的通知类型，可以替代@Before、@After等

## Netty

### redis，nginx，netty 是依赖什么做的这么高性能？（多Reactor多进程、单Reactor单进程 Reactor）

主要是依赖**Reactor 模式**，也就是来了一个事件，Reactor 就有相对应的反应/响应

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send

**Redis**

<img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20240808190811162.png" alt="image-20240808190811162" style="zoom: 67%;" />

Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案

- Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型
- 如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件
- 如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程

存在缺点：

- 第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能
- 第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟

**nginx** 

nginx是多 Reactor 多进程方案，不过方案与标准的多 Reactor 多进程有些差异

具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接

**Netty**

<img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20240808191057217.png" alt="image-20240808191057217" style="zoom:67%;" />

- 主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程
- 子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件
- 如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

优势：

- 主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理
- 主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端

### Netty是什么

1. Netty 是⼀个 **基于 NIO** 的 client-server(客户端服务器)框架，使⽤它可以快速简单地开发⽹络应⽤程序。
2. 它极⼤地简化并优化了 TCP 和 UDP 套接字服务器等⽹络编程,并且性能以及安全性等很多⽅⾯甚⾄都要更好。

### BIO,NIO 和 AIO？（阻塞IO/非阻塞IO）

- **BIO：** 同步阻塞 I/O 模式，数据的读取写⼊必须阻塞在⼀个线程内等待其完成
- **NIO**：同步⾮阻塞的 I/O 模型，线程不断地轮询调用 `read` 操作来判断是否有数据，提供了 Channel , Selector ， Buffer等抽象
- **AIO**：异步⾮阻塞的 IO 模型，当后台处理完成，操作系统会通知相应的线程进⾏后续的操作

### 直接用 NIO和用 Netty？（Netty的优势）

对编程功底要求⽐较⾼，⽽且，NIO 在⾯对断连重连、包丢失、粘包等问题时处理过程⾮常复杂。Netty相对来说有这些优势

- 统⼀的 API，⽀持多种传输类型，阻塞和⾮阻塞的
- 简单⽽强⼤的线程模型
- ⾃带编解码器解决 TCP 粘包/拆包问题
- 安全性不错，有完整的 SSL/TLS 以及 StartTLS ⽀持
- ⽐直接使⽤ Java 核⼼ API 有更⾼的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制

### Netty 应用场景？

Netty 主要⽤来做**⽹络通信**：

1. **作为 RPC 框架的⽹络通信⼯具**：⽐如我调⽤另外⼀个节点的⽅法的话，⾄少是要让对知道我调⽤的是哪个类中的哪个⽅法以及相关参数吧
2. 可以聊天类似微信的即时通讯系统
3. **实现消息推送系统**：比如市面上的像Nacos，RocketMQ、Dubbo

### Netty 的核心组件？

 **Selector**

Netty 基于 **Selector 对象实现 I/O 多路复用**，通过 Selector **一个线程可以监听多个连接的 Channel 事件**。 当向一个 **Selector 中注册 Channel 后**，Selector 内部的机制就可以**自动不断地查询（Select）\**这些注册的 Channel 是否\**有已就绪的 I/O 事件**（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel。

**Bytebuf（字节容器）**

⽹络通信最终都是通过字节流进⾏传输的。 `ByteBuf` 就是 Netty 提供的⼀个字节容器，其内部是⼀个字节数组。 当我们通过 Netty 传输数据的时候，就是通过 `ByteBuf `进⾏的，可以将 `ByteBuf `看作是 Netty 对 `ByteBuffer` 字节容器的封装和抽象

**Bootstrap 和 ServerBootstrap（启动引导类）**

1. `Bootstrap` 通常使⽤ `connect()` ⽅法连接到远程的主机和端⼝，作为⼀个 Netty TCP 协议通信中的客户端
2. `ServerBootstrap` 通常使⽤ `bind()` ⽅法绑定本地的端⼝上，然后等待客户端的连接
3. `Bootstrap` 只需要配置⼀个线程组 `EventLoopGroup` ,⽽ `ServerBootstrap` 需要配置两个线程组`EventLoopGroup` ，⼀个⽤于接收连接，⼀个⽤于具体的 IO 处理。第一个EventLoopGroup通常只有一个EventLoop，通常叫做bossGroup，负责客户端的连接请求

**Channel（⽹络操作抽象类）**

`Channel` 接⼝是 Netty 对⽹络操作抽象类。通过 `Channel` 我们可以进⾏ I/O 操作。

**EventLoop（事件循环）**

`EventLoop`的主要作⽤实际就是责监听⽹络事件并调⽤事件处理器进⾏相关 I/O 操作（读写）的处理

![image-20240808202041747](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20240808202041747.png)

**ChannelHandler（消息处理器） 和 ChannelPipeline（ChannelHandler 对象链表）**

`ChannelHandler`是消息的具体处理器，主要负责处理客户端/服务端接收和发送的数据，当`Channel` 被创建时，它会被⾃动地分配到它专属的 `ChannelPipeline`

 当`ChannelHandler` 被添加到的 `ChannelPipeline` 它得到⼀个 `ChannelHandlerContext` ，它代表⼀个` ChannelHandler` 和 `ChannelPipeline` 之间的"绑定"

**ChannelFuture（操作执⾏结果）**

Netty 中所有的 I/O 操作都为异步的，我们不能⽴刻得到操作是否执⾏成功

可以通过 `ChannelFuture` 接⼝的 `addListener()` ⽅法注册⼀个` ChannelFutureListener `，当操作执⾏成功或者失败时，监听就会⾃动触发返回结果

### Netty-`NioEventLoopGroup` 默认的构造函数会起多少线程呢？

`NioEventLoopGroup` 默认的构造函数实际会起的线程数为 `CPU核⼼数*2`

### `Reactor`/`Proactor`(非阻塞同步网络模式/异步网络模式)

![image-20240808204406736](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20240808204406736.png)

- Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。
- Proactor 是异步网络模式， 感知的是已完成的读写事件

Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」

### 主从多线程 Reactor

⼀组 NIO 线程负责接受请求，⼀组 NIO 线程处理 IO 操作

### Netty 线程模型？

Netty 主要靠 `NioEventLoopGroup` 线程池来实现具体的线程模型的

实现服务端的时候，⼀般会初始化两个线程组：

- `bossGroup`：接收连接
- `workerGroup`：负责具体的处理，交由对应的 `Handler` 处理

单线程模型：`eventGroup`既用于处理客户端连接，又负责具体的处理

单线程模型：⼀个 Acceptor 线程只负责监听客户端的连接，⼀个 NIO 线程池负责具体处理

主从多线程模型：从⼀个 主线程 NIO 线程池中选择⼀个线程作为 `Acceptor` 线程，绑定监听端⼝，接收客户端连接的连接，其他线程负责后续的接⼊认证等⼯作。连接建⽴完成后`SubNIO `线程池负责具体处理 I/O 读写

### Netty 服务端和客户端的启动过程？（Netty启动过程）

**服务端**

1. 创建了两个 `NioEventLoopGroup` 对象实例： `bossGroup` 和 `workerGroup`
2. 创建了⼀个服务端启动引导类： `ServerBootstrap`
3. 通过 `.group()` ⽅法给引导类 `ServerBootstrap` 配置两⼤线程组，确定了线程模型
4. 通过 `channel()` ⽅法给引导类 `ServerBootstrap` 指定了 IO 模型为 NIO
5. `bind()`绑定端口

**客户端**

1. 创建⼀个 `NioEventLoopGroup `对象实例
2. 创建客户端启动的引导类是 `Bootstrap`
3. 通过 `.group() `⽅法给引导类 `Bootstrap` 配置⼀个线程组
4. 通过` channel()` ⽅法给引导类 `Bootstrap` 指定了 IO 模型为 NIO
5. 通过 `.childHandler()` 给引导类创建⼀个 `ChannelInitializer` ，然后指定了客户端消息的业务处理逻辑 `HelloClientHandler` 对象
6. 调⽤ `Bootstrap` 类的 `connect()` ⽅法设定好ip和端口进⾏连接

### Netty 长连接、心跳机制了解么?

**TCP长连接和短链接**

TCP 在进行读写之前，`server` 与 `client`之间必须提前建立一个连接。建立连接的过程，需要三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。

所谓，短连接说的就是 `server` 端 与 `client `端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。短连接的优点很明显，就是管理和实现都比较简单，缺点也很明显，每一次的读写都要建立连接必然会带来大量网络资源的消耗，并且连接的建立也需要耗费时间。

长连接说的就是 `client` 向 `server` 双方建立连接之后，即使 `client`与`server` 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

**为什么需要心跳机制，Netty中心跳机制了解吗**

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， `client`与`server` 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题，我们就需要引入心跳机制。

心跳机制的工作原理是：在 `client` 与 `server` 之间在一定时间内没有数据交互时，即处于 `idle` 状态时，客户端或服务器就会发送一个特殊的数据包给对方，当接收方收到这个数据报文后，也立即发送一个特殊的数据报文，回应发送方，此即一个 `PING-PONG` 交互。所以，当某一端收到心跳消息后，就知道了对方仍然在线，这就确保 TCP连接的有效性。

TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是TCP的选项：`SO_KEEPALIVE`。但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义心跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 `IdleStateHandler`

### Netty-零拷贝

Netty 中的零拷贝与操作系统层面上的不太一样，操作系统通过mmap或者sendfile来实现，Netty的零拷贝完全是在用户态层面的，他更偏向于优化数据操作这样的概念

- Netty 提供了 `CompositeByteBuf` 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝
- 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer等包装成一个 Netty ByteBuf 对象，进而避免了拷贝操作
- ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝
- 通过 `FileRegion` 包装的`FileChannel.tranferTo` 实现文件传输，可以直接将文件缓冲区的数据发送到目标 `Channel`，避免了传统通过循环 write 方式导致的内存拷贝问题

## Zookeeper

### 什么是Zookeeper

ZooKeeper 是一个开源的**分布式协调服务**，为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如**数据发布/订阅、负载均衡、**命名服务、分布式协调/通知、集群管理、**Master 选举、分布式锁和分布式队列**等功能。这些功能的实现主要依赖于 ZooKeeper 提供的 **数据存储+事件监听** 功能。

- 命名服务：可以通过 ZooKeeper 的顺序节点生成全局唯一 ID。
- 数据发布/订阅：通过 Watcher 机制 可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。
- 分布式锁：通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。分布式锁的实现也需要用到 Watcher 机制 ，我在 分布式锁详解 这篇文章中有详细介绍到如何基于 ZooKeeper 实现分布式锁。

ZooKeeper **将数据保存在内存中，性能是不错的。 在“读”多于“写”的应用程序中尤其地高性能**，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景）

很多顶级的开源项目都用到了 ZooKeeper，比如：

- **Kafka** : ZooKeeper 主要为 Kafka 提供 Broker 和 Topic 的注册以及多个 Partition 的负载均衡等功能。不过，在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构。
- **Hbase** : ZooKeeper 为 Hbase 提供确保整个集群只有一个 Master 以及保存和提供 regionserver 状态信息（是否在线）等功能。
- **Hadoop** : ZooKeeper 为 Namenode 提供高可用支持。

### ZooKeeper特点

- **顺序一致性**： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
- **原子性：** 所有事务请求的处理结果**在整个集群中所有机器上的应用情况是一致的**，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
- 单一系统映像： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
- **可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化**，直到被下一次更改覆盖。
- **实时性： 一旦数据发生变更，其他节点会实时感知到**。每个客户端的系统视图都是最新的。
- **集群部署：**3~5 台（最好奇数台）机器就可以组成一个集群，每台机器都在内存保存了 ZooKeeper 的全部数据，机器之间互相通信同步数据，客户端连接任何一台机器都可以。
- **高可用：**如果某台机器宕机，会保证数据不丢失**。集群中挂掉不超过一半的机器，都能保证集群可用**。比如 3 台机器可以挂 1 台，5 台机器可以挂 2 台

### -----Zookeeper重要概念------

### 1. Datamodel数据模型

**ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，**这些数据可以是数字、字符串或者是二进制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“/”来代表。每个数据节点在 ZooKeeper 中被称为 **znode**，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都有一个唯一的路径标识。

强调一句：**ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以不要放比较大的数据在 znode 上，ZooKeeper 给出的每个节点的数据大小上限是 1M 。**

### 2. znode数据节点

我们通常是将 znode 分为 4 大类：

- **持久（PERSISTENT）节点**：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。
- **临时（EPHEMERAL）节点**：临时节点的生命周期是与 **客户端会话（session）** 绑定的，**会话消失则节点消失**。并且，**临时节点只能做叶子节点** ，不能创建子节点。
- **持久顺序（PERSISTENT_SEQUENTIAL）节点**：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 `/node1/app0000000001`、`/node1/app0000000002` 。
- **临时顺序（EPHEMERAL_SEQUENTIAL）节点**：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性

每个 znode 由 2 部分组成:

- **stat**：状态信息
- **data**：节点存放的数据的具体内容

通过 get 命令来获取 根目录下的 dubbo 节点的内容

Stat 类中包含了一个数据节点的所有状态信息的字段**，包括事务 ID（cZxid）、节点创建时间（ctime） 和子节点个数（numChildren） 等等。**

| znode 状态信息 | 解释                                                         |
| -------------- | ------------------------------------------------------------ |
| cZxid          | create ZXID，即该数据节点被创建时的事务 id                   |
| ctime          | create time，即该节点的创建时间                              |
| mZxid          | modified ZXID，即该节点最终一次更新时的事务 id               |
| mtime          | modified time，即该节点最后一次的更新时间                    |
| pZxid          | 该节点的子节点列表最后一次修改时的事务 id，只有子节点列表变更才会更新 pZxid，子节点内容变更不会更新 |
| cversion       | 子节点版本号，当前节点的子节点每次变化时值增加 1             |
| dataVersion    | 数据节点内容版本号，节点创建时为 0，每更新一次节点内容(不管内容有无变化)该版本号的值增加 1 |
| aclVersion     | 节点的 ACL 版本号，表示该节点 ACL 信息变更次数               |
| ephemeralOwner | 创建该临时节点的会话的 sessionId；如果当前节点为持久节点，则 ephemeralOwner=0 |
| dataLength     | 数据节点内容长度                                             |
| numChildren    | 当前节点的子节点个数                                         |

### 3. 版本version

对应于每个 znode，ZooKeeper 都会为其维护一个叫作 Stat 的数据结构**，Stat 中记录了这个 znode 的三个相关的版本：**

- dataVersion：当前 znode 节点的版本号
- cversion：当前 znode 子节点的版本
- aclVersion：当前 znode 的 ACL 的版本

### 4. ACL权限控制

ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。

对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：

- **CREATE** : 能创建子节点
- **READ**：能获取节点数据和列出其子节点
- **WRITE** : 能设置/更新节点数据
- **DELETE** : 能删除子节点
- **ADMIN** : 能设置节点 ACL 的权限

其中尤其需要注意的是，**CREATE** 和 **DELETE** 这两种权限都是针对 **子节点** 的权限控制。

对于身份认证，提供了以下几种方式：

- **world**：默认方式，所有用户都可无条件访问。
- **auth** :不使用任何 id，代表任何已认证的用户。
- **digest** :用户名:密码认证方式：*username:password* 。
- **ip** : 对指定 ip 进行限制

### 5. Watcher事件监听器

Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper 允许用户在指定节点上注册一些 Watcher，**并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，**该机制是 ZooKeeper 实现分布式协调服务的重要特性。

<img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241019121836135.png" alt="image-20241019121836135" style="zoom:50%;" />

### 6. 会话Session

**Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接**，通过这个连接，**客户端能够通过心跳检测与服务器保持有效的会话，也**能够向 ZooKeeper 服**务器发送请求并接受响应**，同时还能**够通过该连接接收来自服务器的 Watcher 事件通知。**

Session 有一个属性叫做：`sessionTimeout` ，`sessionTimeout` 代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在`sessionTimeout`规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

另外，在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 `sessionID`。由于 `sessionID`是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 `sessionID` 的，因此，无论是哪台服务器为客户端分配的 `sessionID`，都务必保证全局唯一。

### ------Zookeeper集群--------

最典型集群模式**：Master/Slave 模式（主备模式）**。
在这种模式中，**通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提**供读服务

### Zookeeper集群角色

在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了 L**eader、Follower 和 Observer** 三种角色

|   角色   |                             说明                             |
| :------: | :----------------------------------------------------------: |
|  Leader  | **为客户端提供读和写的服务**，负责**投票的发起和决议**，更新系统状态。 |
| Follower | 为客户端提供读服务，如果是写服务则转发给 Leader。参与选举过程中的投票。 |
| Observer | 为客户端提供读服务，如果是写服务则转发给 Leader。<br />**不参与选举**过程中的投票，也**不参与“过半写成功”策略**。<br />在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色 |

### Zookeeper集群Leader选举过程

当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。

这个过程大致是这样的：

1. **Leader election（选举阶段）**：节点在一开始都处于选举阶段，**只要有一个节点得到超半数节点的票数，它就可以当选准 leader。**
2. **Discovery（发现阶段）**：在这个阶段**，followers 跟准 leader 进行通信，**同步 followers 最近接收的事务提议。
3. **Synchronization（同步阶段）**：**同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本**。同步完成之后准 leader 才会成为真正的 leader。
4. **Broadcast（广播阶段）**：到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。

ZooKeeper 集群中的服务器状态有下面几种：

- **LOOKING**：寻找 Leader。
- **LEADING**：Leader 状态，对应的节点为 Leader。
- **FOLLOWING**：Follower 状态，对应的节点为 Follower。
- **OBSERVING**：Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。

### Zookeeper集群奇数原因

ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，**如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。**
假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 n/2。先说一下结论，2n 和 2n-1 的容忍度是一样的，都是 n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。
比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。
假如我们有 5 台，那么最大允许宕掉 2 台 ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。
**综上，何必增加那一个不必要的 ZooKeeper 呢？**

### Zookeeper选举的过半机制

**何为集群脑裂？**
对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候**子集群各自选主导致“脑裂”的情况。**
举例说明：比如现在有一个由 6 台服务器所组成的一个集群，部署在了 2 个机房，每个机房 3 台。正常情况下只有 1 个 leader，但是当两个机房中间网络断开的时候，每个机房的 3 台服务器都会认为另一个机房的 3 台服务器下线，而选出自己的 leader 并对外提供服务。若没有过半机制，当网络恢复的时候会发现有 2 个 leader。仿佛是 1 个大脑（leader）分散成了 2 个大脑，这就发生了脑裂现象。脑裂期间 2 个大脑都可能对外提供了服务，这将会带来数据一致性等问题。
**过半机制是如何防止脑裂现象产生的？**

ZooKeeper 的**过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。**

### ------ZAB协议和Paxos算法-----

Paxos 算法应该可以说是 ZooKeeper 的灵魂了。**ZooKeeper 并没有完全采用 Paxos 算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法**。ZAB 协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为 Zookeeper 设计的崩溃可恢复的原子消息广播算法

ZAB（ZooKeeper Atomic Broadcast，原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，**ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性**

### ZAB协议的两种基本模式：崩溃恢复和消息广播

ZAB 协议包括两种基本的模式，分别是
**崩溃恢复：**当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致。
**消息广播：**当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。

### ------Zookeeper和ETCD-------

[ETCD](https://etcd.io/) 是一种强一致性的分布式键值存储，它提供了一种可靠的方式来存储需要由分布式系统或机器集群访问的数据。ETCD 内部采用 [Raft 算法](https://javaguide.cn/distributed-system/protocol/raft-algorithm.html)作为一致性算法，基于 Go 语言实现。

|             |                          ZooKeeper                           |                      ETCD                       |
| :---------: | :----------------------------------------------------------: | :---------------------------------------------: |
|    语言     |                             Java                             |                       Go                        |
|    协议     |                             TCP                              |                      Grpc                       |
|  接口调用   |                必须要使用自己的client进行调用                |  可通过Http传输，即可以通过CURL等命令进行调用   |
| 一致性算法  |                           zab协议                            |                    Raft算法                     |
| Watcher机制 |                    较为局限，一次性触发器                    |           一次watch可以监听所有的事件           |
|  数据模型   |                      基于目录的层次模式                      |      参考了zk的数据模型，是个扁平的kv模型       |
|    存储     | kv存储，使用的是ConcurrentHashMap，内存存储，一般不建议存储较多数据 | kv存储，使用bbolt存储引擎，可以处理几个gb的数据 |
|    MVCC     |                            不支持                            |      支持，可以通过两个b+tree进行版本控制       |
| 全局Session |                           存在缺陷                           |         实现更为灵活，避免了安全性问题          |
|  权限校验   |                             ACL                              |                      RABC                       |
|  事务能力   |                     提供了简易的事务能力                     |            只提供了版本号的检查能力             |
|  部署维护   |                             复杂                             |                      简单                       |

## RabbitMQ

### 什么是RabbitMQ

- 消息队列是一个使用队列来通信的组件。
- RabbitMQ是一个基于AMQP（Advanced Message Queueing Protocol）标准的消息中间件。

### RabbitMQ特点

- 可靠性：使用**持久化、传输确认、发布确认**等机制保证可靠性
- 灵活的路由：在消息进入队列之前，通过交换器路由消息。
  - 典型路由功能：提供内置交换器实现
  - 更复杂的路由功能：将多个交换器绑定在一起，也可以通过插件机制来实现自己的路由
- 扩展性：多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态的扩展集群中的节点。
- 高可用性：队列可以在集群中的机器上设置镜像，使得部分节点出现问题的情况下队列仍然可用。
- 多种协议：原生支持AMQP，还支持STOMP。MQTT等多种消息中间件协议。
- 多语言客户端：几乎支持所有常用语言
- 管理界面：提供一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。
- 插件机制：提供多种机制来扩展

### RabbitMQ核心概念

RabbitMQ 整体上是一个生产者与消费者模型，主要负责接收、存储和转发消息

![图1-RabbitMQ 的整体模型架构](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/96388546.jpg)

#### Producer 生产者和Consumer 消费者

- 消息由两部分组成

  - 消息头 Label

    由一系列的可选属性组成

    - routing-key 路由键
    - priority 优先级
    - delivery-mode 指出该消息可能需要持久性存储

  - 消息体 payLoad

    不透明

- 生产者把消息交由MQ以后，RabbitMQ会根据消息头把消息发送给感兴趣的消费者

#### Exchange 交换器

1. 在 RabbitMQ 中，消息并不是直接被投递到 **Queue(消息队列)** 中的，中间还必须经过 **Exchange(交换器)** 这一层，**Exchange(交换器)** 会把我们的消息分配到对应的 **Queue(消息队列)** 中。
2. **Exchange(交换器)** 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，**或许会返回给 Producer(生产者) ，或许会被直接丢弃掉** 。这里可以将 RabbitMQ 中的交换器看作一个简单的实体。
   1. **RabbitMQ 的 Exchange(交换器) 有 4 种类型，不同的类型对应着不同的路由策略**：**direct(默认)**，**fanout**, **topic**, 和 **headers**，不同类型的 Exchange 转发消息的策略有所区别



1. 生产者将消息发给交换器的时候，一般会指定一个Routing Key路由键，用来指定这个消息的路由规则，

   **这个Routingkey需要与交换器类型和绑定键bindkey联合使用才能生效**

2. Exchange交换器与Queue消息队列关联需要通过binding绑定，**在绑定的时候一般会指定一个bindingkey绑定键**，这样RabbitMQ就知道如何正确将消息路由到消息队列里。

3. **一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则**，所以可以将交换器理解成一个由绑定构成的路由表。Exchange和消息队列可以是多对多的关系



1. **生产者将消息发送给交换其实，需要一个RoutingKey**，当BindingKey和RoutingKey匹配时，消息会被路由到对应的队列中
2. 再绑定多个队列到同一个交换器的时候，允许使用相同的BindingKey，BindingKey并不是在所有情况下都生效，依赖于交换机的类型
   1. fanout类型的交换器就会无视，而是将消息路由到所有绑定到该交换器的队列中。

#### Queue 消息队列

- Queue(消息队列) 用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。
- **RabbitMQ 中消息只能存储在 队列 中，**这一点和 Kafka 这种消息中间件相反。Kafka 将消息存储在 topic（主题） 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。 **RabbitMQ 的生产者生产消息并最终投递到队列中，消费者可以从队列中获取消息并消费。**
- 多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免消息被重复消费。
  - RabbitMQ不支持队列层面的广播消费

#### Broker 消息中间件的服务节点

一个 RabbitMQ Broker 可以简单地看作一个 RabbitMQ 服务节点，或者 RabbitMQ 服务实例。大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。

![image-20241007190820073](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241007190820073.png)

![image-20241007190820073](D:\2024\Notes\Typora\项目rpc+im\image-20241007190820073.png)

#### Exchange Types 交换器类型

1. **fanout**

   1. 把所有发送到该 Exchange 的消息路由到所有与它绑定的 Queue 中
   2. 速度最快、用于广播消息

2. **direct**

   1. 把消息路由到那些 Bindingkey 与 RoutingKey 完全匹配的 Queue 中。
   2. 用于处理有优先级的任务，根据任务的优先级把消息发送到对应的队列，这样可以指派更多的资源去处理高优先级的队列。

3. **topic**

   1. 也是将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中
   2. 不同点：
      1. RoutingKey为一个点号“.”分割的字符串
      2. BindingKey和RoutingKey一样也是点号“.”分割的字符串
      3. BindingKey 中可以存在两种特殊字符串“\*”和“#”，用于做模糊匹配。其中“*”用于匹配一个单词，“#”用于匹配多个单词(可以是零个)。

4. **headers**

   根据发送的消息内容中的 headers 属性进行匹配

5. system

6. 自定义

### 什么是AMQP

RabbitMQ 就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定

1. AMQP 协议的三层：
   1. Module Layer:协议最高层，主要定义了一些**客户端调用的命令**，客户端可以用这些命令实现自己的业务逻辑。
   2. Session Layer:中间层，**主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理**。
   3. TransportLayer:最底层，**主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示等**。
2. AMQP模型的三大组件
   1. 交换器：消息代理服务器中用于把消息路由到队列的组件
   2. 队列：用来存储消息的数据结构，位于硬盘或者内存中
   3. 绑定：一套规则，告知交换器应该将消息投递到哪个队列中

### 说说生产者Producer和消费者Consumer

**生产者** :

- 消息生产者，就是投递消息的一方。
- 消息一般包含两个部分：消息体（`payload`)和标签(`Label`)。

**消费者**：

- 消费消息，也就是接收消息的一方。
- **消费者连接到 RabbitMQ 服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签**

### 说说Broker服务节点、Queue队列、Exchange交换器

- Broker：可以看做 RabbitMQ 的服务节点。一般情况下一个 Broker 可以看做一个 RabbitMQ 服务器。
- Queue：RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。
- Exchange：生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。

###  什么是死信队列？如何导致的？

DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，**它能被重新发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。**

导致的死信的几种原因：

- 消息**被拒**（Basic.Reject /Basic.Nack) 且 requeue = false。
- 消息 **TTL 过期。**
- **队列满了，无法再添加。**

### 什么是延迟队列？RabbitMQ怎么实现延迟队列

延迟队列指的是存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是**等待特定时间后，消费者才能拿到这个消息进行消费。**

RabbitMQ 本身是没有延迟队列的，要实现延迟消息，一般有两种方式：

1. 通过 RabbitMQ 本身队列的特性来实现，**需要使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。**
   1. 首先，需要创建一个 DLX，当消息过期时，这些消息将会被发送到 DLX 中。
   2. 接下来，创建一个普通的队列，并设置它的参数，使得当消息过期后，消息会发送到之前创建的 DLX 中
   3. 发送消息时，可以将消息发送到普通队列中。这些消息将在设定的时间后过期，并自动转移到 DLX。
   4. 最后，需要创建另一个队列来监听 DLX，并处理那些过期
2. 在 RabbitMQ 3.5.7 及以上的版本**提供了一个插件**（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang/OPT 18.0 及以上。

也就是说，AMQP 协议以及 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过 TTL 和 DLX 模拟出延迟队列的功能。

### 什么是优先级队列

RabbitMQ 自 V3.5.0 有优先级队列实现，优先级高的队列会先被消费。

可以通过`x-max-priority`参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义

### RabbitMQ有哪些工作模式

- 简单模式
- work 工作模式
- pub/sub 发布订阅模式
- Routing 路由模式
- Topic 主题模式

### RabbitMQ消息怎么传输

由于 **TCP 链接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈**，所以 **RabbitMQ 使用信道的方式来传输数据**。信道（Channel）是生产者、消费者与 RabbitMQ 通信的渠道，信道是**建立在 TCP 链接上的虚拟链接，且每条 TCP 链接上的信道数量没有限制。就是说 RabbitMQ 在一条 TCP 链接上建立成百上千个信道来达到多个线程处理**，这个 **TCP 被多个线程共享，每个信道在 RabbitMQ 都有唯一的 ID，保证了信道私有性，**每个信道对应一个线程使用

### 如何保证消息的可靠性

消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。

- 生产者到 RabbitMQ：**事务机制和 Confirm 机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。**
- RabbitMQ 自身：**持久化、集群、普通模式、镜像模式。**
- RabbitMQ 到消费者：**basicAck 机制、死信队列、消息补偿机制。**

### 如何保证RabbitMQ消息的顺序性

- 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；
- 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理

### 如何保证RabbitMQ高可用的

R**abbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，**我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。**RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。**

- 单机模式

  Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式。

- 普通集群模式

  意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。**你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（**元数据可以认为是 queue 的一些配置信息，**通过元数据，可以找到 queue 所在实例）。**

  你消费的时候，实际上**如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。**

- 镜像集群模式

  这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是**，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。**然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。**RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

  这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于**，第一，这个性能开销也太大了吧**，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据

### 如何解决消息队列的**延时以及过期失效**问题

RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果**消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，**这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

## TCP/IP四层体系分层结构

## HTTP/HTTPS

## TCP

### 三次握手

![image-20241020213837481](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241020213837481.png)

- 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态
- 客户端会随机初始化序号，把第一个 SYN 报文发送给服务端，表示向服务端发起连接，之后客户端处于 SYN-SENT 状态。
- 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。
- 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状

第三次握手是可以携带数据的，前两次握手是不可以携带数据的

### 为什么需要三次握手建立连接？

[计算机网络面试题 | 小林coding (xiaolincoding.com)](https://www.xiaolincoding.com/interview/network.html#tcp为什么需要三次握手建立连接)

- 三次握手才可以阻止重复历史连接的初始化（主要原因）
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪

### 第一次握手，客户端发送SYN报后，服务端回复ACK报，那这个过程中服务端内部做了哪些工作？

服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。

### 大量SYN包发送给服务端服务端会发生什么事情？

有可能会导致TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。
避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；
- 减少 SYN+ACK 重传次数

### TCP 四次挥手过程说一下？

![image-20241020215232534](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241020215232534.png)

具体过程：

- 客户端主动调用关闭连接的函数，于是就会发送 FIN 报文，这个 FIN 报文代表客户端不会再发送数据了，进入 FIN_WAIT_1 状态；
- 服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 CLOSE_WAIT 状态。在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以必须要得继续 read 接收缓冲区已接收的数据；
- 接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 2MSL 时间之后，也进入 CLOSE 状态

### 服务端出现大量的time-wait有哪些原因？

什么场景下**服务端会主动断开连接呢？**

- 第一个场景：**HTTP 没有使用长连接**

- 第二个场景：HTTP **长连接超时**

  如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。

- 第三个场景：HTTP **长连接的请求数量达到上限**

### TCP和UDP区别是什么

- 连接：**TCP 是面向连接的传输层协议**，传输数据前先要建立连接；**UDP 是不需要连接**，即刻传输数据。
- 服务对象：**TCP 是一对一的**两点服务，即一条连接只有两个端点。**UDP 支持一对一、一对多、多对多的交互通信**
- 可靠性：**TCP 是可靠交付数据的**，数据可以无差错、不丢失、不重复、按序到达。**UDP 是尽最大努力交付**，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，**比如 QUIC 协议**
  - **连接管理、序列号、确认应答、超时重传、流量控制、拥塞控制。**
- 拥塞控制、流量控制**：TCP 有拥塞控制和流量控制机制，**保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
- 首部开销：**TCP 首部长度较长**，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。**UDP 首部只有 8 个字节**，并且是固定不变的，开销较小。
- 传输方式**：TCP 是流式传输**，没有边界，但保证顺序和可靠**。UDP 是一个包一个包的发送**，是有边界的，但可能会丢包和乱序

## 操作系统进程管理

## 操作系统同步机制

## 操作系统虚拟内存

