# 自我介绍 

面试官您好，我是来自西安邮电大学计算机科学与技术专业的一名大三学生。
首先我来介绍一下我的大学经历：

在大一期间，我学习了c语言，数据结构与算法等基础知识，
进入大二后我选择java方向，开始接触javaweb，
也学习了spring，springboot等框架、mysql，redis等数据库，
rabbitMQ等中间件和比如说操作系统，计算机网络，等计算机基础知识。

在校期间我参加了四六级考试，获得了均分620+的成绩。、也参加了数模，蓝桥杯，程序设计天梯赛，并取得了一些不错的奖项。

学习期间我自己也开发了两个项目，

一个是一个即时通讯系统，我负责这个项目的后端开发，
支持好友、群组、私聊、群聊、离线消息拉取、发送文件等功能。
主要实现的是聊天功能，并通过结果监听机制确保信息能够投递成功。

那我主要介绍下简历上第一个项目，就是最近做的这个rpc的项目吧，
这个框架用到了Netty来进行网络通信，
通过自定义通信协议来解决粘包问题；
将Zookeeper作为注册中心和配置中心，
在客户端本地建立缓存，使用watcher来动态监听节点的变化;
再就是实现了多种负载均衡策略，也实现了比如说
超时重试、服务限流、服务熔断等多种功能。

目前感觉自己的开发能力还是比较有限，
希望能在贵公司进一步提升自己的开发能力和项目经验
谢谢面试官。

## 未来规划

希望能在这个业务领域里深耕,在未来3-5年内有一定的行业认可度; 
技术栈继续沉淀,空余时间研究些底层源码,
了解下目前的AI 大模型相的技术及应用方向

## 你的优势？

“作为一名Java程序员，我的优势在于我对Java语言的深入理解和对相关框架的熟练运用，比如Spring Boot、Hibernate等。我能够高效地进行代码编写，并且注重代码质量，确保可读性和可维护性。此外，我还擅长问题解决，能够快速定位并修复bug，保证软件系统的稳定运行。从软技能上来说，我有很强的学习能力，可以快速掌握新技术；同时我也具备良好的团队协作精神，这使得我在团队项目中能够与他人有效沟通，共同推动项目的进展。”

## 怎么处理同事关系？

“我认为建立和谐的同事关系对于提高工作效率至关重要。我会通过积极主动地与同事交流来增进了解，并尊重每个人的意见和工作风格。当出现分歧时，我会寻求开放而建设性的对话，以找到最佳解决方案。同时，我也乐于分享自己的知识和经验，帮助团队成员共同成长。我相信，通过相互支持和合作，我们可以一起实现团队目标。”

## 为什么选开发？

“选择成为开发人员是因为我对编程充满热情，并且热爱解决问题的过程。我喜欢面对挑战，用代码创造出有价值的产品或服务。在这个不断发展的领域里，总有新的东西可以学习，这让我感到非常兴奋。此外，作为开发人员，我有机会参与到从概念到实现的整个过程，看到自己编写的代码转化为实际应用，这种成就感是无价的。我希望能够在技术上不断进步，并为公司贡献自己的力量。”





## 面试问题：

一面：

- 几面？
- 进去以后做什么？

二面：

- 如果我有幸能加入咱们团队的话，您对实习生的期望是什么？
- 公司对新入职的员工的培养机制是什么样子的？

终面：

- 面试什么时候能有结果呢？
- 如果我有幸能加入咱们团队的话，您对实习生的期望是什么？

# 专业技能

- Java：熟悉Java基础知识、Java并发编程，掌握JUC中常用的工具类，如ConcurrentHashMap等。

- JVM：熟悉JVM的垃圾回收机制、类加载机制，了解Java的内存模型。

- MySQL：熟练使用 MySQL，熟悉 MySQL 索引、事务、存储引擎、锁机制。

- Redis：熟悉Redis常见数据类型，熟悉持久化和过期淘汰策略，掌握缓存穿透、缓存击穿、缓存雪崩。

- 常用框架：熟练使用Spring、SpringBoot、MyBatis等常用框架，熟悉 IoC 、AOP 原理，了解 Netty、

  Zookeeper、RabbitMQ等常见组件。

- 计算机网络：熟悉TCP/IP四层体系分层结构，掌握常见网络协议，如HTTP/HTTPS、TCP等。

- 操作系统：了解操作系统的进程管理、同步机制、虚拟内存等基础知识。

## ConcurrentHashMap

- ConcurrentHashMap是一个**线程安全**的HashMap

- **HashMap**

  - JDK1.8之前由数组+链表组成
    - 数组是主体
    - 链表是为了解决哈希冲突存在的
  - JDK1.8之后更新解决冲突的办法
    - 链表长度大于阈值（默认为8）
      - 当前数组长度小于64 
        - 进行数组扩容
      - 将链表转化为红黑树

- **Concurrent HashMap**

  - JDL1.8之前，使用**segment数组+HashEntry数组+链表**的底层数据结构，
    Segment 的每个元素包含一个 HashEntry 数组，每个 HashEntry 数组属于链表结构。
    Segment 继承了 ReentrantLock, 是一种可重入锁。HashEntry 用于存储键值对数据。
    每一把segment锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。

  - JDK1.8 的时候，摒弃了 Segment，**用 Node 数组+链表+红黑树的数据结构来实现，**

    - Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。当冲突链表达到一定长度时，链表会转换成红黑树。
    - 存储红黑树节点TreeNode被TreeBin包装。
      TreeBin通过root属性维护红黑树的根结点，因为红黑树在旋转的时候，根结点可能会被它原来的子节点替换掉，在这个时间点，如果有其他线程要写这棵红黑树就会发生线程不安全问题，
      所以在 ConcurrentHashMap 中TreeBin通过waiter属性维护当前使用这棵红黑树的线程，来防止其他线程的进入。
    - 锁粒度更细，**synchronized 只锁定当前链表或红黑二叉树的首节点**，只要 hash 不冲突，就不会产生并发，不会影响其他 Node 读写，效率提升。

  - JDK 1.8 主**要通过 volatile + CAS 或者 synchronized 来实现的线程安全的**。

    添加元素时**首先会判断容器是否为空：**

    1. **如果为空则使用 volatile 加 CAS 来初始化**
       如果容器不为空，则根据存储的元素**计算该位置是否为空。**
    2. **如果根据存储的元素计算结果为空，则利用 CAS 设置该节点；**
       1. 如果根据存储的元素计算结果不为空，**则使用 synchronized锁定当前链表或者红黑二叉树的首节点**，然后，遍历桶中的数据，并替换或新增节点到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。
       2. JDK 1.8 使用的是红黑树优化了之前的固定链表，当数据量比较大的时候，查询性能也得到提升，从 **O(n) 优化到了 O(logn) 的**时间复杂度。

- **LinkedHashMap：LinkedHashMap 继承自 HashMap，**增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑
- **Hashtable：数组+链表组成的，数组是 Hashtable 的主体，链表则主要为解决哈希冲突而存在的。**

## ConcurrentHashMap源码

[ConcurrentHashMap 源码分析 | JavaGuide](https://javaguide.cn/java/collection/concurrent-hash-map-source-code.html)

### 1.7 存储结构

ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 **Segment 的个数一旦初始化就不能改变**，默认 Segment 的个数是 16 个，也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发处理。

### 1.7 初始化

1. 对初始化容量、负载因子、默认并发级别进行参数校验

2. 校验并发级别 concurrencyLevel 大小，如果大于最大值，重置为最大值。无参构造默认值是 16.

3. 寻找并发级别 concurrencyLevel 之上最近的 2 的幂次方值，作为初始化容量大小，默认是 16。

4. 记录 segmentShift 偏移量，这个值为【容量 = 2 的 N 次方】中的 N，在后面 Put 时计算位置时会用到。默认是 32 - sshift = 28.

   > segmentShift记录的是每个段(segment)的哈希码空间的左移位数，它决定了如何根据哈希码来计算元素应该放置在哪一个段中

5. 记录 segmentMask，默认是 ssize - 1 = 16 -1 = 15.

   > segmentMask是用来辅助计算元素应该放置在哪个段的位置

6. 初始化 segments[0]，默认大小为 2，负载因子 0.75，扩容阀值是 2*0.75=1.5，插入第二个值时才会进行扩容

### 1.7 put

1. **计算要 put 的 key 的位置，获取指定位置的 Segment。**

2. **如果指定位置的 Segment 为空，则初始化这个 Segment.**

   初始化 Segment 流程：

   1. 检查计算得到的位置的 Segment 是否为 null.
   2. 为 null 继续初始化，使用 Segment[0] 的容量和负载因子创建一个 HashEntry 数组。
   3. 再次检查计算得到的指定位置的 Segment 是否为 null.
   4. 使用创建的 HashEntry 数组初始化这个 Segment.
   5. 自旋判断计算得到的指定位置的 Segment 是否为 null，使用 CAS 在这个位置赋值为 Segment.

3. **Segment.put 插入 key,value 值。**

   由于 Segment 继承了 ReentrantLock，所以 Segment 内部可以很方便的获取锁，put 流程就用到了这个功能。

   1. tryLock() 获取锁，获取不到使用 scanAndLockForPut 方法继续获取。

   2. 计算 put 的数据要放入的 index 位置，然后获取这个位置上的 HashEntry 。

   3. 遍历 put 新元素，为什么要遍历？因为这里获取的 HashEntry 可能是一个空元素，也可能是链表已存在，所以要区别对待。
      如果这个位置上的 HashEntry 不存在：

      1. 如果当前容量大于扩容阀值，小于最大容量，进行扩容。
      2. 直接头插法插入。

      如果这个位置上的 HashEntry 存在：

      1. 判断链表当前元素 key 和 hash 值是否和要 put 的 key 和 hash 值一致。一致则替换值
      2. 不一致，获取链表下一个节点，直到发现相同进行值替换，或者链表表里完毕没有相同的。
         1. 如果当前容量大于扩容阀值，小于最大容量，进行扩容。
         2. 直接链表头插法插入。

4. **如果要插入的位置之前已经存在，替换后返回旧值，否则返回 null.**
   这里面的第一步中的 scanAndLockForPut 操作这里没有介绍，这个方法做的操作就是不断的自旋 tryLock() 获取锁。当自旋次数大于指定次数时，使用 lock() 阻塞获取锁。在自旋时顺表获取下 hash 位置的 HashEntry。

### 1.7 扩容rehash

ConcurrentHashMap 的扩容只会扩容到原来的两倍。
老数组里的数据移动到新的数组时，位置要么不变，要么变为 `index+ oldSize`，参数里的 node 会在扩容之后使用链表**头插法**插入到指定位置。

- 如果元素的哈希值与旧数组的大小（oldSize）进行计算后的结果使得它落在了原来的位置，那么这个元素的新位置就不会改变。
  如果元素的哈希值经过某种运算后，使得它需要移动到新位置，那么这个新位置可以通过原来的索引加上旧数组的大小（index + oldSize）来计算得出。

### 1.7 get

- 计算得到 key 的存放位置。
- 遍历指定位置查找相同 key 的 value 值。

### 1.8 存储结构

### 1.8 初始化initTable

从源码中可以发现 `ConcurrentHashMap` 的初始化是通过**自旋和 CAS** 操作完成的。里面需要注意的是变量 `sizeCtl` （sizeControl 的缩写），它的值决定着当前的初始化状态。

1. -1 说明正在初始化，其他线程需要自旋等待
2. -N 说明 table 正在进行扩容，高 16 位表示扩容的标识戳，低 16 位减 1 为正在进行扩容的线程数
3. 0 表示 table 初始化大小，如果 table 没有初始化
4. \>0 表示 table 扩容的阈值，如果 table 已经初始化

### 1.8 put

1. 根据 key 计算出 hashcode 。
2. 判断是否需要进行初始化。
3. 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
4. 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。
5. 如果都不满足，则利用 synchronized 锁写入数据。
6. 如果数量大于 TREEIFY_THRESHOLD 则要执行树化方法，在 treeifyBin 中会首先判断当前数组长度 ≥64 时才会将链表转换为红黑树

### 1.8 get

1. 根据 hash 值计算位置。
2. 查找到指定位置，如果头节点就是要找的，直接返回它的 value.
3. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。
4. 如果是链表，遍历查找

## 垃圾回收机制

**垃圾回收（Garbage Collection, GC）是自动管理内存的一种机制，**它负责自动释放不再被程序引用的对象所占用的内存。



### 垃圾回收触发

- **内存不足时：**当JVM检测到堆内存不足，无法为新的对象分配内存时，会自动触发垃圾回收。
- **手动请求：**虽然垃圾回收是自动的，开发者可以通过调用 System.gc() 或 Runtime.getRuntime().gc() 建议 JVM 进行垃圾回收。不过这只是一个建议，并不能保证立即执行。
- JVM参数：启动 Java 应用时可以**通过 JVM 参数来调整垃圾回收的行为，**比如：-Xmx（最大堆大小）、-Xms（初始堆大小）等。
- **对象数量或内存使用达到阈值**：垃圾收集器内部实现了一些策略，以监控对象的创建和内存使用，达到某个阈值时触发垃圾回收



### 垃圾收集算法

1. 标记-清除算法

标记-清除（Mark-and-Sweep）算法分为“标记（Mark）”和“清除（Sweep）”阶段：首先通过可达性分析，**标记出所有需要回收的对象，然后统一回收所有被标记的对象。**

- 效率问题：标记和清除两个过程**效率都不高。**
- 空间问题：标记清除后**会产生大量不连续的内存碎片。**

2. 复制算法

为了解决标记-清除算法的效率和内存碎片问题，复制（Copying）收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。**当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。**这样就使每次的内存回收都是对内存区间的一半进行回收。

- **可用内存变小**：可用内存缩小为原来的一半。
- **不适合老年代：**如果存活对象数量比较大，复制性能会变得很差。

3. 标记-整理（压缩）算法

标记-整理（Mark-and-Compact）算法是**根据老年代的特点提出的一种标记算法**，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是**让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。**

4. 分代收集算法

当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，**只是根据对象存活周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。**

比如**在新生代中，每次收集都会有大量对象死去，所以可以选择“复制”算法**，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而**老年代的对象存活几率是比较高的**，而且没有额外的空间对它进行分配担保，所以我们必须选择“**标记-清除”或“标记-整理”算法进行垃圾收集。**



### minorGC、majorGC、fullGC的区别，什么场景触发fullGC

在Java中，垃圾回收机制是自动管理内存的重要组成部分。根据其作用范围和触发条件的不同，可以将GC分为三种类型：Minor GC（也称为Young GC）、Major GC（有时也称为Old GC）、以及Full GC。以下是这三种GC的区别和触发场景：

- Minor GC (Young GC)

  - 作用范围：只**针对年轻代进行回收，包括Eden区和两个Survivor区（S0和S1）。**
  - 触发条件：**当Eden区空间不足时，JVM会触发一次Minor GC，将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代（Old Generation）**。
  - 特点：通常发生得非常频繁，因为年轻代中对象的生命周期较短，回收效率高，暂停时间相对较短。

- Major GC

  - 作用范围：**主要针对老年代进行回收，但不一定只回收老年代**。
  - 触发条件：当老年代空间不足时，或者系统检测到年轻代对象晋升到老年代的速度过快，可能会触发Major GC。
  - 特点：相比Minor GC，Major GC发生的频率较低，但每次回收可能需要更长的时间，因为老年代中的对象存活率较高。

- Full GC

  - 作用范围：**对整个堆内存（包括年轻代、老年代以及永久代/元空间）进行回收。**

  - 触发条件：

    - **直接调用System.gc()或Runtime.getRuntime().gc()方法时，虽然不能保证立即执行，但JVM会尝试执行Full GC。**
    - Minor GC（新生代垃圾回收）时**，如果存活的对象无法全部放入老年代，或者老年代空间不足以容纳存活的对象，则会触发Full GC，对整个堆内存进行回收。**
    - **当永久代（Java 8之前的版本）或元空间（Java 8及以后的版本）空间不足时**。

  - 特点：Full GC是最昂贵的操作，因为它需要停止所有的工作线程（Stop The World），遍历整个堆内存来查找和回收不再使用的对象，因此应尽量减少Full GC的触发

    

### 垃圾收集器

![image-20241021082619725](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241021082619725.png)

### G1和CMS区别

##### CMS和G1区别？

1. 区别一：使用的范围不一样：

   **CMS收集器是老年代的收集器，**可以配合新生代的Serial和ParNew收集器一起使用

   **G1收集器收集范围是老年代和新生代。**不需要结合其他收集器使用

2. 区别二：STW的时间：

   **CMS收集器以最小的停顿时间为目标的收集器**。

   **G1收集器可预测垃圾回收 (opens new window)的停顿时间**（建立可预测的停顿时间模型）

3. 区别三： 垃圾碎片

   CMS收集器是使用“**标记-清除”算法进行的垃圾回收，容易产生内存碎片**

   G1收集器使用的是“**标记-整理”算法，进行了空间整合，没有内存空间碎**片。

4. 区别四： **垃圾回收的过程不一样**

   CMS收集器：初始标记、并发标记、重新标记、并发清楚

   G1收集器：初始标记、并发标记、最终标记、筛选回收

5. 区别五: CMS会产生浮动垃圾
   **CMS产生浮动垃圾过多时会退化为serial old**，效率低，因为在上图的第四阶段，CMS清除垃圾时是并发清除的，这个时候，垃圾回收线程和用户**线程同时工作会产生浮动垃圾，也**就意味着CMS垃圾回收器必须预留一部分内存空间用于存放浮动垃圾
   而G1没有浮动垃圾，**G1的筛选回收是多个垃圾回收线程并行gc的，没有浮动垃圾的回收，在执行‘并发清理’步骤时，用户线程也会同时产生一部分可回收对象，但是这部分可回收对象只能在下次执行清理是才会被回收**。如果在清理过程中预留给用户线程的内存不足就会出现‘Concurrent Mode Failure’,一旦出现此错误时便会切换到SerialOld收集方式

## 类加载机制

### 类加载过程

#### 加载

1. **通过全类名获取定义此类的二进制字节流。**
2. **将字节流所代表的静态存储结构转换为方法区的运行时数据结构。**
3. 在**内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口。**

加载这一步主要是通过我们后面要讲到的 **类加载器** 完成的。类加载器有很多种，当我们想要加载一个类的时候，具体是**哪个类加载器加载由 双亲委派模型 决定**

#### 验证

验证是连接阶段的第一步，这一阶段的目的是确保 Class 文件的字节流中包含的信息符合《Java 虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。

1. **文件格式验证**（Class 文件格式检查）
2. **元数据验证**（字节码语义检查）
3. **字节码验证**（程序语义检查）
4. **符号引用验证**（类的正确性检查）

#### 准备

准备阶段是正式为类变量分配内存并设置类变量初始值的阶段

#### 解析

解析阶段是虚拟机将常量池内的**符号引用替换为直接引用的**过程

#### 初始化

初始化阶段是执行初始化方法 <clinit> ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。

#### 类卸载

卸载类即该类的 Class 对象被 GC。
卸载类需要满足 3 个要求:

- 该类的**所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。**
- 该类**没有在其他任何地方被引用**
- 该类的类加载器的**实例已被 GC**

所以，在 JVM 生命周期内**，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。**

### 类加载器详解

#### 类加载器

##### 类加载器介绍

类加载器的主要作用是**加载 Java 类的字节码（ .class 文件）到 JVM 中（**在内存中生成一个代表该类的 Class 对象）。

- 类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步。
- **每个 Java 类都有一个引用指向加载它的 ClassLoader。**
- **数组类不是通过 ClassLoader 创建的**（数组类没有对应的二进制字节流），**是由 JVM 直接生成**

##### 类加载器加载规则

- JVM 启动的时候，并不会一次性加载所有的类，**而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载，这样对内存更加友好。**
- 对于已经加载的类会被放在 ClassLoader 中。在类加载的时候，系统**会首先判断当前类是否被加载过**。已经被加载的类会直接返回，否则才会尝试加载。也就是说，对于一个类加载器来说，相同二进制名称的类只会被加载一次。

##### 类加载器总结

- **BootstrapClassLoader(启动类加载器)：**最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要**用来加载 JDK 内部的核心类库**（ %JAVA_HOME%/lib目录下的 rt.jar、resources.jar、charsets.jar等 jar 包和类）以及被 -Xbootclasspath参数指定的路径下的所有类。
- **ExtensionClassLoader(扩展类加载器)**：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类以及被 java.ext.dirs 系统变量所指定的路径下的所有类。
- **SystemClassLoader系统类加载器/AppClassLoader(应用程序类加载器)**：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。
- 用户自定义类加载器

> 这些类加载器之间的关系形成了**双亲委派模型，其核心思想是当一个类加载器收到类加载的请求时，首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中。**
> 只有**当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载**

除了 BootstrapClassLoader 是 JVM 自身的一部分之外，其他所有的类加载器都是在 JVM 外部实现的，并且全都继承自 ClassLoader抽象类。这样做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。

为什么 获取到 ClassLoader 为null就是 BootstrapClassLoader 加载的呢？ 这是因为BootstrapClassLoader 由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null。

##### 自定义类加载器

- 除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。如果我们要自定义自己的类加载器，很明显需要继承 ClassLoader抽象类。
- ClassLoader 类有两个关键的方法：
  - protected Class loadClass(String name, boolean resolve)：**加载指定二进制名称的类，实现了双亲委派机制** 。name 为类的二进制名称，resolve 如果为 true，在加载时调用 resolveClass(Class<?> c) 方法解析该类。
  - protected Class findClass(String name)：根据类的二进制名称来查找类，默认实现是空方法。
  - 如果我们不**想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可**，无法被父类加载器加载的类最终会通过这个方法被加载。但是，**如果想打破双亲委派模型则需要重写 loadClass()** 方法。

#### 双亲委派模型

##### 双亲委派模型介绍

- ClassLoader 类使用委托模型来搜索类和资源。
- 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。
- ClassLoader 实例会在试图亲自查找类或资源之前，将搜索类或资源的任务委托给其父类加载器。

​		**自顶向下尝试加载类、自底向上查找判断类是否被加载**

- 类加载器之间的父子关系一般不是以继承的关系来实现的，而是**通常使用组合关系来复用父加载器的代码。**
- 在面向对象编程中，有一条非常经典的设计原则：**组合优于继承，多用组合少用继承**

##### 执行流程

1. 在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载（每个父类加载器都会走一遍这个流程）。
2. 类加载器在进行类加载的时候，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成（调用父加载器 loadClass()方法来加载类）。这样的话，所有的请求最终都会传送到顶层的启动类加载器 BootstrapClassLoader 中。
3. 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 findClass() 方法来加载类）。
4. 如果子类加载器也无法加载这个类，那么它会抛出一个 ClassNotFoundException 异常

JVM 判定两个 Java 类是否相同的具体规则**：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。**

##### 好处

1. **保证类的唯一性：**通过委托机制，确保了所有加载请求都会传递到启动类加载器，避免了不同类加载器重复加载相同类的情况，**保证了Java核心类库的统一性，也防止了用户自定义类覆盖核心类库的可能。**
2. **保证安全性**：由于Java核心库被启动类加载器加载，而启动类加载器只加载信任的类路径中的类，这样可以**防止不可信的类假冒核心类**，增强了系统的安全性。例如，恶意代码无法自定义一个java.lang.System类并加载到JVM中，因为这个请求会被委托给启动类加载器，而启动类加载器只会加载标准的Java库中的类。
3. **支持隔离和层次划分**：双亲委派模型支持不同层次的类加载器服务于不同的类加载需求，如应用程序类加载器加载用户代码，扩展类加载器加载扩展框架，启动类加载器加载核心库。这种层次化的划分有助于实现沙箱安全机制，保证了各个层级类加载器的职责清晰，也便于维护和扩展。
4. **简化了加载流程**：通过委派，大部分类能够被正确的类加载器加载，减少了每个加载器需要处理的类的数量，简化了类的加载过程，提高了加载效率

##### 打破双亲委派模型方法

**如果想打破双亲委派模型则需要重写父类 loadClass()** 方法。

## Java的内存模型

在虚拟机自动内存管理机制下， Java 程序员**把内存控制权利交给 Java 虚拟机**

JDK1.7 

- 线程共享
  - 堆
    - 字符串常量池
  - 方法区
    - 运行时常量池
  
  - 线程私有
    - 虚拟机栈
    - 本地方法栈
    - 程序计数器
  - 本地内存-属于操作系统的本地内存，可以直接操作。
    - 直接内存
- JDK1.8
  - 线程共享
    - 堆
      - 字符串常量池
  - 线程私有不变
    - 虚拟机栈
    - 本地方法栈
    - 程序计数器
  - 本地内存
    - 直接内存
    - 元空间
      - 运行时常量池

### 程序计数器

程序计数器主要有两个作用：

- 字节码解释器**通过改变程序计数器来依次读取指令，从而实现代码的流程控制**，如：顺序执行、选择、循环、异常处理。
- 在多线程的情况下，程序计数器**用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。**

⚠️ 注意：程序计数器是唯一一个**不会出现 OutOfMemoryError** 的内存区域**，它的生命周期随着线程的创建而创建，随着线程的结束而死亡**

### Java虚拟机栈

- Java 虚拟机栈（后文简称栈）也是线程私有的，它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。
- **除了一些 Native 方法调用是通过本地方法栈实现的(后面会提到)，其他所有的 Java 方法调用都是通过栈来实现**的（也需要和其他运行时数据区域比如程序计数器配合）。
- 方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。
  - 每个栈帧中都拥有：**局部变量表、操作数栈、动态链接、方法返回地址**
    - 局部变量表
      - **存放了编译期可知的各种数据类型**
        （boolean、byte、char、short、int、float、long、double）、
      - **对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用**指针**，也可能是指向一个代表对象的**句柄**或其他与此对象相关的位置）。
    - 操作数栈
      - 主要作为方法调用的中转站使用，用于**存放方法执行过程中产生的中间计算结果。**
      - 另外，计算过程中**产生的临时变量也**会放在操作数栈中。
    - 动态链接
      - Class 文件的常量池里保存有大量的符号引用。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用
      - 动态链接的作用就是为了**将符号引用转换为调用方法的直接引用，**这个过程也被称为 动态连接 。
    - 方法返回地址
- 简单总结一下程序运行中栈可能会出现两种错误：
  - StackOverFlowError： 若栈的内存大小**不允许动态扩展**，那么当线程请求栈的深度超过当前 Java 虚拟机栈的**最大深度**的时候，就抛出 StackOverFlowError 错误。
  - OutOfMemoryError： 如果栈的内存大小**可以动态扩展**， 如果虚拟机在动态扩展栈时**无法申请到足够的内存空间**，则抛出OutOfMemoryError异常。

### 本地方法栈

虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而**本地方法栈则为虚拟机使用到的 Native 方法服务**。在 **HotSpot 虚拟机中和 Java 虚拟机栈合二为一。**

### 堆

在**虚拟机启动时创建**。此内存区域的唯一目的就是**存放对象实例**，**几乎**所有的对象实例以及数组都在这里分配内存

- 从 JDK 1.7 开始已经默认开启逃逸分析，**如果某些方法中的对象引用没有被返回或者未被外面使用（**也就是未逃逸出去），那么**对象可以直接在栈上分配内存。**

Java 堆是**垃圾收集器管理的主要区域**，因此也被称作 **GC 堆（Garbage Collected Heap）**

- 由于现在收集器基本都采用**分代垃圾收集算法**，所以 Java 堆还可以细分为：**新生代和老年代；**再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是**更好地回收内存，或者更快地分配内存。**

- JDk7及以前，堆内存被分配为以下部分

  - **新生代内存(Young Generation)**

    - **eden**

      在Eden Space中， 大多数新创建的对象首先存放在这里**。Eden区相对较小，当Eden区满时，会触发一次Minor GC（新生代垃圾回收）**

    - **survivor**

      在Survivor Spaces中，通常分为两个相等大小的区域，称为S0（Survivor 0）和S1（Survivor 1）。

      **在每次Minor GC后，存活下来的对象会被移动到其中一个Survivor空间**，以继续它们的生命周期**。这两个区域轮流充当对象的中转站，帮助区分短暂存活的对象和长期存活的对象。**

  - **老生代(Old Generation)（15岁之后）**

    **存放过一次或多次Minor GC仍存活的对象会被移动到老年代。老年代中的对象生命周期较长，因此Major GC（也称为Full GC，涉及老年代的垃圾回收）发生的频率相对较低，但其执行时间通常比Minor GC长**。老年代的空间通常比新生代大，以存储更多的长期存活对象。

  - **永久代(Permanent Generation)**

- JDK 8 版本之后 **PermGen(永久代) 已被 Metaspace(元空间) 取代，元空间使用的是本地内存。**

  **元空间用于存储类的元数据信息，如类的结构信息（如字段、方法信息等）。**元空间并不在Java堆中，而是使用本地内存，这解决了永久代容易出现的内存溢出问题。

- 大对象区（Large Object Space / Humongous Objects）:**在某些JVM实现中（如G1垃圾收集器），为大对象分配了专门的区域，称为大对象区或Humongous Objects区域。**大对象是指需要**大量连续内存空间的对象**，如大数组。这**类对象直接分配在老年代，以避免因频繁的年轻代晋升而导致的内存碎片化问题。**

#### 字符串常量池

字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

JDK 1.7 为什么要将字符串常量池移动到堆中？

主要是因为**永久代（方法区实现）的 GC 回收效率太低**，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，**将字符串常量池放到堆中，能够更高效及时地回收字符串内存。**

### 方法区

当虚拟机要使用一个类时，它需要**读取并解析 Class 文件获取相关信息，再将信息存入到方法区。**方法区会存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存**等数据。

- **类信息：**包括类的结构信息、类的访问修饰符、父类与接口等信息。
- **常量池**：存储类和接口中的常量，包括字面值常量、符号引用，以及运行时常量池。
- **静态变量**：存储类的静态变量，这些变量在类初始化的时候被赋值。
- **方法字节码**：存储类的方法字节码，即编译后的代码。
- **符号引用**：存储类和方法的符号引用，是一种直接引用不同于直接引用的引用类型。
- **运行时常量池**：存储着在类文件中的常量池数据，在类加载后在方法区生成该运行时常量池。
- **常量池缓**存：用于提升类加载的效率，将常用的常量缓存起来方便使用

- **永久代以及元空间**是 HotSpot 虚拟机对虚拟**机规范中方法区**的两种实现方式
- 并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。
  - 整个**永久代有一个 JVM 本身设置的固定大小上限，无法进行调整**（也就是受到 JVM 内存的限制），而元空间**使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。**
  - **元空间里面存放的是类的元数据**，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由**系统的实际可用空间来控制，这样能加载的类就更多了。**
  - 在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。
  - **永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。**

#### 运行时常量池

Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于**存放编译期生成的**各种**字面量**（Literal）和**符号引用**（Symbolic Reference）的 **常量池表**(Constant Pool Table) 。

常量池表会在类加载后存放到方法区的运行时常量池中.

### 直接内存

直接内存**是一种特殊的内存缓冲区**，并不在 Java 堆或方法区中分配的，而是通过 JNI 的方式在本地内存上分配的。

### Java内存模型里的堆和栈有什么区别？

- 用途**：栈主要用于存储局部变量、方法调用的参数、方法返回地址以及一些临时数据。**每当一个方法被调用，一个栈帧（stack frame）就会在栈中创建，用于存储该方法的信息，当方法执行完毕，栈帧也会被移除。堆**用于存储对象的实例（包括类的实例和数组）。**当你使用new关键字创建一个对象时，对象的实例就会在堆上分配空间。
- 生命周期：栈中的数据具有确定的生命周期，**当一个方法调用结束时，其对应的栈帧就会被销毁，栈中存储的局部变量也会随之消失**。堆**中的对象生命周期不确定，对象会在垃圾回收机制（Garbage Collection, GC）检测到对象不再被引用时才被回收。**
- 存取速度：**栈的存取速度通常比堆快，因为栈遵循先进后出**（LIFO, Last In First Out）的原则，操作简单快速。堆的存取速度相对较慢，因为对象在堆上的分配和回收需要更多的时间，而**且垃圾回收机制的运行也会影响性能。**
- 存储空间：**栈的空间相对较小，且固定，由操作系统管理。当栈溢出时，通常是因为递归过深或局部变量过大**。堆的**空间较大，动态扩展，由JVM管理。**堆溢出通常是由于创建了太多的大对象或未能及时回收不再使用的对象。
- 可见性：**栈中的数据对线程是私有的**，每个线程有自己的栈空间。**堆中的数据对线程是共享的**，所有线程都可以访问堆上的对象

### 内存泄漏和内存溢出的理解？

#### 内存泄漏

内存泄漏是指**程序在运行过程中不再使用的对象仍然被引用，而无法被垃圾收集器回收，从而导致可用内存逐渐减少。**虽然在Java中，垃圾回收机制会自动回收不再使用的对象，但如果有对象仍被不再使用的引用持有，垃圾收集器无法回收这些内存，最终可能导致程序的内存使用不断增加。

内存泄漏常见原因?

- 静态集合：**使用静态数据结构（如HashMap或ArrayList）存储对象，且未清理。**
- 事件监听：**未取消对事件源的监听，导致对象持续被引用**。
- 线程：**未停止的线程可能持有对象引用，无法被回收。**

#### 内存溢出

内存溢出是指Java虚拟机（JVM）在申请内存时，无法找到足够的内存，最终引发OutOfMemoryError。这通常**发生在堆内存不足以存放新创建的对象时。**

内存溢出常见原因？

- **大量对象创建**：程序中不断创建大量对象，超出JVM堆的限制。
- **持久引**用：大型数据结构（如缓存、集合等）长时间持有对象引用，导致内存累积。
- **递归调用**：深度递归导致栈溢出

### jvm内存结构有哪几种内存溢出的情况

- **堆内存溢出：**当出现java.lang.OutOfMemoryError:Java heap space异常时，就是堆内存溢出了。原因是**代码中可能存在大对象分配，或者发生了内存泄露，**导致**在多次GC之后，还是无法找到一块足够大的内存容纳当前对象。**
- **栈溢出**：如果我们写一段程序**不断的进行递归调用**，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。
- **元空间溢出：**元空间的溢出，系统会抛出java.lang.OutOfMemoryError: Metaspace。出现这个异常的问题的原因是**系统的代码非常多或引用的第三方包非常多或者通过动态代码生成类加载等方法，**导致元空间的内存占用很大。
- **直接内存内存溢出**：在使用ByteBuffer中的allocateDirect()的时候会用到，很多javaNIO(像netty)的框架中被封装为其他的方法，出现该问题时会抛出java.lang.OutOfMemoryError: Direct buffer memory异常。

## MYSQL索引

### 索引的分类？

- **按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。**
- 为什么InnoDB选择B+tree作为索引的数据结构？
  - b tree：B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。
  - 二叉树：对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。**数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操。**而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。
  - hash：**Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询，它更适合做等值的查**
- **按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）（唯一索引、普通索引、前缀索引都属于二级索引）。**
- **按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。**
- **按「字段个数」分类：单列索引、联合索引。**

### 索引优化和索引失效

- 前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。
- 覆盖索引优化：覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。
- 主键索引最好是自增的：
  - 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。**因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。**
  - 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，**因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。**
- 防止索引失效：
  - 当我们使**用左或者左右模糊匹配**的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；
  - 当我们在查询条件中**对索引列做了计算、函数、类型转换操作，**这些情况下都会造成索引失效；
  - **联合索引要能正确使用需要遵循最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
    - 联合索引（Composite Index）是指在数据库表中创建的一个索引，该索引包含多个列。创建联合索引的目的通常是优化查询性能，特别是在涉及多列的WHERE子句或者JOIN操作的查询中。
      联合索引的工作原理
      当数据库引擎在处理查询时，会首先检查是否有合适的索引可以使用。如果有联合索引可用，那么数据库引擎会从索引的第一列开始，逐步按顺序检查每一列，直到找到满足条件的行为止
  - **在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，**那么索引会失效

### **count(*) = count(1)>count(主键字段)>count(字段)**

## MYSQL事务

### 事务有哪些特性？

1. 原子性是通过 **undo log（回滚日志）** 来保证的；
2. 隔离性是通过 **MVCC（多版本并发控制） 或锁机制**来保证的；
3. 持久性是通过 **redo log （重做日志**）来保证的；
4. 一致性则是通过持久性+原子性+隔离性来保证；

### 并行事务会引发什么问题？

#### 脏读

- 如果一个事务「**读到」了另一个「未提交事务修改过的数据」，**就意味着发生了「脏读」现象。
- 即a修改了没提交被b读到

#### 不可重复读

- 在一个事务内多次读取同一个数据，如果出现前后两次读到的**数据不一样**的情况，就意味着发生了「不可重复读」现象。
  - 描述的是在一个事务内，对某条数据的两次**读取**之间，由于其他事务对该数据进**行了修改或删除，导致第一次读取和第二次读取的结果不同。**

- b先读，a提交b再读，前后读取数据不一样

#### 幻读

- 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的**记录数量不一样**的情况，就意味着发生了「幻读」现象。
  - 描述的是在一个事务内，对一组数据（如通过范围查询得到的数据集合）的两次读取之间，**由于其他事务插入了新的数据，**导致第一次**读取**和第二次读取的**结果集数量不同。**

- 前后读取的记录数量不一致

**幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。**执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。

### 事务的隔离级别

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；

- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；

  读提交隔离级别是在**每次读取数据时，都会生成一个新的 Read View。**

- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
  '可重复读隔离级别是**启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。**

- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

  - **实现：是通过行级锁来实现的，序列化隔离级别下，普通的 select 查询是会对记录加 S 型的 next-key 锁，其他事务就没没办法对这些已经加锁的记录进行增删改操作了，从而避免了脏读、不可重复读和幻读现象**

### ReadView在MVCC里如何工作？

**当前活跃事务的事务id列表，当前活跃事务id最小的事务，创建readview时数据库给下一个事务的id，该事务的id**

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

1. 如果记录的 **trx_id** 值小于 Read View 中的 **min_trx_id** 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。

2. 如果记录的 trx_id 值大于等于 Read View 中的 **max_trx_id** 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。

3. 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 **m_ids** 列表中：

   1. 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
   2. 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

   这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。

### 可重复读隔离完全解决幻读了吗？

MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种：

- 针对快照读（**普通 select 语句**），**是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。**
- 针对当前读（**select ... for update 等语句**），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。**

**可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。**

- 第一个例子：**对于快照读**， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。
  - 在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。                                                                                                                                                                
  - **即a一开始查id为为5的，b插入一个id为5的，由于mvcc现在看不到，然后a对id为5的进行更新，这个时候b插入的记录隐藏列的值为a的id，对a可见，a再次查询，就和第一次查的不一样。**
- 第二个例子：**对于当前读**，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。
  - **即一开始select，后来b插入，这时selectforupdate**
- 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

#### MYSQL transaction

Spring的事务会在什么情况下失效？

Spring Boot通过Spring框架的事务管理模块来支持事务操作。事务管理在Spring Boot中通常是通过 @Transactional 注解来实现的。事务可能会失效的一些常见情况包括:

1. **未捕获异常: 如果一个事务方法中发生了未捕获的异常，并且异常未被处理或传播到事务边界之外，那么事务会失效，所有的数据库操作会回滚。**
2. 非受检异常: 默认情况下，**Spring对非受检异常（RuntimeException或其子类）进行回滚处理，这**意味着当事务方法中抛出这些异常时，事务会回滚。
3. **事务传播属性设置不当:** 如果在多个事务之间存在事务嵌套，且事务传播属性配置不正确，可能导致事务失效。**特别是在方法内部调用有 @Transactional 注解的方法时要特别注意。**
4. **多数据源的事务管理: 如果在使用多数据源时，**事务管理没有正确配置或者存在多个 @Transactional 注解时，可能会导致事务失效。
5. 跨方法调用事务问题: **如果一个事务方法内部调用另一个方法，而这个被调用的方法没有 @Transactional 注解，**这种情况下外层事务可能会失效。
6. **事务在非公开方法中失效: 如果 @Transactional 注解标注在私有方法上或者非 public 方法上，事务也会失效**

#### Spring AOP自调用问题

当一个方法被标记了@Transactional 注解的时候，Spring 事务管理器**只会在被其他类方法调用的时候生效，而不会在一个类中方法调用生效。**

这是因为 Spring AOP 工作原理决定的。因为 Spring AOP 使用动态代理来实现事务的管理，**它会在运行的时候为带有 @Transactional 注解的方法生成代理对象，并在方法调用的前后应用事物逻辑**。如果**该方法被其他类调用我们的代理对象就会拦截方法调用并处理事**务。但是**在一个类中的其他方法内部调用的时候，我们代理对象就无法拦截到这个内部调用，因此事务也就失效了。**

## MYSQL存储引擎

|            区别            |                            InnoDB                            |                            Memory                            |                            MyISAM                            |
| :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|         **行级锁**         |                           **支持**                           |                          **不支持**                          |                   **不支持，只支持表级别**                   |
|          **事务**          |                  **支持，提供四个隔离级别**                  |                          **不支持**                          |                          **不支持**                          |
|            外键            |                             支持                             |                            不支持                            |                            不支持                            |
| 数据库异常崩溃后的安全恢复 |                             支持                             | 将数据存储在内存中，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失 |                            不支持                            |
|            MVCC            |                             支持                             |                                                              |                            不支持                            |
|        索**引实现**        | **InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。**<br /><br /><br />Innodb是聚簇索引，聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大 |                                                              | **MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。**<br /><br /><br />myisam是非聚簇为索引，数据文件是分离的，**索引保存的是数据文件的指针。主键索引和辅助索引是独立的。** |
|      count的效率****       | **InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描** |                                                              | **MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快** |
|          性能差别          |                            更强大                            |                                                              |                                                              |
|     数据缓存策略和机制     |         使用缓冲池（Buffer Pool）缓存数据页和索引页          |                                                              |                   只缓存索引页不缓存数据页                   |

## MYSQL锁机制

#### 全局锁

- 执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞：
  - 对数据的增删改操作，比如 insert、delete、update等语句；
  - 对表结构的更改操作，比如 alter table、drop table 等语句。
- 会话断开，全局锁自动被释放
- 应用场景
  - 全库逻辑备份
- 加全局锁缺点
  - 数据多-》备份时间长-》只读状态-》业务不能更新数据-》业务停滞
  - 解决办法
    - 如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。
    - 但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。

#### 表级锁

##### 表锁

- 表锁限制别的线程和自己线程的读写
- 会话退出，释放所有锁
- 表锁颗粒度太大，影响并发性能，因此使用颗粒度更细的行级锁

##### 元数据锁（MDL）

- 不需要显式使用，对数据库表进行操作时，会自动给加上MDL
  - CRUD操作加MDL读锁
  - 对表进行结构操作的时候加MDL写锁
- MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。
- 在事务执行期间，MDL一直持有，事务提交后才会释放
- 一个线程因为写锁申请不到的时候，后续的申请读锁的查询操作也会被阻塞
  - 申请MDL锁形成队列，写锁优先级高。
  - 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。

##### 意向锁

- 在遍历对某些记录加上共享锁||独占锁之前，需要先在表级别上加上一个意向共享锁||意向独占锁
- **意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突**，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突。
- 意向锁的目的是为了快速判断表里是否有记录被加锁
- 意向锁是由数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InnoDB 会先获取该数据行所在在数据表的对应意向锁。

##### AUTO-INC锁

- Auto-Inc是特殊的表锁价值，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。

- 在插入数据的时候，可以不指定主键的值，数据库会自动给主键赋值递增的值

- 但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。

  - MySQL5.1.22后，提供了一种轻量级的锁来实现自增
  - 一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，**就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。**

- 通过 innodb_autoinc_lock_mode控制使用什么锁

  - 0

    auto-inc，语句结束后释放锁

  - 1

    - 普通insert语句，使用轻量级锁，申请主键后马上释放
    - insert-select批量插入数据，语句结束后释放

  - 2

    - 轻量级，申请主键后释放
    - 效率最高，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，**在「主从复制的场景」中会发生数据不一致的问题。**
    - 当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题。

#### 行级锁

InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。

- 普通的 select 语句是不会对记录加锁的，因为它属于**快照读。**

- 查询会加锁的语句称为**锁定读。**

  ```mysql
  //对读取的记录加共享锁
  select ... lock in share mode;
  //对读取的记录加独占锁
  select ... for update;
  上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。
  ```

- 共享锁（S锁,Shared lock）满足读读共享，读写互斥。独占锁（X锁,exclusive lock）满足写写互斥、读写互斥。

  - sx不兼容
  - ss兼容
  - xx不兼容

1. Record Lock，记录锁，也就是仅仅把一条记录锁上；
2. Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
3. Next-Key Lock：临键锁，Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身

##### Record Lock

当事务执行 commit 后，事务过程中生成的锁都会被释放。

##### Gap Lock

- Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。
- **间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的**，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。

##### Next-Key Lock

- next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中
- **next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。**

##### 插入意向锁

- 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。
- 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。
- 会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁）。此时事务 B 就会发生阻塞，直到事务 A 提交了事务。
- 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。

## Redis常见数据类型

|  数据类型   |                           应用场景                           |                        底层数据结构                         | 内部实现                                                     |
| :---------: | :----------------------------------------------------------: | :---------------------------------------------------------: | :----------------------------------------------------------- |
|   String    |        缓存对象、常规计数、分布式锁、共享session信息         |                     SDS(简单动态字符串)                     | 1.不仅**可以保存文本数据，还可以保持二进制数据**（记录len）2. 获取**字符串长度的时间复杂度是O（1）** 3.**API安全，拼接字符串不造成缓冲区溢出**<br /> |
|    Hash     |                       缓存对象、购物车                       |    Redis3.2以后改成quicklist实现，代替双向链表和压缩列表    | **quicklist**                                                |
|    List     | 消息队列（**问题1 生产者需要自行实现全局唯一ID** 问题**2 不能以消费组形式消费数据**） |  （Redis7.0以后改成**listpack**实现，代替压缩列表）+哈希表  | 小于512，每个小于64字节，listpack 否则哈希表                 |
|     Set     |           聚合计算场景（点赞、共同关注、抽奖活动）           |                     哈希表或者整数集合                      | 小于512 整数集合 否则哈希表                                  |
|    Zset     |                           排序场景                           | （Redis7.0以后改成**listpack**实现，代替压缩列表）**+跳表** | 小于128，每个小于64字节，listpack，否则跳表                  |
|   BitMap    | 二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等 |                                                             |                                                              |
| HyperLogLog |        海量数据基数统计的场景，比如百万级网页 UV 计数        |                                                             |                                                              |
|     GEO     |             存储地理位置信息的场景，比如滴滴叫车             |                                                             |                                                              |
|   Stream    | 消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：<br />**自动生成全局唯一消息ID，支持以消费组形式消费数据。** |                                                             |                                                              |

### SDS和c语言字符串

**O（1）复杂度获取字符串长度**

1. C 语言的字符串长度获取 strlen 函数，需要通过遍历的方式来统计字符串长度，时间复杂度是 O（N）。
2. 而 Redis 的 SDS 结构因为加入了 len 成员变量，那么**获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）。**

**二进制安全**

1. 因为 SDS 不需要用 “\0” 字符来标识字符串结尾了，**而是有个专门的 len 成员变量来记录长度，**所以可存储包含 “\0” 的数据。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。
2. 因此， **SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。**
3. **通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。**

**不会发生缓冲区溢出**

1. C 语言的字符串标准库提供的字符串操作函数，大**多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证**，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。
2. 所以，**Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 alloc - len 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，**就可以由程序内部判断缓冲区大小是否足够用。
3. 而且，**当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小，**以满足修改所需的大小

### ZSet

##### 底层为什么用跳表，而不用平衡树、红黑树或者b+树

这道面试题很多大厂比较喜欢问，难度还是有点大的。

- 平衡树 vs 跳表：
  - 主要是**从内存占用、对范围查找的支持、实现难易程度**这三方面总结的原因：

    1. 从**内存占用**上来比较，跳表比平衡树更灵活一些。**平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。**
    2. 在**做范围查找的**时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点**。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在**跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历**就可以实现。
    3. 从**算法实现难度**上来比较，跳表比平衡树要简单得多。**平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速

- 红黑树 vs 跳表：**相比较于红黑树来说，跳表的实现也更简单一些，不需要通过旋转和染色（红黑变换）来保证黑平衡。并且，按照区间来查找数据这个操作，红黑树的效率没有跳表高。**
- B+树 vs 跳表：B+树更适合作为数据库和文件系统中常用的索引结构之一，它的核心思想是通过可能少的 IO 定位到尽可能多的索引来获得查询数据。**对于 Redis 这种内存数据库来说，它对这些并不感冒，因为 Redis 作为内存数据库它不可能存储大量的数据**，所以对于索引不需要通过 B+树这种方式进行维护，只需按照概率进行随机维护即可，节约内存**。而且使用跳表实现 zset 时相较前者来说更简单一些，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要对节点分裂与合并。**

##### 跳表是怎么实现的

链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，**这样的好处是能快读定位数据。这个查找过程就是在多个层级上跳来跳去，最后定位到元素。**当数据量很大时，跳表的查找复杂度就是 O(logN)。**

## Redis持久化

三种持久化方式：

- **AOF日志：**每执行一条写**操作命令**，就把**该命令以追加的方式写入到一个文件里**
- **RDB快照：**将某一时刻的**内存数据**，以**二进制方式写入磁盘**
- **混合持久化方式：**Redis4.0新增的方式，继承了前两种的优点

### AOF（Append Only File）日志是如何实现的 

Redis 在**执行完一条写操作命令**后，就会**把该命令以追加的方式写入到一个文件**里，
然后 **Redis 重启时，会读取该文件记录的命令**，然后**逐一执行命令**的方式来进行数据恢复。

- **避免额外的检查开销**
- **不会阻塞当前写操作命令的执行**

- **数据可能会丢失**
- **可能阻塞其他的操作**

#### 1. AOF写回策略有几种？

- Redis 执行完写操作命令后，**会将命令追加到 server.aof_buf 缓冲区；**

- 然后通过 write() 系统调用，**将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；**

- 具体**内核缓冲区的数据什么时候写入到硬盘**，由内核决定。

  - **Redis.conf 配置文件中的 appendfsync** 配置项可以有以下 3 种参数可填。
    这三种策略只是在控制 fsync() 函数的调用时机。

    | 写回策略 |                             意思                             | 写回时机           | 优点                           | 缺点                               |
    | -------- | :----------------------------------------------------------: | ------------------ | ------------------------------ | ---------------------------------- |
    | Always   |     **每次写操作命令执行完后，将AOF日志数据写回磁盘。**      | 同步写回           | 可靠性高、最大程度保证数不丢失 | 每个写命令都要写回硬盘，性能开销大 |
    | EverySec | 每次写操作命令执行完后，**先将命令写入AOF文件的内核缓冲区，**然后**每隔一秒将缓冲区里的内容写回到硬盘** | 每秒写回           | 性能适中                       | 宕机时会丢失一秒内的数据           |
    | No       | 每次写操作命令执行完后，先将命令**写入到 AOF 文件的内核缓冲区**，再由**操作系统决定何时将缓冲区内容写回硬盘**。 | 由操作系统控制写回 | 性能好                         | 宕机时可能会丢失大量数据           |

#### 2. AOF日志过大会触发什么机制

- **提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，启用 AOF 重写机制，来压缩 AOF 文件。**
- **读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。**
  - 因为**如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染，可能无法用于恢复使用。所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响**

#### 3. 重写AOF日志的过程是怎样的

Redis 的**重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，**这么做可以达到两个好处

- **避免阻塞主进程**
- 父子进程内存以只读的的方式共享，当父子进程任意一方修改了该共享内存，发生写时复制，父子进程有了独立的数据副本，不用加锁来保存副本
  - 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把**主进程的「页表」复制一份**给子进程，这个页表记录着虚拟地址和物理地址映射关系，而**不会复制物理内存**，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。
  - 当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发**写保护中断**，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里**进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写**，最后才会对内存进行写操作，这个过程被称为「写时复制(Copy On Write)」
  - 写时复制顾名思义**，在发生写操作的时候，操作系统才会去复制物理内存**，这样是**为了防止** fork 创建子进程时，**由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。**

**触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）**

 在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

- 执行客户端发来的命令；
  - 如**果此时主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的。**
- 将执行后的写命令**追加到 「AOF 缓冲区」；**
- 将执行后的写命令**追加到 「AOF 重写缓冲区」；**

子进程完成重写工作，向主进程发信号，主进程收到信号，调用信号处理函数：

- **将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；**
- **新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。**

### RDB（Redis Database）快照是如何实现的呢

用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，**一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢**。为了解决这个问题，Redis 增加了 RDB 快照。

​	RDB 快照**就是记录某一个瞬间的内存数据**，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

​	RDB 快照的缺点**：在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多**，因为 RDB 快照是全量快照的方式，因此**执行的频率不能太频繁**，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少

#### RDB做快照时会阻塞线程吗

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行

- **save 在主线程生成RDB文件，会阻塞主线程**
- **bgsave 创建子线程来生成RDB文件，避免主线程的阻塞**
- 也可以通过配置文件的选项自动执行bgsave

#### RDB在执行快照的时候，数据能修改吗

​	执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write, COW）。

​	共享同一片内存数据，页表指向的物理内存还是一个，主线程可以直接修改原来的数据。

​	bgsave 快照过程中，如果主线程修改了共享数据，发生了写时复制后，RDB 快照保存的是原本的内存数据，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。
​	所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据
​	如果系统恰好在 RDB 快照文件创建完毕后崩溃了，那么 Redis 将会丢失主线程在快照期间修改的数据。

#### 为什么会有混合持久化

- **混合持久化工作在 AOF 日志重写过程，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。**
  - 当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。
- **既保证了 Redis 重启速度，又降低数据丢失风险。**
- **添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。**

### AOF和RDB优缺点

#### AOF

- **优点：**
  - 首先，AOF提供了**更好的数据安全性**，因为它默认每接收到一个写命令就会**追加**到文件末尾。即使Redis服务器宕机，也**只会丢失最后一次**写入前的数据。
  - 其次，AOF支**持多种同步策略**（如everysec、always等），可以根据需要调整**数据安全性和性能之间的平衡。**
  - 同时，**AOF文件在Redis启动时可以通过重写机制优化，减少**文件体积，加快恢复速度。
  - 并且，即使**文件发生损坏，AOF还提供了redis-check-aof工具来修复**损坏的文件。
- **缺点:**
  - 因为记录了每一个写操作，所以**AOF文件通常比RDB文件更大，消耗更多的磁盘空间。**
  - 并且，**频繁的磁盘IO操作（尤其是同步策略设置为always时）可能会对Redis的写入性能造成一定影响**。
  - 而且，当问个文件体积过大时，AOF会进行重写操作**，AOF如果没有开启AOF重写或者重写频率较低，恢复过程可能较慢，因为它需要重放所有的操作命令。**

#### RDB

- **优点:** 
  - **RDB通过快照的形式保存**某一时刻的数据状态，**文件体积小，**备份和恢复的速度非常快。
  - 并且，RDB是**在主线程之外通过fork子进程来进行的，不会阻塞服务器处理命令请求，**对Redis服务的性能影响较小。
  - 最后，由于是**定期快照，RDB文件通常比AOF文件小得多。**
- **缺点**: 
  - RDB方式**在两次快照之间，如果Redis服务器发生故障，这段时间的数据将会丢失。**
  - 并且，如果**在RDB创建快照到恢复期间有写操作，**恢复后的数据可能与故障前的数据**不完全一致**



### Redis大key对持久化有什么影响

#### 什么是大key问题

Redis大key问题指的是**某个key对应的value值所占的内存空间比较大，导致Redis的性能下降、内存不足、数据不均衡以及主从同步延迟等问题。**

到底多大的数据量才算是大key？没有固定的判别标准**，通常认为字符串类型的key对应的value值占用空间大于1M，或者集合类型的k元素数量超过1万个，就算是大key。**

Redis大key问题的定义及评判准则并非一成不变，而应根据Redis的实际运用以及业务需求来综合评估。

例如，在高并发且低延迟的场景中，仅10kb可能就已构成大key；然而在低并发、高容量的环境下，大key的界限可能在100kb。因此，在设计与运用Redis时，要依据业务需求与性能指标来确立合理的大key阈值

#### 大key对AOF日志的影响

- 在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。
  - 如果写入是一个大 Key，**主线程在执行 fsync() 函数的时候，阻塞的时间会比较久**，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。
- 当使用 **Everysec 策略**的时候，由于是**异步**执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）**不会影响**主线程。
- 当使用 No 策略的时候，由于**永不执**行 fsync() 函数，所以大 Key 持久化的过程**不会影响主线程。**

#### 大key对AOF重写和RDB的影响

**AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 fork() 函数创建一个子进程来处理任务**。会有两个阶段会导致阻塞父进程（主线程）：

1. 创建子进程的途中，由于要复制父进程的**页表**等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
2. 创建完子进程后，如**果父进程修改了共享数据中的大 Key**，就会发**生写时复制**，**这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，**那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程

#### 大key问题的缺点？

1. **内存占用过高。**大Key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。
2. **性能下降。**大Key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大Key的操作，如读取、写入、删除等，都会消耗更多的CPU时间和内存资源，进一步降低系统性能。
3. **阻塞其他操作**。某些对大Key的操作可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。
4. **网络拥塞。**每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。
5. **主从同步延迟。**当Redis实例配置了主从同步时，大Key可能导致主从同步延迟。由于大Key占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。
6. **数据倾斜。**在Redis集群模式中，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。另外也可能造成Redis内存达到maxmemory参数定义的上限导致重要的key被逐出，甚至引发内存溢出。

#### 如何避免大key

- **对大Key进行拆分**。例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。

- **监控Redis的内存水位**。可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。

- **对大Key进行清理。**将**不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。**

- **对过期数据进行定期清。**堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。**可以通过定时任务的方式对失效数据进行清**

- **定时检查** Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，**而是用 unlink 命令**（Redis 4.0+）删除大 key，**因为该命令的删除过程是异步的，不会阻塞主线程。**

###  热key

#### 什么是热key

通常以其接收到的**Key被请求频率来判定，**例如：

- **QPS集中在特定的Key**：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。
- **带宽使用率集中在特定的Key**：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。
- **CPU使用时间占比集中在特定的Key：**对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求

#### 如何解决热key问题

- 在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。**此时，可以将对应热Key进行复制并迁移至其他数据分片，**例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。
- **使用读写分离架构。**如果热Key的产生来自于读请求，您可以将实例改造**成读写分离架构来降低每个数据分片的读请求压力**，甚至可以不断地增加从节点。**但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。**要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。                                  

## Redis过期淘汰策略

### 过期删除策略和内存淘汰策略有什么区别？

- 内存淘汰策略是在**内存满了的时候，redis 会触发内存淘汰策略，来淘汰一些不必要的内存资源**，以腾出空间，来保存新的内容
- 过期键删除策略**是将已过期的键值对进行删除，Redis 采用的删除策略是惰性删除+定期删除**

### 如何设置过期时间

1. 对key设置过期时间的命令
   1. expire <key> <n>：设置 key 在 n 秒后过期
   2. pexpire <key> <n>：设置 key 在 n 毫秒后过期
   3. expireat <key> <n>：设置 key 在某个时间戳（精确到秒）之后过期，
   4. pexpireat <key> <n>：设置 key 在某个时间戳（精确到毫秒）之后过期
2. 设置字符串时，同时对key设置过期时间
   1. set <key> <value> ex <n> ：设置键值对的时候，同时指定过期时间（精确到秒）；
   2. set <key> <value> px <n> ：设置键值对的时候，同时指定过期时间（精确到毫秒）；
   3. setex <key> <n> <valule> ：设置键值对的时候，同时指定过期时间（精确到秒）
3. 如果你想查看某个 key 剩余的存活时间，可以使用 TTL <key> 命令。
4. 如果突然反悔，取消 key 的过期时间，则可以使用 PERSIST <key> 命令。

### Redis 使用的过期删除策略是什么？

- Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

- Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中（**过期字典存储在redisDb结构中**），也就是说「过期字典」保存了数据库中所有 key 的过期时间。Redis 选择**「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

  - **过期字典的 key 是一个指针，指向某个键对象；**
    **过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；**

- 当我们查询一个 key 时，**Redis 首先检查该 key 是否存在于过期字典中：**

  - **不存在，正常读取**
  - **存在，比对时间**

- 定时删除策略

  在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作

  优点：可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。

  缺点：在过期 key 比较多的情况下，**删除过期 key 可能会占用相当一部分 CPU 时间，**在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。

- **惰性删除策略**

  **不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

  优点：惰性删除策略**对 CPU 时间最友好。**

  缺点：只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的**内存空间浪费。**

- **定期删除策略**

  每隔一段时间**「随机」从数据库中取出一定数量**的 key 进行检查**，并删除其中的过期key。超过25%继续查。**

  **默认为每秒进行10次过期检查。**

  那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。

  优点：

  ​	通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响。

  ​	同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

  缺点：

  ​	难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

### Redis 持久化时，对过期键会如何处理的？

1. **RDB文件**
   1. **生成**阶段：**从内存状态持久化成RDB的时候，对key进行过期检查，不会保存到新的RDB文件中**
   2. **加载**阶段
      1. **主服务器，载入RDB文件时，对文件中保存的key进行检查，不会载入到数据库中**
      2. **从服务器，直接载入**。但是主从**服务器同步时候从服务器数据会被清空**，所以也没影响
2. **AOF文件**
   1. **写入**阶段：**以AOF模式持久化，过期键被保留，当此过期键被删除后，会向AOF文件追加一条DEL命令来显式地删除该键值**
   2. **重写**阶段**：执行AOF重写，对键进行检查，不会保存到重写的文件中。**

### Redis 主从模式中，对过期键会如何处理？

- 当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。
  - 小林哥，感觉redis有些东西有点老了。主从复制那里，**master删除过期键，但是slave不会删除过期键。这句话是redis3.2以前适用的。**
    **在4.0.11 以上版本，所有命令均已修复，过期 key 在 slave 上查询，均返回不存在了**
- **主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key**

### Redis 内存满了，会发生什么？

触发内存淘汰策略

### Redis 内存淘汰策略有哪些？

八种内存淘汰策略，大体分为不进行数据淘汰和进行数据淘汰两种策略。

1. **不进行数据淘汰的策略**

   **noeviction（**Redis3.0之后，默认的内存淘汰策略） ：它表示**当运行内存超过最大设置内存时，不淘汰任何数据**，这时如果**有新的数据**写入，会报错通知**禁止写入**，不淘汰任何数据，但是如果**没用数据写入**的话，只是单纯的查询或者删除操作的话，还是可以**正常工作**。

2. **进行数据淘汰的策略**

   1. **在设置了过期时间的数据中进行淘汰**
      1. **volatile-random**：随机淘汰设置了过期时间的任意键值；
      2. **volatile-ttl：**优先淘汰更早过期的键值。
      3. **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：**淘汰所有设置了过期时间的键值中，最久未使用的键值；**
      4. **volatile-lfu（**Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，**最少使用的键值；**
   2. **在所有数据范围内进行淘汰**
      1. **allkeys-random：**随机淘汰任意键值;
      2. **allkeys-lru：**淘汰整个键值中最久未使用的键值；
      3. **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

### LRU 算法和 LFU 算法有什么区别？

1. 传统的LRU算法：最近最少使用 Least Recently Used

   1. 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
   2. 当有数据被访问时，**需要在链表上把该数据移动到头端**，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

2. Redis实现的LRU算法 

   1. Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，**用于记录此数据的最后一次访问时间。**
   2. 当 Redis 进行内存淘汰时**，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。**
   3. 节省了空间占用，提升了缓存性能
   4. 但是 LRU 算法有一个问题，**无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。**

3. Redis实现的LFU算法 最近最不常用的 Least Frequently Used

   1. LFU 算法相比于 LRU 算法的实现，多记录了**「数据的访问频次」**的信息

   2. 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，**Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。**

   3. 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；**低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。**

      注意，logc 并不是单纯的访问次数，而是**访问频次（访问频率），因为 logc 会随时间推移而衰减的**

## Redis缓存雪崩、缓存击穿、缓存穿透

### 缓存雪崩

**大量缓存数据在同一时间过期（失效）时**，如果此时有大量的用户请求，都无法在 Redis 中处理，于是**全部请求都直接访问数据库，**从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。

发生原因和解决办法

- 大量数据同时过期

  - **随机打散缓存失效时间**

  - **互斥锁**

    - 当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就**加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里），**当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
    - 实现互斥锁的时候，**最好设置超时时间**，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。

  - **后台更新缓存**

    - 让缓存“永久有效”，并**将更新缓存的工作交由后台线程定时更新。**

      - 但是**这并不意味着数据一直能在内存里**，当系统**内存紧张的时候，有些缓存数据会被“淘汰”，**而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程**读取缓存失败就返回空值**，业务的视角就以为是数据丢失

        解决方法：

        1. 后台线程**不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效**，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要**马上从数据库读取数据，并更新到缓存**。
        2. 在业务线程**发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存**，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作**；不存在就读取数据库数据，并将数据加载到缓存。**

      - 业务刚上线的时候，我们·最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的**缓存预热**，后台更新缓存的机制刚好也适合干这个事情。

- Redis故障宕机

  - **服务熔断机制或者请求限流机制**
    - 服务熔断机制：**暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库**，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 **Redis 恢复正常后，再允许业务应用访问缓存服务。**
    - 请求限流机制：**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，**等到 Redis **恢复正常并把缓存预热完**后，再解除请求限流的机制。
  - **构建Redis缓存高可靠集群**
    - 通过**主从节点的方式构建 Redis 缓存高可靠集群**。如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。

### 缓存击穿

如果缓存中的**某个热点数据过期了**，此时**大量的请求访问了该热点数据**，就无法从缓存中读取，**直接访问数据库**，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。

- **互斥锁方案**（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），**保证同一时间只有一个业务线程请求缓存**，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值
- **不给热点数据设置过期时间，由后台异步更新缓存**，或者在热点数据**准备要过期前，提前通知后台线程**更新缓存以及重新设置过期时间；

### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再**去访问数据库时，发现数据库中也没有要访问的数据**，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；

- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

  

- 限制非法请求

- 设置空值或者默认值

- 使用布隆过滤器判断数据是否存在，避免通过查询数据库来判断数据是否存在。

  - 查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据
  - 布隆过滤器由**「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。**当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。
    布隆过滤器会通过 3 个操作完成标记：
    - 第一步，**使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；**
    - 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，**得到每个哈希值在位图数组的对应位置。**
    - 第三**步，将每个哈希值在位图数组的对应位置的值设置为 1；**

## Redis、Mysql缓存一致性问题

### 一、Redis缓存策略

|          |                           内存淘汰                           |                           超时剔除                           |                 主动更新                  |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------: |
|   说明   | 不用自己维护，利用Redis的内存淘汰机制，当内存不足时自动淘汰部分数据，下次查询时更新缓存。 | **给缓存数据添加TTL时间，到期后自动删除缓存，下次查询时更新缓存** | 编写业务逻辑，在修改数据的6同时，更新缓存 |
|  一致性  |                              差                              |                             一般                             |                    好                     |
| 维护成本 |                              无                              |                              低                              |                    高                     |

1. 在基本不会更新数据的情况下可以使用内存淘汰机制
2. 在频繁更新数据的情况下可以使用主动更新**，并以超时剔除作为兜底方案**

### 二、主动更新的三种方法

1. **（旁路缓存）Cache Aside Pattern**：由缓存的调用者，在更新数据库的同时更新缓存

2. **（读穿 / 写穿）Read/Write Through Pattern**：缓存**和数据库整合为一个服务**，由服务来维护一致性。调用者调用该服务，无需关心缓存一致性问题。

   1. 优点：整合的服务保证了数据的一致性

   2. 缺点：维护和开放成本高

      ###### 读穿

      先看能否命中缓存，没有命中，由缓存组件从数据库中读取数据，将数据写入缓存组件，最后缓存组件将数据返回给应用

      ###### 写穿

      - 如果缓存中数据不存在，直接更新数据库，然后返回
      - 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。

3. **（写回）Write Behind Caching Pattern：**调用者**只操作缓存，由其他线程异步的将缓存数据持久化到数据库，**最终保持一致。

   1. 优点：异步更新缓存数据，效率高。例如缓存多次更新，但是更新到的缓存并没有被使用，多次将数据持久化到数据库就相当于进行了无用的操作，异步更新相当于将前几次的更新合并为一次更新，因而提高了效率。

   2. 缺点：无法保证一致性，维护成本高

      Write Back（写回）策略在更新数据的时候，**只更新缓存，同时将缓存数据设置为脏的**，然后立马返回，并不会更新数据库。对于**数据库的更新，会通过批量异步更新**的方式进行。

      - Write Back 策略特别适合**写多**的场景，因为发**生写操作的时候， 只需要更新缓存，就立马返回了**。
      - 但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险，

### 三、Redis的读

如果缓存在[Redis](https://cloud.tencent.com/document/product/239?from=10680)中存在，即缓存命中，则直接返回数据

如果[Redis](https://cloud.tencent.com/document/product/239?from=10680)中没有对应缓存，则需要直接查询[数据库](https://cloud.tencent.com/document/product/236?from=10680)，然后存入[Redis](https://cloud.tencent.com/document/product/239?from=10680)，最后把数据返回

![image-20241015092601203](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092601203.png)

通常情况下，我们会为某个缓存设置一个key值，并针对key值设置一个过期时间，如果被查询的数据对应的key过期了，则直接查询[数据库](https://cloud.tencent.com/document/product/236?from=10680)，并将查询得到的数据存入[Redis](https://cloud.tencent.com/document/product/239?from=10680)，然后重置过期时间，最后将数据返回。

### 四、Redis的写

**一致性问题:** 

```
在Redis的key值未过期的情况下，用户修改了个人信息，我们此时既要操作数据库数据，也要操作Redis数据。
```

**到底是先更新数据库还是先更新缓存？**

```
从本质上讲，无论是先写数据库还是先写缓存，都是为了保证数据库和缓存的数据一致，也就是我们常说的数据一致性。
```

操作缓存和数据库时需要考虑的三个问题:

1. **删除缓存还是更新缓存？**
   更新缓存：每次更新数据库都更新缓存，无效写操作较多
   删除缓存：更新数据库时让缓存失效，查询时再更新缓存
   结论：推荐**直接使用「删除」操作。**

2. **如何保证缓存与数据库的操作的同时成功或者失败**
   对于单体系统：将缓存与数据库操作放在一个事务中
   对于分布式系统：利用TCC等分布式事务方案

3. **先操作缓存还是先操作数据库?**
   3-1. 先删除缓存，再操作数据库
   这种方式可能存在以下两种异常情况:

   1. 删除缓存失败，这时可以通过程序捕获异常，直接返回结果，不再继续更新数据库，所以不会出现数据不一致的问题

   2. **删除缓存成功，更新数据库失败。在多线程下可能会出现数据不一致的问题**

      <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092223313.png" alt="image-20241015092223313" style="zoom:50%;" />

       这时，Redis中存储的旧数据，数据库的值是新数据，导致数据不一致**。这时我们可以采用 延时双删 的策略，即更新数据库数据之后，再删除一次缓存。**

      **线程延时3-5s以后（时间一般要大于SQL执行时间+线程切换+线程切换执行时间100ms足够），再将缓存删除。之后其他线程再查询缓存。**
      
      <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092235976.png" alt="image-20241015092235976" style="zoom:50%;" />

   3-2. 先操作数据库，再删除缓存

   这种方式可能存在以下两种异常情况:
   
   1. 更新数据库失败，这时可以通过程序捕获异常，直接返回结果，不再继续删除缓存，所以不会出现数据不一致的问题
   2. **更新数据库成功，删除缓存失败。导致数据库是最新数据，缓存中的是旧数据，数据不一致**

   这里, 我们有两种方式来解决数据不一致问题：**失败重试** 和 **异步更新**。

   方式1. 失败重试

   <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092346479.png" alt="image-20241015092346479" style="zoom:50%;" />

   消息队列重试机制
   
   - 将删除缓存要操作的数据加入到消息队列，由消费者来操作数据
     - **如果删除缓存失败，从消息队列里再次读取，并重新删除。超过一定次数，向业务层报错**
     - **如果删除缓存成功，把数据从消息队列中移除，避免重复操作。**
   - 优点：保证缓存一致性问题
   - 缺点：对代码入侵性比较强，因为需要改造原本业务的代码

   方式2. 异步更新

   订阅MySQL binlog+消息队列+重试缓存
   
   - 更新数据库成功，就会产生一条变更日志，记录在 binlog 里。 订阅binlog日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。
   - **将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性。必须是删除缓存成功，再回 ack 机制给消息队列，否则可能会造成消息丢失的问题，比如消费服务从消息队列拿到事件之后，直接回了 ack，然后再执行删除缓存操作的话，如果删除缓存的操作还是失败了，那么因为提前给消息队列回 ack了，就没办重试了。**
   - 优点：规避了代码入侵的问题，保证缓存一致性问题
   - 缺点：引入组件较多，对运维有较高要求

   <img src="https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241015092406938.png" alt="image-20241015092406938" style="zoom:50%;" />
   
   总之，对于删除缓存失败的情况，我们的做法是不断地重试删除操作，直到成功。无论是重试还是异步删除，都是最终一致性的思想。
   如上图所示，两种方案在多线程的情况下都会产生数据不一致的问题
   在**先操作数据库再删除缓存的情况下，要发生数据不一致的问题，需要在缓存写入之前完成更新数据库和删除缓存的操作，而写入缓存的耗时非常短。因而发生的概率相对于另一种方案更低。所以优先选择先操作数据库，再删除缓存。**
   **结论：推荐直接使用「先更新数据库再删除缓存」操作。**

### 五、总结

缓存策略的最佳实践是 **Cache Aside 模式**。分别分为读缓存最佳实践和写缓存最佳实践。

**读缓存最佳实践**

```
先读缓存，命中则返回；
未命中则查询数据库，再写到缓存中。
```

**写缓存最佳实践**

```
先更新数据库，再操作缓存；
操作缓存采用直接删除缓存，而不是修改。
```

## IOC、AOP

### 什么是IoC

**IoC（Inversion of Control:控制反转） 是一种设计思想，将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理**

- 控制：指的是对象创建（实例化、管理）的权力
- 反转：控制权交给外部环境（Spring 框架、IoC 容器）

**将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。**

所谓**控制就是对象的创建、初始化、销毁。**

- 创建对象：原来是 new 一个，现在是由 Spring 容器创建。
- 初始化对象：原来是对象自己通过构造器或者 setter 方法给依赖的对象赋值，现在是由 Spring 容器自动注入。
- 销毁对象：原来是直接给对象赋值 null 或做一些销毁操作，现在是 Spring 容器管理生命周期负责销毁对象。

### IOC实现机制

- 反射：**Spring IOC容器利用Java的反射机制动态地加载类、创建对象实例及调用对象方法**，反射允许在运行时检查类、方法、属性等信息，从而实现灵活的对象实例化和管理。
- 依赖注入：**IOC的核心概念是依赖注入，即容器负责管理应用程序组件之间的依赖关系。Spring通过构造函数注入、属性注入或方法注入，**将组件之间的依赖关系描述在配置文件中或使用注解。
- 设计模式 - 工厂模式：Spring IOC容器通常采用工厂模式来管理对象的创建和生命周期。容**器作为工厂负责实例化Bean并管理它们的生命周期，将Bean的实例化过程交给容器来管理。**
- 容器实现：S**pring IOC容器是实现IOC的核心，通常使用BeanFactory或ApplicationContext来管理Bean。****BeanFactory是IOC容器的基本形式，提供基本的IOC功能；ApplicationContext是BeanFactory的扩展，**并提供更多企业级功能

### 什么是AOP

在面向切面编程中，核心业务功能和周边功能是分别独立进行开发，两者不是耦合的，然后把切面功能和核心业务功能 "编织" 在一起，这就叫AOP。

AOP(Aspect-Oriented Programming:**面向切面编程**)能够**将那些与业务无关**，**却为业务模块**所共同**调用的**逻辑或责任（例如事务处理、日志管理、权限控制等）**封装起来**，便于**减少系统的重复代码**，**降低**模块间的**耦合度**，并有利于未来的可拓展性和可维护性

### AOP应用场景

1. **日志记录**：自定义日志记录注解，利用 AOP，一行代码即可实现日志记录。
2. **性能统计：**利用 AOP 在目标方法的执行前后统计方法的执行时间，方便优化和分析。
3. **事务管理：**@Transactional 注解可以让 Spring 为我们进行事务管理比如回滚异常操作，免去了重复的事务管理逻辑。@Transactional注解就是基于 AOP 实现的。
4. **权限控制**：利用 AOP 在目标方法执行前判断用户是否具备所需要的权限，如果具备，就执行目标方法，否则就不执行。例如，SpringSecurity 利用@PreAuthorize 注解一行代码即可自定义权限校验。
5. **接口限流**：利用 AOP 在目标方法执行前通过具体的限流算法和实现对请求进行限流处理。
6. **缓存管理**：利用 AOP 在目标方法执行前后进行缓存的读取和更新。
   ……

### AOP实现机制

Spring AOP的实现依赖于动态代理技术。**动态代理是在运行时动态生成代理对象，而不是在编译时。**它允许开发者在运行**时指定要代理的接口和行为，从而实现在不修改源码的情况下增强方法的功能。**

Spring AOP支持两种动态代理：

- 基**于接口的代理（JDK动态代理）：** 这种类型的代理要求**目标对象必须实现至少一个接口**。**Java动态代理会创建一个实现了相同接口的代理类，然后在运行时动态生成该类的实例。这**种代理的实现核心是java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口**。每一个动态代理类都必须实现InvocationHandler接口，并且每个代理类的实例都关联到一个handler。当**通过代理对象**调用一个方法时，这个方法的调用会被转发为由InvocationHandler接口的invoke()方法来进行调用。**
- **基于类的代理（CGLIB动态代理）：** CGLIB（Code Generation Library）是一个强大的高性能的代码生成库，它可以在运行时动态生成一个目标类的子类。**CGLIB代理不需要目标类实现接口，而是通过继承的方式创建代理类。因此，如果目标对象没有实现任何接口，可以使用CGLIB来创建动态代理**

Spring AOP 是基于动态代理的

- 如果要代理的对象，**实现了某个接口**，那么 Spring AOP 会使用 **JDK Proxy，去创建代理对象**
- 而对**于没有实现接口**的对象，Spring AOP 会使用 **Cglib 生成一个被代理对象的子类来**作为代理

**专业术语**

|      术语       |                             含义                             |
| :-------------: | :----------------------------------------------------------: |
|   目标target    |                         被通知的对象                         |
|    代理proxy    |             向目标对象应用通知之后创建的代理对象             |
| 连接点joinpoint |       目标对象的所属类中**，定义的所有方法**均为连接点       |
| 切入点pointcut  | **被切面拦截 / 增强的连接点**（切入点一定是连接点，连接点不一定是切入点） |
|   通知advice    | **增强的逻辑 / 代码，也即拦**截到目标对象的连接点之后要做的事情 |
|   切面aspect    |                切入点(Pointcut)+通知(Advice)                 |
|   织入weaving   |       将通知应用到目标对象，进而生成代理对象的过程动作       |

### 动态代理和静态代理的区别

代理是一种常用的设计模式，目的是：**为其他对象提供一个代理以控制对某个对象的访问，将两个类的关系解耦。代理类和委托类都要实现相同的接口，因为代理真正调用的是委托类的方法。**
区别：

- 静态代理：由程序员创建或者是由特定工具创建，**在代码编译时就确定了被代理的类是一个静态代理**。静态代理**通常只代理一个类；**
- 动态代理：在**代码运行期间，运用反射机制动态创建生成**。动态代理**代理的是一个接口下的多个实现类。**

### Spring Aop和Aspect Aop的区别

- **Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP **基于代理(Proxying)**，而 AspectJ **基于字节码操作(Bytecode** Manipulation)。
- Spring AOP 集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。
- 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多

### AOP常见的通知类型有哪些

- **Before（前置通知）**：目标对象的方法调用之前触发
- **After （后置通知）**：目标对象的方法调用之后触发
- **AfterReturning（返回通知）：**目标对象的方法调用完成，在返回结果值之后触发
- **AfterThrowing（异常通知）：**目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
- **Around （环绕通知）**：编程式控制目标对象的方法调用。环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以**环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法**

### 多个切面的执行顺序如何控制？

1. **通常使用@Order注解直接定义切面顺序**
2. **实现Ordered接口重写getOrder方法**

### AOP实现有哪些注解？

常用的注解包括：

1. @Aspect：用于定义切面，标注在切面类上。
2. @Pointcut：定义切点，标注在方法上，用于指定连接点。
3. @Before：在方法执行之前执行通知。
4. @After：在方法执行之后执行通知。
5. @Around：在方法执行前后都执行通知。
6. @AfterReturning：在方法执行后返回结果后执行通知。
7. @AfterThrowing：在方法抛出异常后执行通知。
8. @Advice：通用的通知类型，可以替代@Before、@After等

## TCP/IP四层体系分层结构

## HTTP/HTTPS

## TCP

### 三次握手

![image-20241020213837481](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241020213837481.png)

- 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态
- 客户端会随机初始化序号，把第一个 SYN 报文发送给服务端，表示向服务端发起连接，之后客户端处于 SYN-SENT 状态。
- 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。
- 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状

第三次握手是可以携带数据的，前两次握手是不可以携带数据的

### 为什么需要三次握手建立连接？

[计算机网络面试题 | 小林coding (xiaolincoding.com)](https://www.xiaolincoding.com/interview/network.html#tcp为什么需要三次握手建立连接)

- 三次握手才**可以阻止重复历史连接的初始化（主要原因）**
- 三次握手才**可以同步双方的初始序列号**
- 三次握手才可以**避免资源浪费**

### 第一次握手，客户端发送SYN报后，服务端回复ACK报，那这个过程中服务端内部做了哪些工作？

服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。

### 大量SYN包发送给服务端服务端会发生什么事情？

有可能会导致TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。
避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；
- 减少 SYN+ACK 重传次数

### TCP 四次挥手过程说一下？

![image-20241020215232534](https://raw.githubusercontent.com/Xiaoxi121/xiaoxi.github.image/main/img/image-20241020215232534.png)

具体过程：

- 客户端主动调用关闭连接的函数，于是就会发送 FIN 报文，这个 FIN 报文代表客户端不会再发送数据了，进入 FIN_WAIT_1 状态；
- 服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 CLOSE_WAIT 状态。在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以必须要得继续 read 接收缓冲区已接收的数据；
- 接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 2MSL 时间之后，也进入 CLOSE 状态

### 服务端出现大量的time-wait有哪些原因？

什么场景下**服务端会主动断开连接呢？**

- 第一个场景：**HTTP 没有使用长连接**

- 第二个场景：HTTP **长连接超时**

  如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。

- 第三个场景：HTTP **长连接的请求数量达到上限**

### TCP和UDP区别是什么

- 连接：**TCP 是面向连接的传输层协议**，传输数据前先要建立连接；**UDP 是不需要连接**，即刻传输数据。
- 服务对象：**TCP 是一对一的**两点服务，即一条连接只有两个端点。**UDP 支持一对一、一对多、多对多的交互通信**
- 可靠性：**TCP 是可靠交付数据的**，数据可以无差错、不丢失、不重复、按序到达。**UDP 是尽最大努力交付**，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，**比如 QUIC 协议**
  - **连接管理、序列号、确认应答、超时重传、流量控制、拥塞控制。**
- 拥塞控制、流量控制**：TCP 有拥塞控制和流量控制机制，**保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
- 首部开销：**TCP 首部长度较长**，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。**UDP 首部只有 8 个字节**，并且是固定不变的，开销较小。
- 传输方式**：TCP 是流式传输**，没有边界，但保证顺序和可靠**。UDP 是一个包一个包的发送**，是有边界的，但可能会丢包和乱序

## 操作系统进程管理

- 进程：

  **进程是操作系统资源分配的基本单位**，每个进程都有独立的地址空间和其他内部状态。

  进程之间相互隔离，拥有自己的内存空间，这意味着它们之间的通信需要通过IPC（Inter-Process Communication）机制，如管道、消息队列等。

  创建和销毁进程的开销较大，因为涉及到系统调用。

- 线程：

  线程是进程内的一个执行单元，称为轻量级进程，**属于同一进程中的多个线程共享相同的地址空间和资源。**

  线程间的切换成本低于进程间的切换，因为它们不需要跨进程边界。

  线程共享进程的数据段，因此在多线程编程中需要注意同步和数据一致性的问题。

- 协程：

  **协程是一种用户空间的执行单元，它的调度由用户程序控制，不像线程那样由操作系统内核调度。**

  协程的特点是可以挂起（yield）和恢复（resume）其执行状态，允许在一个协程中暂停执行并保存当前状态，然后稍后恢复。

  协程的切换成本更低，因为它不涉及任何操作系统级别的上下文切换。

## 操作系统同步机制

## 操作系统虚拟内存

## 设计模式

1. 面向接口编程，而非面向实现
2. 职责单一原则，每个类都应该只有一个单一的功能，并且该功能应该由这个类完全封装起来
3. 对修改关闭，对扩展开放，代码易扩展

### 设计模式分类

1. 创建型：创建对象时隐藏创建逻辑，不使用new直接实例化对象，程序在判断需要创建哪些对象时更灵活
2. 结构型：通过类和接口间的继承和引用实现创建复杂结构的对象
3. 行为型：通过类之间不同通信方式实现不同行为

### 创建型模式

创建型模式的作用是创建对象

简单工厂模式最简单；工厂模式在简单工厂模式的基础上增加了选择工厂的维度，需要第一步选择合适的工厂；抽象工厂模式有产品族的概念，如果各个产品是存在兼容性问题的，就要用抽象工厂模式。单例模式就不说了，为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源；建造者模式专门对付属性很多的那种类，为了让代码更优美；原型模式用得最少，了解和 Object 类中的 clone() 方法相关的知识即可

#### 简单工厂模式

简单的说，简单工厂模式就是这样，一个工厂类 XxxFactory，里面有一个静态方法，根据我们不同的参数，返回不同的派生自同一个父类(或实现同一接口)的对象

```java
public class FoodFactory {

    public static Food makeFood(String name) {
        if (name.equals("noodle")) {
            Food noodle = new LanZhouNoodle();
            noodle.addSpicy("more");
            return noodle;
        } else if (name.equals("chicken")) {
            Food chicken = new HuangMenChicken();
            chicken.addCondiment("potato");
            return chicken;
        } else {
            return null;
        }
    }

}
```

#### 工厂模式

工厂方法模式生成具体产品的任务分发给具体产品工厂

当我们需要使用两个或两个以上的工厂时，就可以使用工厂模式

首先需要选取合适的工厂，然后跟简单工厂模式一样

核心在于 第一步选取什么工厂，因为不同的工厂功能也不一样

```java
public interface FoodFactory {
    Food makeFood(String name);
}
public class ChineseFoodFactory implements FoodFactory {

    @Override
    public Food makeFood(String name) {
        if (name.equals("A")) {
            return new ChineseFoodA();
        } else if (name.equals("B")) {
            return new ChineseFoodB();
        } else {
            return null;
        }
    }
}
public class AmericanFoodFactory implements FoodFactory {

    @Override
    public Food makeFood(String name) {
        if (name.equals("A")) {
            return new AmericanFoodA();
        } else if (name.equals("B")) {
            return new AmericanFoodB();
        } else {
            return null;
        }
    }
}
public class APP {
    public static void main(String[] args) {
        // 先选择一个具体的工厂
        FoodFactory factory = new ChineseFoodFactory();
        // 由第一步的工厂产生具体的对象，不同的工厂造出不一样的对象
        Food food = factory.makeFood("A");
    }
}
```

#### 抽象工厂模式

当涉及到产品族的时候，就需要引入抽象工厂模式了

产品族：代表了组成某个产品的一系列附件的集合

如果不使用抽象工厂模式 那么可能的创建情形如下

```java
// 得到 Intel 的 CPU
CPUFactory cpuFactory = new IntelCPUFactory();
CPU cpu = intelCPUFactory.makeCPU();

// 得到 AMD 的主板
MainBoardFactory mainBoardFactory = new AmdMainBoardFactory();
MainBoard mainBoard = mainBoardFactory.make();

// 组装 CPU 和主板
Computer computer = new Computer(cpu, mainBoard);
```

这样的话 就是 附件与附件之间的排列组合 [ 这里的 CPU 和主板 ]

但是存在的问题是，这些附件适配吗，有可能 Intel 和 AMD 不适配，也就是说创建出来的 Computer 是无法使用的

所以涉及到产品族的问题，使用抽象工厂模式来支持，比如这里，直接定义电脑工厂，每个电脑工厂负责生产所有设备，这样能保证不存在兼容问题	

对于客户端而言，就直接选择一家品牌工厂即可

```java
public static void main(String[] args) {
    // 第一步就要选定一个“大厂”
    ComputerFactory cf = new AmdFactory();
    // 从这个大厂造 CPU
    CPU cpu = cf.makeCPU();
    // 从这个大厂造主板
    MainBoard board = cf.makeMainBoard();
    // 从这个大厂造硬盘
    HardDisk hardDisk = cf.makeHardDisk();

    // 将同一个厂子出来的 CPU、主板、硬盘组装在一起
    Computer result = new Computer(cpu, board, hardDisk);
}
```

这种设计模式存在的问题是，如果我们需要加个显示器，就需要修改所有的工厂，给所有的工厂都加上制造显示器的方法，这有点违背了对修改关闭，对扩展开放的设计原则

#### 单例模式

只存在一个实例，**构造方法必须私有、由自己创建一个静态变量存储实例，对外提供一个静态公有方法获取实例**

**优点是内存中只有⼀个实例，减少了开销，尤其是频繁创建和销毁实例的** 

**情况下并且可以避免对资源的多重占⽤。缺点是没有抽象层，难以扩展，** 

与单⼀职责原则冲突。

##### 饿汉式

1. **类一加载就创建对象**

2. **优点：线程安全，没有加锁，执行效率高**

   饿汉式单例模式是线程安全的，原因如下：

   1. **实例化发生在类加载时**：由于实例化发生在类加载的过程中，而Java的类加载机制是线程安全的，这意味着类只会被加载一次，并且加载过程不会被其他线程干扰。因此，在类加载时创建的单例对象自然也是线程安全的。
   2. **静态变量初始化**：饿汉式的单例实现通常会将单例对象声明为静态变量，并在静态代码块中进行初始化。静态变量的初始化也是线程安全的，因为JVM规范保证了静态字段的初始化是原子性的，并且所有线程都会看到相同的初始化结果。

缺点：不是懒加载，类加载时就初始化，浪费内存空间

1. 线程安全，基于类加载器避免多线程的同步问题，
   如果类被不同的类加载器加载就会创建不同的实例。可反射破坏单例

```java
public class Singleton {
     // 1、私有化构造⽅法
     private Singleton(){}
     // 2、定义⼀个静态变量指向⾃⼰类型
     private final static Singleton instance = new Singleton();
     // 3、对外提供⼀个公共的⽅法获取实例
     public static Singleton getInstance() {
     return instance;
 }
}
```

##### 懒汉式（饱汉式）

**懒加载：使用时再创建对象。**

线程安全：

**synchronized关键字加锁保证线程安全，但影响效率**

```java
public class Singleton {
     // 1、私有化构造⽅法
     private Singleton(){ }
     // 2、定义⼀个静态变量指向⾃⼰类型
     private static Singleton instance;
     // 3、对外提供⼀个公共的⽅法获取实例
     public synchronized static Singleton getInstance() {
         if (instance == null) {
         instance = new Singleton();
         }
         return instance;
     }
}
```

还可以双重锁机制

**优点**

- 延迟初始化：只有在第一次调用时才会创建单例对象，这可以节省不必要的内存占用，特别是在单例对象创建成本较高的情况下。
- 线程安全：通过使用双重检查锁定机制，可以在多线程环境中正确地创建单例对象，避免了多次实例化的问题。
- 性能优化：相比于同步整个方法（如在懒汉式单例模式中），双重检查锁定只在必要时进行同步，从而减少了同步带来的性能开销。
- **缺点**
- 可见性问题：在 Java 早期版本中，由于内存模型的问题，双重检查锁定可能会导致单例对象创建不完全的问题。具体来说，如果两个线程几乎同时到达第一次检查，其中一个线程进入同步块创建了对象并退出，而另一个线程在第一个线程尚未完成对象构造的情况下进行了第二次检查，那么就可能访问到一个尚未构造完成的对象。这个问题在 Java 5 之后得到了修正，通过使用 volatile 关键字可以解决可见性问题。
- 复杂性增加：相比于简单的懒汉式单例模式，双重检查锁定增加了代码的复杂性，使得理解起来更加困难，也增加了出错的可能性。
- 调试难度：由于涉及到线程同步和内存可见性问题，如果实现不当，调试起来会比较麻烦，尤其是对于初学者来说。

```java
//饱汉模式的双重锁模式，提高效率
public class Singleton3 {
	private static Singleton3 singleton;
	
	private Singleton3(){
		
	}
	
	public static Singleton3 getInstance(){
		if(singleton == null){
			synchronized(Singleton3.class){
				if(singleton == null){
					singleton = new Singleton3();
				}
			}
		}
		return singleton;
	}
}
```

#### 建造者模式

经常遇到的 XxxBuilder 的类，通常都是建造者模式的产物

对于客户端而言，一般都是 new 一个 builder，然后链式的调用一堆方法，最后调用 build 方法，需要的对象就创建好了

核心是：先把所有的属性都设置给 Builder，然后使用 build 方法时，将这些属性复制给实际产生的对象

```java
class User {
    // 下面是“一堆”的属性
    private String name;
    private String password;
    private String nickName;
    private int age;

    // 构造方法私有化，不然客户端就会直接调用构造方法了
    private User(String name, String password, String nickName, int age) {
        this.name = name;
        this.password = password;
        this.nickName = nickName;
        this.age = age;
    }
    // 静态方法，用于生成一个 Builder，这个不一定要有，不过写这个方法是一个很好的习惯，
    // 有些代码要求别人写 new User.UserBuilder().a()...build() 看上去就没那么好
    public static UserBuilder builder() {
        return new UserBuilder();
    }

    public static class UserBuilder {
        // 下面是和 User 一模一样的一堆属性
        private String  name;
        private String password;
        private String nickName;
        private int age;

        private UserBuilder() {
        }

        // 链式调用设置各个属性值，返回 this，即 UserBuilder
        public UserBuilder name(String name) {
            this.name = name;
            return this;
        }

        public UserBuilder password(String password) {
            this.password = password;
            return this;
        }

        public UserBuilder nickName(String nickName) {
            this.nickName = nickName;
            return this;
        }

        public UserBuilder age(int age) {
            this.age = age;
            return this;
        }

        // build() 方法负责将 UserBuilder 中设置好的属性“复制”到 User 中。
        // 当然，可以在 “复制” 之前做点检验
        public User build() {
            if (name == null || password == null) {
                throw new RuntimeException("用户名和密码必填");
            }
            if (age <= 0 || age >= 150) {
                throw new RuntimeException("年龄不合法");
            }
            // 还可以做赋予”默认值“的功能
              if (nickName == null) {
                nickName = name;
            }
            return new User(name, password, nickName, age);
        }
    }
}
```

客户端调用

```java
public class APP {
    public static void main(String[] args) {
        User d = User.builder()
                .name("foo")
                .password("pAss12345")
                .age(25)
                .build();
    }
}
```

#### 原型模式

有一个原型实例，基于这个原型实例产生新的实例，也就是“克隆”了

Object 类中有一个 clone 方法，用于生成一个新的对象，当然，如果需要调用这个方法，Java 要求我们的类必须实现 Cloneable 接口，此接口没有定义任何方法，但是不这么做的话，在 clone 的时候，会抛出 CloneNotSupportedException 异常

Java 的克隆通常是浅克隆，碰到对象引用的时候，克隆的对象和原对象中的引用指向的是同一个对象。通常实现深克隆的方法是将对象进行序列化，然后再反序列化

### 结构型模式

结构型模式旨在通过改变代码结构来达到解耦的目的，使得我们的代码容易维护和扩展

代理模式是做方法增强的，适配器模式是把鸡包装成鸭这种用来适配接口的，桥梁模式做到了很好的解耦，装饰模式从名字上就看得出来，适合于装饰类或者说是增强类的场景，门面模式的优点是客户端不需要关心实例化过程，只要调用需要的方法即可，组合模式用于描述具有层次结构的数据，享元模式是为了在特定的场景中缓存已经创建的对象，用于提高性能

#### 代理模式

用代理来隐藏具体实现类的实现细节，通常还用于在真实的实现前后添加一部分逻辑

既然是代理，那就要对客户端隐藏真实实现，由代理来负责客户端的所有请求。

代理只是代理，不会完成实际的业务逻辑，但是对于客户端而言，它必须表现的就是客户端需要的真实实现

```java
public interface FoodService {
    Food makeChicken();
    Food makeNoodle();
}

public class FoodServiceImpl implements FoodService {
    public Food makeChicken() {
          Food f = new Chicken()
        f.setChicken("1kg");
          f.setSpicy("1g");
          f.setSalt("3g");
        return f;
    }
    public Food makeNoodle() {
        Food f = new Noodle();
        f.setNoodle("500g");
        f.setSalt("5g");
        return f;
    }
}

// 代理要表现得“就像是”真实实现类，所以需要实现 FoodService
public class FoodServiceProxy implements FoodService {

    // 内部一定要有一个真实的实现类，当然也可以通过构造方法注入
    private FoodService foodService = new FoodServiceImpl();

    public Food makeChicken() {
        System.out.println("我们马上要开始制作鸡肉了");

        // 如果我们定义这句为核心代码的话，那么，核心代码是真实实现类做的，
        // 代理只是在核心代码前后做些“无足轻重”的事情
        Food food = foodService.makeChicken();

        System.out.println("鸡肉制作完成啦，加点胡椒粉"); // 增强
          food.addCondiment("pepper");

        return food;
    }
    public Food makeNoodle() {
        System.out.println("准备制作拉面~");
        Food food = foodService.makeNoodle();
        System.out.println("制作完成啦")
        return food;
    }
}
```

客户端调用

```java
// 这里用代理类来实例化
FoodService foodService = new FoodServiceProxy();
foodService.makeChicken();
```

代理模式说白了就是做方法包装或方法增强，在 AOP 中，就是动态代理的过程。比如在 Spring 中，实现动态代理的方式有两种：如果类定义了接口，可以使用 Spring 的 JDK 动态代理；没有自己定义的接口，Spring 会使用 CGLIB 进行动态代理

#### 适配器模式

1. **两个不同接口的类通信，不修改这两个的前提下，使用某个中间键完成衔接。**
2. 适配器模式：将已给类的接口，转换成客户端期望的另一个接口，让原本两个不兼容的接口无缝对接
3. 适配器模式分为三类：类适配器模式、对象适配器模式、默认适配器模式
4. 适配器模式和代理模式的异同

1. 在代码结构上，它们很相似，都需要一个具体的实现类的实例。但是他们的目的不一样，代理模式做的是增强原方法；适配器做的是适配，提供的是“把鸡包装成鸭，然后当做鸭来使用”，而鸡鸭之间原本没有继承关系

1. 类适配器：通过类继承实现适配。静态实现
2. 对象适配：类对象组合实现适配。动态实现

就是将一个对象当成另一个对象来使用，但是需要使用适配器来将两个对象之间的方法进行映射

```java
public interface Duck {
    public void quack(); // 鸭的呱呱叫
      public void fly(); // 飞
}

public interface Cock {
    public void gobble(); // 鸡的咕咕叫
      public void fly(); // 飞
}

public class WildCock implements Cock {
    public void gobble() {
        System.out.println("咕咕叫");
    }
      public void fly() {
        System.out.println("鸡也会飞哦");
    }
}
```



```java
// 毫无疑问，首先，这个适配器肯定需要 implements Duck，这样才能当做鸭来用
public class CockAdapter implements Duck {

    Cock cock;
    // 构造方法中需要一个鸡的实例，此类就是将这只鸡适配成鸭来用
      public CockAdapter(Cock cock) {
        this.cock = cock;
    }

    // 实现鸭的呱呱叫方法
      @Override
      public void quack() {
        // 内部其实是一只鸡的咕咕叫
        cock.gobble();
    }

      @Override
      public void fly() {
        cock.fly();
    }
}
```



客户端调用

```java
public static void main(String[] args) {
    // 有一只野鸡
      Cock wildCock = new WildCock();
      // 成功将野鸡适配成鸭
      Duck duck = new CockAdapter(wildCock);
      ...
}
```

1. 默认适配器模式

1. 默默 OS，感觉就是嫌弃上层接口在本类中使用不到，所以使用适配器，先实现所有的上层接口 [return null 或 空方法 ]，然后定义自己的类继承这个适配器，再实现自己需要的方法就可以了
2. 比如 这是 Appache commons-io 包中的 FileAlterationListener，这个接口用于对文件或文件夹进行监控，一旦发生了对应的操作，就会触发相应的方法

```java
public interface FileAlterationListener {
    void onStart(final FileAlterationObserver observer);
    void onDirectoryCreate(final File directory);
    void onDirectoryChange(final File directory);
    void onDirectoryDelete(final File directory);
    void onFileCreate(final File file);
    void onFileChange(final File file);
    void onFileDelete(final File file);
    void onStop(final FileAlterationObserver observer);
}
```

如果我们只是想监控文件夹中的文件创建和删除事件，实现上面这个 Listener 就过于臃肿了

```java
public class FileAlterationListenerAdaptor implements FileAlterationListener {

    public void onStart(final FileAlterationObserver observer) {
    }

    public void onDirectoryCreate(final File directory) {
    }

    public void onDirectoryChange(final File directory) {
    }

    public void onDirectoryDelete(final File directory) {
    }

    public void onFileCreate(final File file) {
    }

    public void onFileChange(final File file) {
    }

    public void onFileDelete(final File file) {
    }

    public void onStop(final FileAlterationObserver observer) {
    }
}
```

采用如上的适配器，然后定义自己的类继承这个适配器，然后实现自己需要的监控文件创建和删除即可

```java
public class FileMonitor extends FileAlterationListenerAdaptor {
    public void onFileCreate(final File file) {
        // 文件创建
        doSomething();
    }

    public void onFileDelete(final File file) {
        // 文件删除
        doSomething();
    }
}
```

#### 桥接模式

代码抽象与解耦

#### 装饰模式

**增强实现类，用具体的装饰器来装饰实现类，以达到增强的目的**

装饰者模式把每个增强类都继承最高级父类。然后需要功能增强时把类实例传入增强类即可，然后增强类在使用时就可以增强原有类的功能了

和代理模式不同的是，装饰者模式每个装饰类都继承父类，并且可以进行多级封装

饮料抽象基类

```java
public abstract class Beverage {
      // 返回描述
      public abstract String getDescription();
      // 返回价格
      public abstract double cost();
}
```

三个饮料基础实现类：红茶、绿茶、咖啡

```java
public class BlackTea extends Beverage {
      public String getDescription() {
        return "红茶";
    }
      public double cost() {
        return 10;
    }
}
public class GreenTea extends Beverage {
    public String getDescription() {
        return "绿茶";
    }
      public double cost() {
        return 11;
    }
}
...// 咖啡省略
```

定义调料，也就是装饰者的基类

```java
// 调料
public abstract class Condiment extends Beverage {

}
```

定义具体的调料，属于装饰者

```java
public class Lemon extends Condiment {
    private Beverage bevarage;
      // 这里很关键，需要传入具体的饮料，如需要传入没有被装饰的红茶或绿茶，
      // 当然也可以传入已经装饰好的芒果绿茶，这样可以做芒果柠檬绿茶
      public Lemon(Beverage bevarage) {
        this.bevarage = bevarage;
    }
      public String getDescription() {
        // 装饰
        return bevarage.getDescription() + ", 加柠檬";
    }
      public double cost() {
          // 装饰
        return beverage.cost() + 2; // 加柠檬需要 2 元
    }
}

public class Mango extends Condiment {
    private Beverage bevarage;
    public Mango(Beverage bevarage) {
        this.bevarage = bevarage;
    }
      public String getDescription() {
        return bevarage.getDescription() + ", 加芒果";
    }
      public double cost() {
        return beverage.cost() + 3; // 加芒果需要 3 元
    }
}
...// 给每一种调料都加一个类
```

客户端调用

```java
public static void main(String[] args) {
      // 首先，我们需要一个基础饮料，红茶、绿茶或咖啡
      Beverage beverage = new GreenTea();
      // 开始装饰
      beverage = new Lemon(beverage); // 先加一份柠檬
      beverage = new Mongo(beverage); // 再加一份芒果

      System.out.println(beverage.getDescription() + " 价格：￥" + beverage.cost());
      //"绿茶, 加柠檬, 加芒果 价格：￥16"
}
```

芒果珍珠双份柠檬红茶

```java
Beverage beverage = new Mongo(new Pearl(new Lemon(new Lemon(new BlackTea())))); 
```

#### 门面模式

优点：客户端不需要关注实例化时应该使用那个实现类，直接调用门面提供的方法就可以了，因为门面类提供的方法的方法名对用户来说已经很友好了

定义接口

```java
public interface Shape {
   void draw();
}
```

定义实现类

```java
public class Circle implements Shape {

   @Override
   public void draw() {
      System.out.println("Circle::draw()");
   }
}

public class Rectangle implements Shape {

   @Override
   public void draw() {
      System.out.println("Rectangle::draw()");
   }
}
```

客户端调用

```java
public static void main(String[] args) {
      // 画一个圆形
      Shape circle = new Circle();
      circle.draw();

      // 画一个长方形
      Shape rectangle = new Rectangle();
      rectangle.draw();
}
```



门面模式

```java
public class ShapeMaker {
   private Shape circle;
   private Shape rectangle;
   private Shape square;

   public ShapeMaker() {
      circle = new Circle();
      rectangle = new Rectangle();
      square = new Square();
   }

  /**
   * 下面定义一堆方法，具体应该调用什么方法，由这个门面来决定
   */

   public void drawCircle(){
      circle.draw();
   }
   public void drawRectangle(){
      rectangle.draw();
   }
   public void drawSquare(){
      square.draw();
   }
}
```

客户端调用

```java
public static void main(String[] args) {
  ShapeMaker shapeMaker = new ShapeMaker();

  // 客户端调用现在更加清晰了
  shapeMaker.drawCircle();
  shapeMaker.drawRectangle();
  shapeMaker.drawSquare();        
}
```

#### 组合模式

组合模式用于表示具有层次结构的数据，使得我们对单个对象和组合对象的访问具有一致性

```java
public class Employee {
   private String name;
   private String dept;
   private int salary;
   private List<Employee> subordinates; // 下属

   public Employee(String name,String dept, int sal) {
      this.name = name;
      this.dept = dept;
      this.salary = sal;
      subordinates = new ArrayList<Employee>();
   }

   public void add(Employee e) {
      subordinates.add(e);
   }

   public void remove(Employee e) {
      subordinates.remove(e);
   }

   public List<Employee> getSubordinates(){
     return subordinates;
   }

   public String toString(){
      return ("Employee :[ Name : " + name + ", dept : " + dept + ", salary :" + salary+" ]");
   }   
}
```

#### 享元模式

共享元器件，也就是复用已经生成的对象

很典型的例子就是包装类 Integer，会初始化一定范围内 [-128,127] 的数字，当我们使用这个范围内的数字，对象的引用都会指向同一个对象

### 行为型模式

行为型模式关注的是各个类之间的相互作用，将职责划分清楚，使得代码更加清晰

#### 策略模式

跟桥梁模式很像，但是桥梁模式的耦合度更低，结构更加复杂



下面设计的一个场景：我们需要画一个图形，可选的策略就是用红色笔、绿色笔还是黄色笔来画



定义策略接口：

```java
public interface Strategy {
   public void draw(int radius, int x, int y);
}
```



定义具体策略：

```java
public class RedPen implements Strategy {
   @Override
   public void draw(int radius, int x, int y) {
      System.out.println("用红色笔画图，radius:" + radius + ", x:" + x + ", y:" + y);
   }
}
public class GreenPen implements Strategy {
   @Override
   public void draw(int radius, int x, int y) {
      System.out.println("用绿色笔画图，radius:" + radius + ", x:" + x + ", y:" + y);
   }
}
public class BluePen implements Strategy {
   @Override
   public void draw(int radius, int x, int y) {
      System.out.println("用蓝色笔画图，radius:" + radius + ", x:" + x + ", y:" + y);
   }
}
```



使用策略的类：

```java
public class Context {
   private Strategy strategy;

   public Context(Strategy strategy){
      this.strategy = strategy;
   }

   public int executeDraw(int radius, int x, int y){
      return strategy.draw(radius, x, y);
   }
}
```



客户端演示：

```java
public static void main(String[] args) {
    Context context = new Context(new BluePen()); // 使用绿色笔来画
      context.executeDraw(10, 0, 0);
}
```

#### 观察者模式

**两个操作：观察者订阅自己关心的主题和主题有数据变化后通知观察者们**

实际生产过程中，观察者模式往往使用消息中间件来实现

定义主题，每个主题需要持有观察者列表的引用，用于在数据变更时通知各个观察者

```java
public class Subject {

   private List<Observer> observers = new ArrayList<Observer>();
   private int state;

   public int getState() {
      return state;
   }

   public void setState(int state) {
      this.state = state;
      // 数据已变更，通知观察者们
      notifyAllObservers();
   }

   public void attach(Observer observer){
      observers.add(observer);        
   }

   // 通知观察者们
   public void notifyAllObservers(){
      for (Observer observer : observers) {
         observer.update();
      }
   }     

}
```

定义观察者接口

```java
public abstract class Observer {
   protected Subject subject;
   public abstract void update();
}
```

#### 责任链模式

责任链通常需要先建立一个单向链表，然后调用方只需要调用头部节点就可以了，后面会自动流转下去。比如流程审批，只要有终端用户提交申请，根据申请的内容信息，自动建立一条责任链，然后就可以开始流转了

如果在执行过程中没有抛出异常，就说明责任链流转成功，即用户可以完成本次操作

对比定义一个 List，其中存放需要执行的规则而言，这种方法更加灵活，可以在客户端完成需要校验的逻辑装配



eg：

定义流程上节点的基类：

```java
public abstract class RuleHandler {
      // 后继节点
    protected RuleHandler successor;

    public abstract void apply(Context context);

    public void setSuccessor(RuleHandler successor) {
        this.successor = successor;
    }
    public RuleHandler getSuccessor() {
        return successor;
    }
}
```



定义具体的节点

校验用户是否是新用户

```java
public class NewUserRuleHandler extends RuleHandler {

    public void apply(Context context) {
        if (context.isNewUser()) {
              // 如果有后继节点的话，传递下去
            if (this.getSuccessor() != null) {
                this.getSuccessor().apply(context);
            }
        } else {
            throw new RuntimeException("该活动仅限新用户参与");
        }
    }

}
```

校验用户所在地区是否可以参与

```java
public class LocationRuleHandler extends RuleHandler {
    public void apply(Context context) {
        boolean allowed = activityService.isSupportedLocation(context.getLocation);
          if (allowed) {
            if (this.getSuccessor() != null) {
                this.getSuccessor().apply(context);
            }
        } else  {
            throw new RuntimeException("非常抱歉，您所在的地区无法参与本次活动");
        }
    }
}
```

校验奖品是否已经领完

```java
public class LimitRuleHandler extends RuleHandler {
    public void apply(Context context) {
        int remainedTimes = activityService.queryRemainedTimes(context); // 查询剩余奖品
        if (remainedTimes > 0) {
            if (this.getSuccessor() != null) {
                this.getSuccessor().apply(userInfo);
            }
        } else {
            throw new RuntimeException("您来得太晚了，奖品被领完了");
        }
    }
}
```



客户端：

```java
public static void main(String[] args) {
      RuleHandler newUserHandler = new NewUserRuleHandler();
      RuleHandler locationHandler = new LocationRuleHandler();
      RuleHandler limitHandler = new LimitRuleHandler();

      // 假设本次活动仅校验地区和奖品数量，不校验新老用户
      locationHandler.setSuccessor(limitHandler);
      locationHandler.apply(context);
}
```

#### 状态模式

eg：商品库存中心有个最基本的需求就是减库存和补库存

定义状态接口

```java
public interface State {
   public void doAction(Context context);
}
```



定义减库存的状态

```java
public class DeductState implements State {

   public void doAction(Context context) {
      System.out.println("商品卖出，准备减库存");
      context.setState(this);

      //... 执行减库存的具体操作
   }

   public String toString(){
      return "Deduct State";
   }
}
```



定义补库存的状态

```java
public class RevertState implements State {
    public void doAction(Context context) {
        System.out.println("给此商品补库存");
        context.setState(this);

        //... 执行加库存的具体操作
    }
      public String toString() {
        return "Revert State";
    }
}
```



context 的定义

```java
public class Context {
    private State state;
    private String name;
    public Context(String name) {
        this.name = name;
    }

    public void setState(State state) {
        this.state = state;
    }
    public void getState() {
        return this.state;
    }
}
```

客户端调用

```java
public static void main(String[] args) {
    // 我们需要操作的是 iPhone X
    Context context = new Context("iPhone X");

    // 看看怎么进行补库存操作
    State revertState = new RevertState();
    revertState.doAction(context);

    // 同样的，减库存操作也非常简单
    State deductState = new DeductState();
    deductState.doAction(context);

    // 如果需要我们可以获取当前的状态
    // context.getState().toString();
}
```

   
